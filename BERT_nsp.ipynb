{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read files including `Answer`, `Choice`, `Question`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Files to List\n",
    "doc_num = 91\n",
    "question_doc = []\n",
    "choice_doc = []\n",
    "ans_doc = []\n",
    "\n",
    "for i in range(1, doc_num + 1):\n",
    "    try:\n",
    "        with open(f'Data/Question/{i}.txt', encoding='utf-8') as f:\n",
    "            raw_q = f.read()\n",
    "    except:\n",
    "        with open(f'Data/Question/{i}.txt', encoding='big5') as f:\n",
    "            raw_q = f.read()\n",
    "    try:\n",
    "        with open(f'Data/Choice/{i}.txt', encoding='utf-8') as f:\n",
    "            raw_ch = f.read()\n",
    "    except:\n",
    "        with open(f'Data/Choice/{i}.txt', encoding='big5') as f:\n",
    "            raw_ch = f.read()\n",
    "    try:\n",
    "        with open(f'Data/Answer/{i}.txt', encoding='utf-8') as f:\n",
    "            raw_a = f.read()\n",
    "    except:\n",
    "        with open(f'Data/Answer/{i}.txt', encoding='big5') as f:\n",
    "            raw_a = f.read()\n",
    "    question_doc.append(raw_q)\n",
    "    choice_doc.append(raw_ch.split('\\n'))\n",
    "    ans_doc.append(list(raw_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nothing is made up.</td>\n",
       "      <td>History is nonfiction, too.</td>\n",
       "      <td>But your trip through space would be fiction.</td>\n",
       "      <td>You could write a story in which you fly to t...</td>\n",
       "      <td>But fiction isn’t always different from the w...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>But when I pulled into the driveway, there wa...</td>\n",
       "      <td>Hours later I called my daughter and asked if...</td>\n",
       "      <td>One time, I even shouted at Derek when he unp...</td>\n",
       "      <td>Derek became part of our life and seemed to f...</td>\n",
       "      <td>Without any experience in raising pets, my hu...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Another genre commonly found in Chinese brush...</td>\n",
       "      <td>However, the subject matters later expanded b...</td>\n",
       "      <td>As a result, they have obtained more natural ...</td>\n",
       "      <td>Its growth has inevitably reflected the chang...</td>\n",
       "      <td>It then gradually developed into two separate...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>She got to look at the fine old houses as wel...</td>\n",
       "      <td>Architects make drawings and careful plans of...</td>\n",
       "      <td>The word for what she does is rehabilitation.</td>\n",
       "      <td>Then she went on to study architecture.</td>\n",
       "      <td>That is precisely what Carrie does.</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>There are definitely two sides to this issue.</td>\n",
       "      <td>Scores decreased as the family size increased...</td>\n",
       "      <td>An intelligence test was administered to over...</td>\n",
       "      <td>On the other side are Rutherford and Sewell, ...</td>\n",
       "      <td>Since then, the theory has been elaborated an...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   A  \\\n",
       "1                                Nothing is made up.   \n",
       "2   But when I pulled into the driveway, there wa...   \n",
       "3   Another genre commonly found in Chinese brush...   \n",
       "4   She got to look at the fine old houses as wel...   \n",
       "5      There are definitely two sides to this issue.   \n",
       "\n",
       "                                                   B  \\\n",
       "1                        History is nonfiction, too.   \n",
       "2   Hours later I called my daughter and asked if...   \n",
       "3   However, the subject matters later expanded b...   \n",
       "4   Architects make drawings and careful plans of...   \n",
       "5   Scores decreased as the family size increased...   \n",
       "\n",
       "                                                   C  \\\n",
       "1      But your trip through space would be fiction.   \n",
       "2   One time, I even shouted at Derek when he unp...   \n",
       "3   As a result, they have obtained more natural ...   \n",
       "4      The word for what she does is rehabilitation.   \n",
       "5   An intelligence test was administered to over...   \n",
       "\n",
       "                                                   D  \\\n",
       "1   You could write a story in which you fly to t...   \n",
       "2   Derek became part of our life and seemed to f...   \n",
       "3   Its growth has inevitably reflected the chang...   \n",
       "4            Then she went on to study architecture.   \n",
       "5   On the other side are Rutherford and Sewell, ...   \n",
       "\n",
       "                                                   E     F  \n",
       "1   But fiction isn’t always different from the w...  None  \n",
       "2   Without any experience in raising pets, my hu...  None  \n",
       "3   It then gradually developed into two separate...        \n",
       "4                That is precisely what Carrie does.  None  \n",
       "5   Since then, the theory has been elaborated an...  None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1  2  3  4  5\n",
       "1  E  D  C  A  B\n",
       "2  E  D  C  A  B\n",
       "3  D  B  E  A  C\n",
       "4  C  E  A  D  B\n",
       "5  C  B  E  A  D"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "choice_cols = ['A', 'B', 'C', 'D', 'E', 'F']\n",
    "choice_df = pd.DataFrame(choice_doc, columns=choice_cols, index=[i + 1 for i in range(len(choice_doc))])\n",
    "for col in choice_cols:\n",
    "    choice_df[col] = choice_df[col].str.replace(r'\\([A-F]\\)', '')\n",
    "\n",
    "ans_cols = [1, 2, 3, 4, 5]\n",
    "ans_df = pd.DataFrame(ans_doc, columns=ans_cols, index=[i + 1 for i in range(len(choice_doc))])\n",
    "\n",
    "display(choice_df.head())\n",
    "display(ans_df.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. BERT (NSP) only considering sentence before option\n",
    "code ref: https://towardsdatascience.com/bert-for-next-sentence-prediction-466b67f8226f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForNextSentencePrediction: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# pip3 install transformers\n",
    "# pip3 install torch\n",
    "\n",
    "from transformers import BertTokenizer, BertForNextSentencePrediction\n",
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Finish Doc 1 ===\n",
      "=== Finish Doc 2 ===\n",
      "=== Finish Doc 3 ===\n",
      "=== Finish Doc 4 ===\n",
      "=== Finish Doc 5 ===\n",
      "=== Finish Doc 6 ===\n",
      "=== Finish Doc 7 ===\n",
      "=== Finish Doc 8 ===\n",
      "=== Finish Doc 9 ===\n",
      "=== Finish Doc 10 ===\n",
      "=== Finish Doc 11 ===\n",
      "=== Finish Doc 12 ===\n",
      "=== Finish Doc 13 ===\n",
      "=== Finish Doc 14 ===\n",
      "=== Finish Doc 15 ===\n",
      "=== Finish Doc 16 ===\n",
      "=== Finish Doc 17 ===\n",
      "=== Finish Doc 18 ===\n",
      "=== Finish Doc 19 ===\n",
      "=== Finish Doc 20 ===\n",
      "=== Finish Doc 21 ===\n",
      "=== Finish Doc 22 ===\n",
      "=== Finish Doc 23 ===\n",
      "=== Finish Doc 24 ===\n",
      "=== Finish Doc 25 ===\n",
      "=== Finish Doc 26 ===\n",
      "=== Finish Doc 27 ===\n",
      "=== Finish Doc 28 ===\n",
      "=== Finish Doc 29 ===\n",
      "=== Finish Doc 30 ===\n",
      "=== Finish Doc 31 ===\n",
      "=== Finish Doc 32 ===\n",
      "=== Finish Doc 33 ===\n",
      "=== Finish Doc 34 ===\n",
      "=== Finish Doc 35 ===\n",
      "=== Finish Doc 36 ===\n",
      "=== Finish Doc 37 ===\n",
      "=== Finish Doc 38 ===\n",
      "=== Finish Doc 39 ===\n",
      "=== Finish Doc 40 ===\n",
      "=== Finish Doc 41 ===\n",
      "=== Finish Doc 42 ===\n",
      "=== Finish Doc 43 ===\n",
      "=== Finish Doc 44 ===\n",
      "=== Finish Doc 45 ===\n",
      "=== Finish Doc 46 ===\n",
      "=== Finish Doc 47 ===\n",
      "=== Finish Doc 48 ===\n",
      "=== Finish Doc 49 ===\n",
      "=== Finish Doc 50 ===\n",
      "=== Finish Doc 51 ===\n",
      "=== Finish Doc 52 ===\n",
      "=== Finish Doc 53 ===\n",
      "=== Finish Doc 54 ===\n",
      "=== Finish Doc 55 ===\n",
      "=== Finish Doc 56 ===\n",
      "=== Finish Doc 57 ===\n",
      "=== Finish Doc 58 ===\n",
      "=== Finish Doc 59 ===\n",
      "=== Finish Doc 60 ===\n",
      "=== Finish Doc 61 ===\n",
      "=== Finish Doc 62 ===\n",
      "=== Finish Doc 63 ===\n",
      "=== Finish Doc 64 ===\n",
      "=== Finish Doc 65 ===\n",
      "=== Finish Doc 66 ===\n",
      "=== Finish Doc 67 ===\n",
      "=== Finish Doc 68 ===\n",
      "=== Finish Doc 69 ===\n",
      "=== Finish Doc 70 ===\n",
      "=== Finish Doc 71 ===\n",
      "=== Finish Doc 72 ===\n",
      "=== Finish Doc 73 ===\n",
      "=== Finish Doc 74 ===\n",
      "=== Finish Doc 75 ===\n",
      "=== Finish Doc 76 ===\n",
      "=== Finish Doc 77 ===\n",
      "=== Finish Doc 78 ===\n",
      "=== Finish Doc 79 ===\n",
      "=== Finish Doc 80 ===\n",
      "=== Finish Doc 81 ===\n",
      "=== Finish Doc 82 ===\n",
      "=== Finish Doc 83 ===\n",
      "=== Finish Doc 84 ===\n",
      "=== Finish Doc 85 ===\n",
      "=== Finish Doc 86 ===\n",
      "=== Finish Doc 87 ===\n",
      "=== Finish Doc 88 ===\n",
      "=== Finish Doc 89 ===\n",
      "=== Finish Doc 90 ===\n",
      "=== Finish Doc 91 ===\n"
     ]
    }
   ],
   "source": [
    "count_NotNextSentence = 0\n",
    "NotNextSentence = []\n",
    "\n",
    "for i in range(len(question_doc)): # each document\n",
    "  question_sentence = re.split('\\(1\\)|\\(2\\)|\\(3\\)|\\(4\\)|\\(5\\)', question_doc[i])\n",
    "  quesion_num = 5\n",
    "  if (ans_df.iloc[i][5] == None):\n",
    "    quesion_num = 4\n",
    "  for j in range(quesion_num): # each question\n",
    "      for k in range(6): # each option\n",
    "        if (choice_df.iloc[i][choice_cols[k]] != None):\n",
    "          inputs = tokenizer(question_sentence[j], choice_df.iloc[i][choice_cols[k]], return_tensors='pt')\n",
    "          outputs = model(**inputs)\n",
    "          if (torch.argmax(outputs.logits).item() == 1): # NotNextSentence\n",
    "            count_NotNextSentence += 1\n",
    "            NotNextSentence.append([i+1, j+1, choice_cols[k]]) # Doc i+1, Question j+1, Choice choice_cols[k], is not the answer\n",
    "  print(\"=== Finish Doc\", i+1, \"===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188\n"
     ]
    }
   ],
   "source": [
    "# In all situations (91*5*5 = 2375), only `count_NotNextSentence` situations are defined as `NotNextSentence`\n",
    "print(count_NotNextSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 4, 'D'], [4, 1, 'D'], [4, 2, 'C'], [4, 2, 'D'], [4, 2, 'E'], [4, 3, 'B'], [5, 3, 'A'], [6, 1, 'B'], [6, 4, 'B'], [8, 5, 'D'], [10, 1, 'A'], [10, 1, 'C'], [10, 1, 'D'], [10, 3, 'C'], [13, 1, 'C'], [13, 2, 'C'], [14, 1, 'C'], [14, 2, 'C'], [14, 3, 'C'], [17, 5, 'F'], [18, 5, 'D'], [19, 1, 'B'], [19, 1, 'C'], [19, 2, 'C'], [19, 3, 'C'], [19, 4, 'B'], [20, 2, 'C'], [20, 3, 'C'], [20, 5, 'C'], [22, 1, 'A'], [22, 1, 'B'], [22, 1, 'D'], [22, 1, 'F'], [22, 2, 'B'], [22, 2, 'F'], [22, 3, 'B'], [22, 3, 'E'], [22, 3, 'F'], [22, 4, 'A'], [22, 4, 'D'], [22, 4, 'E'], [22, 5, 'A'], [22, 5, 'C'], [22, 5, 'E'], [23, 1, 'B'], [27, 4, 'C'], [31, 1, 'B'], [31, 1, 'C'], [31, 3, 'A'], [31, 4, 'A'], [33, 1, 'A'], [33, 2, 'A'], [34, 2, 'A'], [38, 1, 'B'], [38, 3, 'B'], [41, 2, 'B'], [41, 4, 'B'], [43, 1, 'B'], [43, 4, 'B'], [43, 4, 'F'], [44, 1, 'B'], [44, 1, 'C'], [44, 5, 'A'], [45, 1, 'B'], [45, 1, 'D'], [45, 1, 'E'], [45, 2, 'B'], [45, 3, 'B'], [45, 3, 'C'], [45, 4, 'B'], [46, 3, 'E'], [46, 4, 'C'], [46, 5, 'E'], [47, 1, 'B'], [47, 2, 'B'], [47, 4, 'A'], [47, 5, 'B'], [48, 2, 'E'], [49, 1, 'C'], [49, 4, 'D'], [49, 4, 'F'], [49, 5, 'C'], [49, 5, 'D'], [50, 1, 'B'], [50, 1, 'E'], [50, 1, 'F'], [50, 3, 'B'], [51, 1, 'A'], [51, 1, 'D'], [51, 1, 'F'], [51, 2, 'A'], [51, 5, 'D'], [52, 1, 'B'], [52, 1, 'E'], [52, 2, 'B'], [52, 2, 'D'], [52, 3, 'B'], [52, 3, 'E'], [52, 3, 'F'], [52, 4, 'D'], [52, 5, 'D'], [53, 2, 'E'], [53, 3, 'E'], [53, 4, 'A'], [53, 4, 'B'], [53, 4, 'E'], [53, 5, 'C'], [54, 4, 'F'], [54, 5, 'F'], [55, 2, 'A'], [55, 3, 'C'], [56, 1, 'D'], [57, 3, 'D'], [59, 3, 'D'], [59, 4, 'B'], [59, 4, 'D'], [60, 5, 'A'], [60, 5, 'B'], [60, 5, 'C'], [60, 5, 'E'], [60, 5, 'F'], [61, 1, 'D'], [61, 1, 'E'], [61, 2, 'D'], [62, 1, 'D'], [62, 2, 'A'], [62, 2, 'C'], [62, 2, 'D'], [62, 3, 'C'], [62, 4, 'B'], [62, 4, 'C'], [62, 5, 'D'], [63, 1, 'A'], [63, 1, 'C'], [63, 2, 'A'], [63, 2, 'E'], [63, 4, 'B'], [63, 4, 'C'], [63, 5, 'B'], [63, 5, 'C'], [64, 2, 'E'], [64, 2, 'F'], [64, 5, 'D'], [64, 5, 'E'], [67, 3, 'E'], [67, 4, 'D'], [67, 4, 'E'], [68, 3, 'A'], [68, 4, 'A'], [68, 5, 'A'], [69, 2, 'A'], [69, 3, 'A'], [69, 4, 'A'], [69, 5, 'A'], [71, 4, 'D'], [72, 1, 'B'], [72, 1, 'C'], [72, 2, 'C'], [72, 3, 'C'], [72, 4, 'D'], [73, 1, 'A'], [73, 1, 'C'], [73, 4, 'F'], [75, 2, 'F'], [75, 3, 'F'], [75, 4, 'B'], [75, 5, 'B'], [75, 5, 'F'], [77, 3, 'E'], [78, 3, 'F'], [78, 4, 'F'], [79, 1, 'A'], [79, 1, 'B'], [79, 1, 'C'], [79, 1, 'E'], [79, 1, 'F'], [79, 5, 'F'], [82, 1, 'C'], [82, 2, 'C'], [82, 5, 'D'], [83, 1, 'E'], [83, 2, 'E'], [83, 4, 'E'], [83, 5, 'E'], [85, 4, 'E'], [90, 3, 'B'], [91, 2, 'C'], [91, 3, 'C']]\n"
     ]
    }
   ],
   "source": [
    "print(NotNextSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong answer!! [4, 2, 'E']\n",
      "Wrong answer!! [47, 4, 'A']\n",
      "Wrong answer!! [52, 3, 'F']\n",
      "Wrong answer!! [53, 4, 'B']\n",
      "Wrong answer!! [60, 5, 'E']\n",
      "Wrong answer!! [63, 5, 'C']\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(NotNextSentence)):\n",
    "  if (ans_df.iloc[NotNextSentence[i][0]-1][NotNextSentence[i][1]] == NotNextSentence[i][2]):\n",
    "    print(\"Wrong answer!!\", NotNextSentence[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. BERT (NSP) consider sentence after option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Finish Doc 1 ===\n",
      "=== Finish Doc 2 ===\n",
      "=== Finish Doc 3 ===\n",
      "=== Finish Doc 4 ===\n",
      "=== Finish Doc 5 ===\n",
      "=== Finish Doc 6 ===\n",
      "=== Finish Doc 7 ===\n",
      "=== Finish Doc 8 ===\n",
      "=== Finish Doc 9 ===\n",
      "=== Finish Doc 10 ===\n",
      "=== Finish Doc 11 ===\n",
      "=== Finish Doc 12 ===\n",
      "=== Finish Doc 13 ===\n",
      "=== Finish Doc 14 ===\n",
      "=== Finish Doc 15 ===\n",
      "=== Finish Doc 16 ===\n",
      "=== Finish Doc 17 ===\n",
      "=== Finish Doc 18 ===\n",
      "=== Finish Doc 19 ===\n",
      "=== Finish Doc 20 ===\n",
      "=== Finish Doc 21 ===\n",
      "=== Finish Doc 22 ===\n",
      "=== Finish Doc 23 ===\n",
      "=== Finish Doc 24 ===\n",
      "=== Finish Doc 25 ===\n",
      "=== Finish Doc 26 ===\n",
      "=== Finish Doc 27 ===\n",
      "=== Finish Doc 28 ===\n",
      "=== Finish Doc 29 ===\n",
      "=== Finish Doc 30 ===\n",
      "=== Finish Doc 31 ===\n",
      "=== Finish Doc 32 ===\n",
      "=== Finish Doc 33 ===\n",
      "=== Finish Doc 34 ===\n",
      "=== Finish Doc 35 ===\n",
      "=== Finish Doc 36 ===\n",
      "=== Finish Doc 37 ===\n",
      "=== Finish Doc 38 ===\n",
      "=== Finish Doc 39 ===\n",
      "=== Finish Doc 40 ===\n",
      "=== Finish Doc 41 ===\n",
      "=== Finish Doc 42 ===\n",
      "=== Finish Doc 43 ===\n",
      "=== Finish Doc 44 ===\n",
      "=== Finish Doc 45 ===\n",
      "=== Finish Doc 46 ===\n",
      "=== Finish Doc 47 ===\n",
      "=== Finish Doc 48 ===\n",
      "=== Finish Doc 49 ===\n",
      "=== Finish Doc 50 ===\n",
      "=== Finish Doc 51 ===\n",
      "=== Finish Doc 52 ===\n",
      "=== Finish Doc 53 ===\n",
      "=== Finish Doc 54 ===\n",
      "=== Finish Doc 55 ===\n",
      "=== Finish Doc 56 ===\n",
      "=== Finish Doc 57 ===\n",
      "=== Finish Doc 58 ===\n",
      "=== Finish Doc 59 ===\n",
      "=== Finish Doc 60 ===\n",
      "=== Finish Doc 61 ===\n",
      "=== Finish Doc 62 ===\n",
      "=== Finish Doc 63 ===\n",
      "=== Finish Doc 64 ===\n",
      "=== Finish Doc 65 ===\n",
      "=== Finish Doc 66 ===\n",
      "=== Finish Doc 67 ===\n",
      "=== Finish Doc 68 ===\n",
      "=== Finish Doc 69 ===\n",
      "=== Finish Doc 70 ===\n",
      "=== Finish Doc 71 ===\n",
      "=== Finish Doc 72 ===\n",
      "=== Finish Doc 73 ===\n",
      "=== Finish Doc 74 ===\n",
      "=== Finish Doc 75 ===\n",
      "=== Finish Doc 76 ===\n",
      "=== Finish Doc 77 ===\n",
      "=== Finish Doc 78 ===\n",
      "=== Finish Doc 79 ===\n",
      "=== Finish Doc 80 ===\n",
      "=== Finish Doc 81 ===\n",
      "=== Finish Doc 82 ===\n",
      "=== Finish Doc 83 ===\n",
      "=== Finish Doc 84 ===\n",
      "=== Finish Doc 85 ===\n",
      "=== Finish Doc 86 ===\n",
      "=== Finish Doc 87 ===\n",
      "=== Finish Doc 88 ===\n",
      "=== Finish Doc 89 ===\n",
      "=== Finish Doc 90 ===\n",
      "=== Finish Doc 91 ===\n"
     ]
    }
   ],
   "source": [
    "count_answer = 0\n",
    "count_not_answer = 0\n",
    "answer = []\n",
    "not_answer = []\n",
    "\n",
    "for i in range(len(question_doc)): # each document\n",
    "  question_sentence = re.split('\\(1\\)|\\(2\\)|\\(3\\)|\\(4\\)|\\(5\\)', question_doc[i])\n",
    "  quesion_num = 5\n",
    "  if (ans_df.iloc[i][5] == None):\n",
    "    quesion_num = 4\n",
    "  for j in range(quesion_num): # each question\n",
    "    for k in range(6): # each option\n",
    "      if (choice_df.iloc[i][choice_cols[k]] != None):\n",
    "        inputs = tokenizer(question_sentence[j], choice_df.iloc[i][choice_cols[k]], return_tensors='pt')\n",
    "        outputs = model(**inputs)\n",
    "        if (torch.argmax(outputs.logits).item() == 0 and len(question_sentence) > j): # IsNextSentence\n",
    "          inputs_2 = tokenizer(choice_df.iloc[i][choice_cols[k]], question_sentence[j+1], return_tensors='pt')\n",
    "          outputs_2 = model(**inputs_2)\n",
    "          if (torch.argmax(outputs_2.logits).item() == 0): # IsNextSentence\n",
    "            count_answer += 1\n",
    "            answer.append([i+1, j+1, choice_cols[k]]) # Doc i+1, Question j+1, Choice choice_cols[k], is the answer\n",
    "          else:\n",
    "            count_not_answer += 1\n",
    "            not_answer.append([i+1, j+1, choice_cols[k]])\n",
    "        elif (torch.argmax(outputs.logits).item() == 0): # IsNextSentence but no more content after the option field\n",
    "          count_answer += 1\n",
    "          answer.append([i+1, j+1, choice_cols[k]]) # Doc i+1, Question j+1, Choice choice_cols[k], is the answer\n",
    "        else:\n",
    "          count_not_answer += 1\n",
    "          not_answer.append([i+1, j+1, choice_cols[k]])\n",
    "  print(\"=== Finish Doc\", i+1, \"===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2072"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(not_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong answer!! [4, 2, 'E']\n",
      "Wrong answer!! [22, 3, 'D']\n",
      "Wrong answer!! [47, 4, 'A']\n",
      "Wrong answer!! [50, 5, 'B']\n",
      "Wrong answer!! [52, 3, 'F']\n",
      "Wrong answer!! [53, 1, 'E']\n",
      "Wrong answer!! [53, 4, 'B']\n",
      "Wrong answer!! [60, 5, 'E']\n",
      "Wrong answer!! [62, 1, 'C']\n",
      "Wrong answer!! [63, 5, 'C']\n",
      "Wrong answer!! [69, 1, 'A']\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(not_answer)):\n",
    "  if (ans_df.iloc[not_answer[i][0]-1][not_answer[i][1]] == not_answer[i][2]):\n",
    "    print(\"Wrong answer!!\", not_answer[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 'A'],\n",
       " [1, 1, 'B'],\n",
       " [1, 1, 'C'],\n",
       " [1, 1, 'D'],\n",
       " [1, 1, 'E'],\n",
       " [1, 2, 'A'],\n",
       " [1, 2, 'B'],\n",
       " [1, 2, 'C'],\n",
       " [1, 2, 'D'],\n",
       " [1, 2, 'E'],\n",
       " [1, 3, 'A'],\n",
       " [1, 3, 'B'],\n",
       " [1, 3, 'C'],\n",
       " [1, 3, 'D'],\n",
       " [1, 3, 'E'],\n",
       " [1, 4, 'A'],\n",
       " [1, 4, 'B'],\n",
       " [1, 4, 'C'],\n",
       " [1, 4, 'D'],\n",
       " [1, 4, 'E'],\n",
       " [1, 5, 'A'],\n",
       " [1, 5, 'B'],\n",
       " [1, 5, 'C'],\n",
       " [1, 5, 'D'],\n",
       " [1, 5, 'E'],\n",
       " [2, 1, 'A'],\n",
       " [2, 1, 'B'],\n",
       " [2, 1, 'C'],\n",
       " [2, 1, 'D'],\n",
       " [2, 1, 'E'],\n",
       " [2, 2, 'A'],\n",
       " [2, 2, 'B'],\n",
       " [2, 2, 'C'],\n",
       " [2, 2, 'D'],\n",
       " [2, 2, 'E'],\n",
       " [2, 3, 'A'],\n",
       " [2, 3, 'B'],\n",
       " [2, 3, 'C'],\n",
       " [2, 3, 'D'],\n",
       " [2, 3, 'E'],\n",
       " [2, 4, 'A'],\n",
       " [2, 4, 'B'],\n",
       " [2, 4, 'C'],\n",
       " [2, 4, 'D'],\n",
       " [2, 4, 'E'],\n",
       " [2, 5, 'B'],\n",
       " [2, 5, 'C'],\n",
       " [2, 5, 'D'],\n",
       " [3, 1, 'A'],\n",
       " [3, 1, 'B'],\n",
       " [3, 1, 'C'],\n",
       " [3, 1, 'D'],\n",
       " [3, 1, 'E'],\n",
       " [3, 1, 'F'],\n",
       " [3, 2, 'A'],\n",
       " [3, 2, 'B'],\n",
       " [3, 2, 'C'],\n",
       " [3, 2, 'D'],\n",
       " [3, 2, 'E'],\n",
       " [3, 3, 'A'],\n",
       " [3, 3, 'B'],\n",
       " [3, 3, 'C'],\n",
       " [3, 3, 'E'],\n",
       " [3, 3, 'F'],\n",
       " [3, 4, 'A'],\n",
       " [3, 4, 'B'],\n",
       " [3, 4, 'C'],\n",
       " [3, 4, 'E'],\n",
       " [3, 4, 'F'],\n",
       " [3, 5, 'A'],\n",
       " [3, 5, 'B'],\n",
       " [3, 5, 'C'],\n",
       " [3, 5, 'E'],\n",
       " [3, 5, 'F'],\n",
       " [4, 1, 'A'],\n",
       " [4, 1, 'B'],\n",
       " [4, 1, 'C'],\n",
       " [4, 2, 'A'],\n",
       " [4, 2, 'B'],\n",
       " [4, 3, 'A'],\n",
       " [4, 3, 'C'],\n",
       " [4, 3, 'D'],\n",
       " [4, 3, 'E'],\n",
       " [4, 4, 'A'],\n",
       " [4, 4, 'C'],\n",
       " [4, 4, 'D'],\n",
       " [4, 4, 'E'],\n",
       " [4, 5, 'A'],\n",
       " [4, 5, 'B'],\n",
       " [4, 5, 'C'],\n",
       " [4, 5, 'D'],\n",
       " [4, 5, 'E'],\n",
       " [5, 1, 'B'],\n",
       " [5, 1, 'C'],\n",
       " [5, 1, 'D'],\n",
       " [5, 1, 'E'],\n",
       " [5, 2, 'B'],\n",
       " [5, 2, 'C'],\n",
       " [5, 2, 'D'],\n",
       " [5, 2, 'E'],\n",
       " [5, 3, 'B'],\n",
       " [5, 3, 'C'],\n",
       " [5, 3, 'D'],\n",
       " [5, 3, 'E'],\n",
       " [5, 4, 'A'],\n",
       " [5, 4, 'B'],\n",
       " [5, 4, 'C'],\n",
       " [5, 4, 'D'],\n",
       " [5, 4, 'E'],\n",
       " [5, 5, 'A'],\n",
       " [5, 5, 'B'],\n",
       " [5, 5, 'C'],\n",
       " [5, 5, 'D'],\n",
       " [5, 5, 'E'],\n",
       " [6, 1, 'A'],\n",
       " [6, 1, 'C'],\n",
       " [6, 1, 'D'],\n",
       " [6, 1, 'E'],\n",
       " [6, 2, 'A'],\n",
       " [6, 2, 'B'],\n",
       " [6, 2, 'C'],\n",
       " [6, 2, 'D'],\n",
       " [6, 2, 'E'],\n",
       " [6, 3, 'A'],\n",
       " [6, 3, 'C'],\n",
       " [6, 3, 'D'],\n",
       " [6, 4, 'A'],\n",
       " [6, 4, 'C'],\n",
       " [6, 4, 'D'],\n",
       " [6, 4, 'E'],\n",
       " [6, 5, 'A'],\n",
       " [6, 5, 'B'],\n",
       " [6, 5, 'C'],\n",
       " [6, 5, 'D'],\n",
       " [6, 5, 'E'],\n",
       " [7, 1, 'A'],\n",
       " [7, 1, 'B'],\n",
       " [7, 1, 'C'],\n",
       " [7, 1, 'D'],\n",
       " [7, 1, 'E'],\n",
       " [7, 2, 'A'],\n",
       " [7, 2, 'B'],\n",
       " [7, 2, 'C'],\n",
       " [7, 2, 'D'],\n",
       " [7, 2, 'E'],\n",
       " [7, 3, 'A'],\n",
       " [7, 3, 'B'],\n",
       " [7, 3, 'C'],\n",
       " [7, 3, 'D'],\n",
       " [7, 3, 'E'],\n",
       " [7, 4, 'A'],\n",
       " [7, 4, 'B'],\n",
       " [7, 4, 'C'],\n",
       " [7, 4, 'D'],\n",
       " [7, 4, 'E'],\n",
       " [7, 5, 'A'],\n",
       " [7, 5, 'B'],\n",
       " [7, 5, 'C'],\n",
       " [7, 5, 'D'],\n",
       " [7, 5, 'E'],\n",
       " [8, 1, 'A'],\n",
       " [8, 1, 'B'],\n",
       " [8, 1, 'C'],\n",
       " [8, 1, 'D'],\n",
       " [8, 1, 'E'],\n",
       " [8, 2, 'A'],\n",
       " [8, 2, 'B'],\n",
       " [8, 2, 'C'],\n",
       " [8, 2, 'D'],\n",
       " [8, 2, 'E'],\n",
       " [8, 3, 'A'],\n",
       " [8, 3, 'B'],\n",
       " [8, 3, 'C'],\n",
       " [8, 3, 'D'],\n",
       " [8, 3, 'E'],\n",
       " [8, 4, 'A'],\n",
       " [8, 4, 'B'],\n",
       " [8, 4, 'C'],\n",
       " [8, 4, 'E'],\n",
       " [8, 5, 'A'],\n",
       " [8, 5, 'B'],\n",
       " [8, 5, 'C'],\n",
       " [8, 5, 'E'],\n",
       " [9, 1, 'A'],\n",
       " [9, 1, 'B'],\n",
       " [9, 1, 'C'],\n",
       " [9, 1, 'D'],\n",
       " [9, 1, 'E'],\n",
       " [9, 2, 'A'],\n",
       " [9, 2, 'B'],\n",
       " [9, 2, 'C'],\n",
       " [9, 2, 'D'],\n",
       " [9, 2, 'E'],\n",
       " [9, 3, 'B'],\n",
       " [9, 3, 'C'],\n",
       " [9, 3, 'D'],\n",
       " [9, 3, 'E'],\n",
       " [9, 4, 'A'],\n",
       " [9, 4, 'B'],\n",
       " [9, 4, 'C'],\n",
       " [9, 4, 'D'],\n",
       " [9, 4, 'E'],\n",
       " [9, 5, 'A'],\n",
       " [9, 5, 'B'],\n",
       " [9, 5, 'D'],\n",
       " [9, 5, 'E'],\n",
       " [10, 1, 'B'],\n",
       " [10, 1, 'E'],\n",
       " [10, 2, 'A'],\n",
       " [10, 2, 'B'],\n",
       " [10, 2, 'D'],\n",
       " [10, 2, 'E'],\n",
       " [10, 3, 'A'],\n",
       " [10, 3, 'B'],\n",
       " [10, 3, 'D'],\n",
       " [10, 3, 'E'],\n",
       " [10, 4, 'A'],\n",
       " [10, 4, 'B'],\n",
       " [10, 4, 'C'],\n",
       " [10, 4, 'D'],\n",
       " [10, 4, 'E'],\n",
       " [10, 5, 'A'],\n",
       " [10, 5, 'B'],\n",
       " [10, 5, 'C'],\n",
       " [10, 5, 'D'],\n",
       " [10, 5, 'E'],\n",
       " [11, 1, 'A'],\n",
       " [11, 1, 'B'],\n",
       " [11, 1, 'C'],\n",
       " [11, 1, 'D'],\n",
       " [11, 1, 'F'],\n",
       " [11, 2, 'A'],\n",
       " [11, 2, 'B'],\n",
       " [11, 2, 'C'],\n",
       " [11, 2, 'D'],\n",
       " [11, 2, 'E'],\n",
       " [11, 2, 'F'],\n",
       " [11, 3, 'A'],\n",
       " [11, 3, 'B'],\n",
       " [11, 3, 'C'],\n",
       " [11, 3, 'D'],\n",
       " [11, 3, 'E'],\n",
       " [11, 3, 'F'],\n",
       " [11, 4, 'A'],\n",
       " [11, 4, 'B'],\n",
       " [11, 4, 'C'],\n",
       " [11, 4, 'D'],\n",
       " [11, 4, 'E'],\n",
       " [11, 4, 'F'],\n",
       " [11, 5, 'A'],\n",
       " [11, 5, 'B'],\n",
       " [11, 5, 'C'],\n",
       " [11, 5, 'D'],\n",
       " [11, 5, 'E'],\n",
       " [11, 5, 'F'],\n",
       " [12, 1, 'A'],\n",
       " [12, 1, 'B'],\n",
       " [12, 1, 'C'],\n",
       " [12, 1, 'D'],\n",
       " [12, 1, 'E'],\n",
       " [12, 1, 'F'],\n",
       " [12, 2, 'A'],\n",
       " [12, 2, 'B'],\n",
       " [12, 2, 'C'],\n",
       " [12, 2, 'D'],\n",
       " [12, 2, 'E'],\n",
       " [12, 2, 'F'],\n",
       " [12, 3, 'A'],\n",
       " [12, 3, 'B'],\n",
       " [12, 3, 'C'],\n",
       " [12, 3, 'D'],\n",
       " [12, 3, 'E'],\n",
       " [12, 3, 'F'],\n",
       " [12, 4, 'A'],\n",
       " [12, 4, 'B'],\n",
       " [12, 4, 'C'],\n",
       " [12, 4, 'D'],\n",
       " [12, 4, 'E'],\n",
       " [12, 4, 'F'],\n",
       " [12, 5, 'A'],\n",
       " [12, 5, 'B'],\n",
       " [12, 5, 'C'],\n",
       " [12, 5, 'D'],\n",
       " [12, 5, 'E'],\n",
       " [12, 5, 'F'],\n",
       " [13, 1, 'A'],\n",
       " [13, 1, 'B'],\n",
       " [13, 1, 'D'],\n",
       " [13, 1, 'E'],\n",
       " [13, 1, 'F'],\n",
       " [13, 2, 'D'],\n",
       " [13, 2, 'E'],\n",
       " [13, 2, 'F'],\n",
       " [13, 3, 'B'],\n",
       " [13, 3, 'C'],\n",
       " [13, 3, 'D'],\n",
       " [13, 3, 'E'],\n",
       " [13, 3, 'F'],\n",
       " [13, 4, 'A'],\n",
       " [13, 4, 'C'],\n",
       " [13, 4, 'D'],\n",
       " [13, 4, 'E'],\n",
       " [13, 4, 'F'],\n",
       " [13, 5, 'C'],\n",
       " [13, 5, 'D'],\n",
       " [13, 5, 'E'],\n",
       " [14, 1, 'A'],\n",
       " [14, 1, 'B'],\n",
       " [14, 1, 'D'],\n",
       " [14, 1, 'E'],\n",
       " [14, 1, 'F'],\n",
       " [14, 2, 'A'],\n",
       " [14, 2, 'B'],\n",
       " [14, 2, 'D'],\n",
       " [14, 2, 'E'],\n",
       " [14, 2, 'F'],\n",
       " [14, 3, 'A'],\n",
       " [14, 3, 'B'],\n",
       " [14, 3, 'D'],\n",
       " [14, 3, 'E'],\n",
       " [14, 3, 'F'],\n",
       " [14, 4, 'A'],\n",
       " [14, 4, 'B'],\n",
       " [14, 4, 'C'],\n",
       " [14, 4, 'D'],\n",
       " [14, 4, 'E'],\n",
       " [14, 4, 'F'],\n",
       " [14, 5, 'A'],\n",
       " [14, 5, 'B'],\n",
       " [14, 5, 'D'],\n",
       " [14, 5, 'E'],\n",
       " [14, 5, 'F'],\n",
       " [15, 1, 'A'],\n",
       " [15, 1, 'B'],\n",
       " [15, 1, 'C'],\n",
       " [15, 1, 'D'],\n",
       " [15, 1, 'E'],\n",
       " [15, 1, 'F'],\n",
       " [15, 2, 'A'],\n",
       " [15, 2, 'B'],\n",
       " [15, 2, 'C'],\n",
       " [15, 2, 'D'],\n",
       " [15, 2, 'E'],\n",
       " [15, 2, 'F'],\n",
       " [15, 3, 'A'],\n",
       " [15, 3, 'B'],\n",
       " [15, 3, 'D'],\n",
       " [15, 3, 'E'],\n",
       " [15, 3, 'F'],\n",
       " [15, 4, 'A'],\n",
       " [15, 4, 'B'],\n",
       " [15, 4, 'C'],\n",
       " [15, 4, 'D'],\n",
       " [15, 4, 'E'],\n",
       " [15, 4, 'F'],\n",
       " [15, 5, 'A'],\n",
       " [15, 5, 'B'],\n",
       " [15, 5, 'C'],\n",
       " [15, 5, 'D'],\n",
       " [15, 5, 'E'],\n",
       " [15, 5, 'F'],\n",
       " [16, 1, 'A'],\n",
       " [16, 1, 'B'],\n",
       " [16, 1, 'C'],\n",
       " [16, 1, 'D'],\n",
       " [16, 1, 'E'],\n",
       " [16, 1, 'F'],\n",
       " [16, 2, 'A'],\n",
       " [16, 2, 'B'],\n",
       " [16, 2, 'C'],\n",
       " [16, 2, 'D'],\n",
       " [16, 2, 'E'],\n",
       " [16, 2, 'F'],\n",
       " [16, 3, 'A'],\n",
       " [16, 3, 'B'],\n",
       " [16, 3, 'C'],\n",
       " [16, 3, 'D'],\n",
       " [16, 3, 'E'],\n",
       " [16, 3, 'F'],\n",
       " [16, 4, 'A'],\n",
       " [16, 4, 'B'],\n",
       " [16, 4, 'C'],\n",
       " [16, 4, 'D'],\n",
       " [16, 4, 'E'],\n",
       " [16, 4, 'F'],\n",
       " [16, 5, 'A'],\n",
       " [16, 5, 'B'],\n",
       " [16, 5, 'C'],\n",
       " [16, 5, 'D'],\n",
       " [16, 5, 'E'],\n",
       " [16, 5, 'F'],\n",
       " [17, 1, 'A'],\n",
       " [17, 1, 'B'],\n",
       " [17, 1, 'C'],\n",
       " [17, 1, 'D'],\n",
       " [17, 1, 'E'],\n",
       " [17, 1, 'F'],\n",
       " [17, 2, 'A'],\n",
       " [17, 2, 'B'],\n",
       " [17, 2, 'C'],\n",
       " [17, 2, 'D'],\n",
       " [17, 2, 'E'],\n",
       " [17, 2, 'F'],\n",
       " [17, 3, 'A'],\n",
       " [17, 3, 'B'],\n",
       " [17, 3, 'C'],\n",
       " [17, 3, 'D'],\n",
       " [17, 3, 'E'],\n",
       " [17, 3, 'F'],\n",
       " [17, 4, 'A'],\n",
       " [17, 4, 'B'],\n",
       " [17, 4, 'C'],\n",
       " [17, 4, 'D'],\n",
       " [17, 4, 'E'],\n",
       " [17, 5, 'A'],\n",
       " [17, 5, 'B'],\n",
       " [17, 5, 'C'],\n",
       " [17, 5, 'D'],\n",
       " [17, 5, 'E'],\n",
       " [18, 1, 'A'],\n",
       " [18, 1, 'B'],\n",
       " [18, 1, 'C'],\n",
       " [18, 1, 'D'],\n",
       " [18, 1, 'E'],\n",
       " [18, 1, 'F'],\n",
       " [18, 2, 'A'],\n",
       " [18, 2, 'B'],\n",
       " [18, 2, 'C'],\n",
       " [18, 2, 'D'],\n",
       " [18, 2, 'E'],\n",
       " [18, 2, 'F'],\n",
       " [18, 3, 'A'],\n",
       " [18, 3, 'B'],\n",
       " [18, 3, 'C'],\n",
       " [18, 3, 'D'],\n",
       " [18, 3, 'E'],\n",
       " [18, 3, 'F'],\n",
       " [18, 4, 'A'],\n",
       " [18, 4, 'B'],\n",
       " [18, 4, 'C'],\n",
       " [18, 4, 'E'],\n",
       " [18, 4, 'F'],\n",
       " [18, 5, 'A'],\n",
       " [18, 5, 'B'],\n",
       " [18, 5, 'C'],\n",
       " [18, 5, 'E'],\n",
       " [18, 5, 'F'],\n",
       " [19, 1, 'A'],\n",
       " [19, 1, 'D'],\n",
       " [19, 1, 'F'],\n",
       " [19, 2, 'A'],\n",
       " [19, 2, 'B'],\n",
       " [19, 2, 'D'],\n",
       " [19, 2, 'E'],\n",
       " [19, 2, 'F'],\n",
       " [19, 3, 'A'],\n",
       " [19, 3, 'D'],\n",
       " [19, 3, 'E'],\n",
       " [19, 3, 'F'],\n",
       " [19, 4, 'A'],\n",
       " [19, 4, 'C'],\n",
       " [19, 4, 'D'],\n",
       " [19, 4, 'E'],\n",
       " [19, 4, 'F'],\n",
       " [19, 5, 'A'],\n",
       " [19, 5, 'B'],\n",
       " [19, 5, 'C'],\n",
       " [19, 5, 'D'],\n",
       " [19, 5, 'E'],\n",
       " [19, 5, 'F'],\n",
       " [20, 1, 'A'],\n",
       " [20, 1, 'B'],\n",
       " [20, 1, 'C'],\n",
       " [20, 1, 'D'],\n",
       " [20, 1, 'E'],\n",
       " [20, 1, 'F'],\n",
       " [20, 2, 'A'],\n",
       " [20, 2, 'B'],\n",
       " [20, 2, 'D'],\n",
       " [20, 2, 'E'],\n",
       " [20, 2, 'F'],\n",
       " [20, 3, 'A'],\n",
       " [20, 3, 'B'],\n",
       " [20, 3, 'D'],\n",
       " [20, 3, 'E'],\n",
       " [20, 3, 'F'],\n",
       " [20, 4, 'A'],\n",
       " [20, 4, 'B'],\n",
       " [20, 4, 'C'],\n",
       " [20, 4, 'D'],\n",
       " [20, 4, 'E'],\n",
       " [20, 4, 'F'],\n",
       " [20, 5, 'A'],\n",
       " [20, 5, 'B'],\n",
       " [20, 5, 'D'],\n",
       " [20, 5, 'E'],\n",
       " [20, 5, 'F'],\n",
       " [21, 1, 'A'],\n",
       " [21, 1, 'B'],\n",
       " [21, 1, 'C'],\n",
       " [21, 1, 'D'],\n",
       " [21, 1, 'E'],\n",
       " [21, 1, 'F'],\n",
       " [21, 2, 'A'],\n",
       " [21, 2, 'B'],\n",
       " [21, 2, 'C'],\n",
       " [21, 2, 'D'],\n",
       " [21, 2, 'E'],\n",
       " [21, 2, 'F'],\n",
       " [21, 3, 'A'],\n",
       " [21, 3, 'B'],\n",
       " [21, 3, 'C'],\n",
       " [21, 3, 'D'],\n",
       " [21, 3, 'E'],\n",
       " [21, 3, 'F'],\n",
       " [21, 4, 'A'],\n",
       " [21, 4, 'B'],\n",
       " [21, 4, 'C'],\n",
       " [21, 4, 'D'],\n",
       " [21, 4, 'E'],\n",
       " [21, 4, 'F'],\n",
       " [21, 5, 'A'],\n",
       " [21, 5, 'B'],\n",
       " [21, 5, 'C'],\n",
       " [21, 5, 'D'],\n",
       " [21, 5, 'E'],\n",
       " [21, 5, 'F'],\n",
       " [22, 1, 'C'],\n",
       " [22, 1, 'E'],\n",
       " [22, 2, 'A'],\n",
       " [22, 2, 'C'],\n",
       " [22, 2, 'D'],\n",
       " [22, 3, 'C'],\n",
       " [22, 4, 'B'],\n",
       " [22, 4, 'F'],\n",
       " [22, 5, 'D'],\n",
       " [22, 5, 'F'],\n",
       " [23, 1, 'A'],\n",
       " [23, 1, 'C'],\n",
       " [23, 1, 'D'],\n",
       " [23, 2, 'A'],\n",
       " [23, 2, 'B'],\n",
       " [23, 2, 'C'],\n",
       " [23, 2, 'D'],\n",
       " [23, 3, 'A'],\n",
       " [23, 3, 'B'],\n",
       " [23, 3, 'C'],\n",
       " [23, 3, 'D'],\n",
       " [23, 4, 'C'],\n",
       " [23, 4, 'D'],\n",
       " [24, 1, 'A'],\n",
       " [24, 1, 'B'],\n",
       " [24, 1, 'C'],\n",
       " [24, 1, 'D'],\n",
       " [24, 2, 'A'],\n",
       " [24, 2, 'B'],\n",
       " [24, 2, 'D'],\n",
       " [24, 3, 'A'],\n",
       " [24, 3, 'B'],\n",
       " [24, 3, 'C'],\n",
       " [24, 3, 'D'],\n",
       " [24, 4, 'A'],\n",
       " [24, 4, 'B'],\n",
       " [24, 4, 'C'],\n",
       " [24, 4, 'D'],\n",
       " [25, 1, 'A'],\n",
       " [25, 1, 'B'],\n",
       " [25, 1, 'C'],\n",
       " [25, 1, 'D'],\n",
       " [25, 2, 'A'],\n",
       " [25, 2, 'B'],\n",
       " [25, 2, 'C'],\n",
       " [25, 2, 'D'],\n",
       " [25, 3, 'A'],\n",
       " [25, 3, 'B'],\n",
       " [25, 3, 'C'],\n",
       " [25, 3, 'D'],\n",
       " [25, 4, 'A'],\n",
       " [25, 4, 'B'],\n",
       " [25, 4, 'C'],\n",
       " [25, 4, 'D'],\n",
       " [26, 1, 'A'],\n",
       " [26, 1, 'B'],\n",
       " [26, 1, 'C'],\n",
       " [26, 1, 'D'],\n",
       " [26, 2, 'A'],\n",
       " [26, 2, 'B'],\n",
       " [26, 2, 'C'],\n",
       " [26, 2, 'D'],\n",
       " [26, 3, 'A'],\n",
       " [26, 3, 'B'],\n",
       " [26, 3, 'C'],\n",
       " [26, 3, 'D'],\n",
       " [26, 4, 'A'],\n",
       " [26, 4, 'B'],\n",
       " [26, 4, 'C'],\n",
       " [26, 4, 'D'],\n",
       " [27, 1, 'A'],\n",
       " [27, 1, 'B'],\n",
       " [27, 1, 'C'],\n",
       " [27, 1, 'D'],\n",
       " [27, 2, 'A'],\n",
       " [27, 2, 'B'],\n",
       " [27, 2, 'C'],\n",
       " [27, 2, 'D'],\n",
       " [27, 3, 'A'],\n",
       " [27, 3, 'B'],\n",
       " [27, 3, 'C'],\n",
       " [27, 3, 'D'],\n",
       " [27, 4, 'A'],\n",
       " [27, 4, 'B'],\n",
       " [27, 4, 'D'],\n",
       " [28, 1, 'A'],\n",
       " [28, 1, 'B'],\n",
       " [28, 1, 'C'],\n",
       " [28, 1, 'D'],\n",
       " [28, 2, 'A'],\n",
       " [28, 2, 'B'],\n",
       " [28, 2, 'C'],\n",
       " [28, 2, 'D'],\n",
       " [28, 3, 'A'],\n",
       " [28, 3, 'B'],\n",
       " [28, 3, 'C'],\n",
       " [28, 3, 'D'],\n",
       " [28, 4, 'A'],\n",
       " [28, 4, 'B'],\n",
       " [28, 4, 'C'],\n",
       " [28, 4, 'D'],\n",
       " [29, 1, 'A'],\n",
       " [29, 1, 'B'],\n",
       " [29, 1, 'C'],\n",
       " [29, 1, 'D'],\n",
       " [29, 2, 'A'],\n",
       " [29, 2, 'B'],\n",
       " [29, 2, 'C'],\n",
       " [29, 2, 'D'],\n",
       " [29, 3, 'A'],\n",
       " [29, 3, 'B'],\n",
       " [29, 3, 'C'],\n",
       " [29, 3, 'D'],\n",
       " [29, 4, 'A'],\n",
       " [29, 4, 'B'],\n",
       " [29, 4, 'C'],\n",
       " [29, 4, 'D'],\n",
       " [30, 1, 'A'],\n",
       " [30, 1, 'B'],\n",
       " [30, 1, 'C'],\n",
       " [30, 1, 'D'],\n",
       " [30, 2, 'A'],\n",
       " [30, 2, 'B'],\n",
       " [30, 2, 'C'],\n",
       " [30, 2, 'D'],\n",
       " [30, 3, 'A'],\n",
       " [30, 3, 'B'],\n",
       " [30, 3, 'C'],\n",
       " [30, 3, 'D'],\n",
       " [30, 4, 'A'],\n",
       " [30, 4, 'B'],\n",
       " [30, 4, 'C'],\n",
       " [30, 4, 'D'],\n",
       " [31, 1, 'A'],\n",
       " [31, 1, 'D'],\n",
       " [31, 2, 'B'],\n",
       " [31, 2, 'C'],\n",
       " [31, 2, 'D'],\n",
       " [31, 3, 'B'],\n",
       " [31, 3, 'D'],\n",
       " [31, 4, 'B'],\n",
       " [31, 4, 'C'],\n",
       " [31, 4, 'D'],\n",
       " [32, 1, 'A'],\n",
       " [32, 1, 'B'],\n",
       " [32, 1, 'C'],\n",
       " [32, 1, 'D'],\n",
       " [32, 2, 'A'],\n",
       " [32, 2, 'B'],\n",
       " [32, 2, 'C'],\n",
       " [32, 2, 'D'],\n",
       " [32, 3, 'A'],\n",
       " [32, 3, 'B'],\n",
       " [32, 3, 'C'],\n",
       " [32, 3, 'D'],\n",
       " [32, 4, 'A'],\n",
       " [32, 4, 'B'],\n",
       " [32, 4, 'C'],\n",
       " [32, 4, 'D'],\n",
       " [33, 1, 'B'],\n",
       " [33, 1, 'C'],\n",
       " [33, 1, 'D'],\n",
       " [33, 2, 'B'],\n",
       " [33, 2, 'C'],\n",
       " [33, 2, 'D'],\n",
       " [33, 3, 'A'],\n",
       " [33, 3, 'B'],\n",
       " [33, 3, 'C'],\n",
       " [33, 3, 'D'],\n",
       " [33, 4, 'A'],\n",
       " [33, 4, 'B'],\n",
       " [33, 4, 'C'],\n",
       " [33, 4, 'D'],\n",
       " [34, 1, 'A'],\n",
       " [34, 1, 'B'],\n",
       " [34, 1, 'C'],\n",
       " [34, 1, 'D'],\n",
       " [34, 2, 'B'],\n",
       " [34, 2, 'C'],\n",
       " [34, 2, 'D'],\n",
       " [34, 3, 'A'],\n",
       " [34, 3, 'B'],\n",
       " [34, 3, 'C'],\n",
       " [34, 3, 'D'],\n",
       " [34, 4, 'A'],\n",
       " [34, 4, 'B'],\n",
       " [34, 4, 'C'],\n",
       " [34, 4, 'D'],\n",
       " [35, 1, 'A'],\n",
       " [35, 1, 'B'],\n",
       " [35, 1, 'C'],\n",
       " [35, 1, 'D'],\n",
       " [35, 2, 'A'],\n",
       " [35, 2, 'B'],\n",
       " [35, 2, 'C'],\n",
       " [35, 2, 'D'],\n",
       " [35, 3, 'A'],\n",
       " [35, 3, 'B'],\n",
       " [35, 3, 'C'],\n",
       " [35, 3, 'D'],\n",
       " [35, 4, 'A'],\n",
       " [35, 4, 'B'],\n",
       " [35, 4, 'C'],\n",
       " [35, 4, 'D'],\n",
       " [36, 1, 'A'],\n",
       " [36, 1, 'B'],\n",
       " [36, 1, 'C'],\n",
       " [36, 1, 'D'],\n",
       " [36, 2, 'A'],\n",
       " [36, 2, 'B'],\n",
       " [36, 2, 'C'],\n",
       " [36, 2, 'D'],\n",
       " [36, 3, 'A'],\n",
       " [36, 3, 'B'],\n",
       " [36, 3, 'C'],\n",
       " [36, 3, 'D'],\n",
       " [36, 4, 'A'],\n",
       " [36, 4, 'B'],\n",
       " [36, 4, 'C'],\n",
       " [36, 4, 'D'],\n",
       " [37, 1, 'A'],\n",
       " [37, 1, 'B'],\n",
       " [37, 1, 'C'],\n",
       " [37, 1, 'D'],\n",
       " [37, 2, 'A'],\n",
       " [37, 2, 'B'],\n",
       " [37, 2, 'C'],\n",
       " [37, 2, 'D'],\n",
       " [37, 3, 'A'],\n",
       " [37, 3, 'B'],\n",
       " [37, 3, 'C'],\n",
       " [37, 3, 'D'],\n",
       " [37, 4, 'A'],\n",
       " [37, 4, 'B'],\n",
       " [37, 4, 'C'],\n",
       " [37, 4, 'D'],\n",
       " [38, 1, 'A'],\n",
       " [38, 1, 'C'],\n",
       " [38, 1, 'D'],\n",
       " [38, 2, 'A'],\n",
       " [38, 2, 'B'],\n",
       " [38, 2, 'C'],\n",
       " [38, 2, 'D'],\n",
       " [38, 3, 'A'],\n",
       " [38, 3, 'C'],\n",
       " [38, 3, 'D'],\n",
       " [38, 4, 'A'],\n",
       " [38, 4, 'B'],\n",
       " [38, 4, 'C'],\n",
       " [38, 4, 'D'],\n",
       " [39, 1, 'A'],\n",
       " [39, 1, 'B'],\n",
       " [39, 1, 'C'],\n",
       " [39, 1, 'D'],\n",
       " [39, 2, 'A'],\n",
       " [39, 2, 'B'],\n",
       " [39, 2, 'C'],\n",
       " [39, 2, 'D'],\n",
       " [39, 3, 'A'],\n",
       " [39, 3, 'B'],\n",
       " [39, 3, 'C'],\n",
       " [39, 3, 'D'],\n",
       " [39, 4, 'A'],\n",
       " [39, 4, 'B'],\n",
       " [39, 4, 'C'],\n",
       " [39, 4, 'D'],\n",
       " [40, 1, 'A'],\n",
       " [40, 1, 'B'],\n",
       " [40, 1, 'C'],\n",
       " [40, 1, 'D'],\n",
       " [40, 2, 'A'],\n",
       " [40, 2, 'B'],\n",
       " [40, 2, 'C'],\n",
       " [40, 2, 'D'],\n",
       " [40, 3, 'A'],\n",
       " [40, 3, 'B'],\n",
       " [40, 3, 'C'],\n",
       " [40, 3, 'D'],\n",
       " [40, 4, 'A'],\n",
       " [40, 4, 'B'],\n",
       " [40, 4, 'C'],\n",
       " [40, 4, 'D'],\n",
       " [41, 1, 'A'],\n",
       " [41, 1, 'B'],\n",
       " [41, 1, 'C'],\n",
       " [41, 1, 'D'],\n",
       " [41, 2, 'A'],\n",
       " [41, 2, 'C'],\n",
       " [41, 2, 'D'],\n",
       " [41, 3, 'A'],\n",
       " [41, 3, 'C'],\n",
       " [41, 3, 'D'],\n",
       " [41, 4, 'A'],\n",
       " [41, 4, 'C'],\n",
       " [41, 4, 'D'],\n",
       " [42, 1, 'A'],\n",
       " [42, 1, 'B'],\n",
       " [42, 1, 'C'],\n",
       " [42, 1, 'D'],\n",
       " [42, 2, 'A'],\n",
       " [42, 2, 'B'],\n",
       " [42, 2, 'C'],\n",
       " [42, 2, 'D'],\n",
       " [42, 3, 'A'],\n",
       " [42, 3, 'B'],\n",
       " [42, 3, 'C'],\n",
       " [42, 3, 'D'],\n",
       " [42, 4, 'A'],\n",
       " [42, 4, 'B'],\n",
       " [42, 4, 'C'],\n",
       " [42, 4, 'D'],\n",
       " [43, 1, 'A'],\n",
       " [43, 1, 'C'],\n",
       " [43, 1, 'D'],\n",
       " [43, 1, 'E'],\n",
       " [43, 1, 'F'],\n",
       " [43, 2, 'A'],\n",
       " [43, 2, 'B'],\n",
       " [43, 2, 'C'],\n",
       " [43, 2, 'D'],\n",
       " [43, 2, 'E'],\n",
       " [43, 2, 'F'],\n",
       " [43, 3, 'A'],\n",
       " [43, 3, 'B'],\n",
       " [43, 3, 'C'],\n",
       " [43, 3, 'D'],\n",
       " [43, 3, 'E'],\n",
       " [43, 3, 'F'],\n",
       " [43, 4, 'A'],\n",
       " [43, 4, 'C'],\n",
       " [43, 4, 'D'],\n",
       " [43, 4, 'E'],\n",
       " [43, 5, 'A'],\n",
       " [43, 5, 'B'],\n",
       " [43, 5, 'C'],\n",
       " [43, 5, 'E'],\n",
       " [43, 5, 'F'],\n",
       " [44, 1, 'A'],\n",
       " [44, 1, 'D'],\n",
       " [44, 1, 'E'],\n",
       " [44, 1, 'F'],\n",
       " [44, 2, 'A'],\n",
       " [44, 2, 'B'],\n",
       " [44, 2, 'C'],\n",
       " [44, 2, 'D'],\n",
       " [44, 2, 'E'],\n",
       " [44, 2, 'F'],\n",
       " [44, 3, 'A'],\n",
       " [44, 3, 'B'],\n",
       " [44, 3, 'C'],\n",
       " [44, 3, 'D'],\n",
       " [44, 3, 'E'],\n",
       " [44, 3, 'F'],\n",
       " [44, 4, 'A'],\n",
       " [44, 4, 'B'],\n",
       " [44, 4, 'C'],\n",
       " [44, 4, 'D'],\n",
       " [44, 4, 'E'],\n",
       " [44, 4, 'F'],\n",
       " [44, 5, 'B'],\n",
       " [44, 5, 'C'],\n",
       " [44, 5, 'D'],\n",
       " [44, 5, 'E'],\n",
       " [44, 5, 'F'],\n",
       " [45, 1, 'A'],\n",
       " [45, 1, 'C'],\n",
       " [45, 1, 'F'],\n",
       " [45, 2, 'A'],\n",
       " [45, 2, 'D'],\n",
       " [45, 2, 'E'],\n",
       " [45, 2, 'F'],\n",
       " [45, 3, 'A'],\n",
       " [45, 3, 'D'],\n",
       " [45, 3, 'E'],\n",
       " [45, 3, 'F'],\n",
       " [45, 4, 'A'],\n",
       " [45, 4, 'C'],\n",
       " [45, 4, 'D'],\n",
       " [45, 4, 'E'],\n",
       " [45, 4, 'F'],\n",
       " [45, 5, 'A'],\n",
       " [45, 5, 'B'],\n",
       " [45, 5, 'C'],\n",
       " [45, 5, 'D'],\n",
       " [45, 5, 'E'],\n",
       " [45, 5, 'F'],\n",
       " [46, 1, 'A'],\n",
       " [46, 1, 'B'],\n",
       " [46, 1, 'C'],\n",
       " [46, 1, 'D'],\n",
       " [46, 1, 'E'],\n",
       " [46, 1, 'F'],\n",
       " [46, 2, 'A'],\n",
       " [46, 2, 'B'],\n",
       " [46, 2, 'C'],\n",
       " [46, 2, 'D'],\n",
       " [46, 2, 'E'],\n",
       " [46, 2, 'F'],\n",
       " [46, 3, 'A'],\n",
       " [46, 3, 'D'],\n",
       " [46, 3, 'F'],\n",
       " [46, 4, 'A'],\n",
       " [46, 4, 'B'],\n",
       " [46, 4, 'D'],\n",
       " [46, 4, 'E'],\n",
       " [46, 4, 'F'],\n",
       " [46, 5, 'A'],\n",
       " [46, 5, 'B'],\n",
       " [46, 5, 'C'],\n",
       " [46, 5, 'D'],\n",
       " [46, 5, 'F'],\n",
       " [47, 1, 'A'],\n",
       " [47, 1, 'C'],\n",
       " [47, 1, 'D'],\n",
       " [47, 1, 'E'],\n",
       " [47, 1, 'F'],\n",
       " [47, 2, 'A'],\n",
       " [47, 2, 'C'],\n",
       " [47, 2, 'D'],\n",
       " [47, 2, 'E'],\n",
       " [47, 2, 'F'],\n",
       " [47, 3, 'B'],\n",
       " [47, 3, 'C'],\n",
       " [47, 3, 'D'],\n",
       " [47, 3, 'E'],\n",
       " [47, 3, 'F'],\n",
       " [47, 4, 'C'],\n",
       " [47, 4, 'D'],\n",
       " [47, 4, 'E'],\n",
       " [47, 4, 'F'],\n",
       " [47, 5, 'A'],\n",
       " [47, 5, 'C'],\n",
       " [47, 5, 'D'],\n",
       " [47, 5, 'E'],\n",
       " [47, 5, 'F'],\n",
       " [48, 1, 'A'],\n",
       " [48, 1, 'B'],\n",
       " [48, 1, 'C'],\n",
       " [48, 1, 'D'],\n",
       " [48, 1, 'F'],\n",
       " [48, 2, 'A'],\n",
       " [48, 2, 'B'],\n",
       " [48, 2, 'C'],\n",
       " [48, 2, 'D'],\n",
       " [48, 2, 'F'],\n",
       " [48, 3, 'A'],\n",
       " [48, 3, 'B'],\n",
       " [48, 3, 'C'],\n",
       " [48, 3, 'D'],\n",
       " [48, 3, 'E'],\n",
       " [48, 3, 'F'],\n",
       " [48, 4, 'B'],\n",
       " [48, 4, 'D'],\n",
       " [48, 4, 'E'],\n",
       " [48, 5, 'A'],\n",
       " [48, 5, 'B'],\n",
       " [48, 5, 'C'],\n",
       " [48, 5, 'D'],\n",
       " [48, 5, 'E'],\n",
       " [48, 5, 'F'],\n",
       " [49, 1, 'A'],\n",
       " [49, 1, 'B'],\n",
       " [49, 1, 'D'],\n",
       " [49, 1, 'E'],\n",
       " [49, 1, 'F'],\n",
       " [49, 2, 'A'],\n",
       " [49, 2, 'B'],\n",
       " [49, 2, 'C'],\n",
       " [49, 2, 'D'],\n",
       " [49, 2, 'E'],\n",
       " [49, 2, 'F'],\n",
       " [49, 3, 'A'],\n",
       " [49, 3, 'B'],\n",
       " ...]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = 1\n",
    "question = 1\n",
    "tmp_count = 0\n",
    "answer_count = []\n",
    "\n",
    "for i in range(len(answer)):\n",
    "  if (answer[i][0] == doc and answer[i][1] == question):\n",
    "    tmp_count += 1\n",
    "  else:\n",
    "    answer_count.append([doc, question, tmp_count])\n",
    "    doc = answer[i][0]\n",
    "    question = answer[i][1]\n",
    "    tmp_count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 5],\n",
       " [1, 2, 5],\n",
       " [1, 3, 5],\n",
       " [1, 4, 5],\n",
       " [1, 5, 5],\n",
       " [2, 1, 5],\n",
       " [2, 2, 5],\n",
       " [2, 3, 5],\n",
       " [2, 4, 5],\n",
       " [2, 5, 3],\n",
       " [3, 1, 6],\n",
       " [3, 2, 5],\n",
       " [3, 3, 5],\n",
       " [3, 4, 5],\n",
       " [3, 5, 5],\n",
       " [4, 1, 3],\n",
       " [4, 2, 2],\n",
       " [4, 3, 4],\n",
       " [4, 4, 4],\n",
       " [4, 5, 5],\n",
       " [5, 1, 4],\n",
       " [5, 2, 4],\n",
       " [5, 3, 4],\n",
       " [5, 4, 5],\n",
       " [5, 5, 5],\n",
       " [6, 1, 4],\n",
       " [6, 2, 5],\n",
       " [6, 3, 3],\n",
       " [6, 4, 4],\n",
       " [6, 5, 5],\n",
       " [7, 1, 5],\n",
       " [7, 2, 5],\n",
       " [7, 3, 5],\n",
       " [7, 4, 5],\n",
       " [7, 5, 5],\n",
       " [8, 1, 5],\n",
       " [8, 2, 5],\n",
       " [8, 3, 5],\n",
       " [8, 4, 4],\n",
       " [8, 5, 4],\n",
       " [9, 1, 5],\n",
       " [9, 2, 5],\n",
       " [9, 3, 4],\n",
       " [9, 4, 5],\n",
       " [9, 5, 4],\n",
       " [10, 1, 2],\n",
       " [10, 2, 4],\n",
       " [10, 3, 4],\n",
       " [10, 4, 5],\n",
       " [10, 5, 5],\n",
       " [11, 1, 5],\n",
       " [11, 2, 6],\n",
       " [11, 3, 6],\n",
       " [11, 4, 6],\n",
       " [11, 5, 6],\n",
       " [12, 1, 6],\n",
       " [12, 2, 6],\n",
       " [12, 3, 6],\n",
       " [12, 4, 6],\n",
       " [12, 5, 6],\n",
       " [13, 1, 5],\n",
       " [13, 2, 3],\n",
       " [13, 3, 5],\n",
       " [13, 4, 5],\n",
       " [13, 5, 3],\n",
       " [14, 1, 5],\n",
       " [14, 2, 5],\n",
       " [14, 3, 5],\n",
       " [14, 4, 6],\n",
       " [14, 5, 5],\n",
       " [15, 1, 6],\n",
       " [15, 2, 6],\n",
       " [15, 3, 5],\n",
       " [15, 4, 6],\n",
       " [15, 5, 6],\n",
       " [16, 1, 6],\n",
       " [16, 2, 6],\n",
       " [16, 3, 6],\n",
       " [16, 4, 6],\n",
       " [16, 5, 6],\n",
       " [17, 1, 6],\n",
       " [17, 2, 6],\n",
       " [17, 3, 6],\n",
       " [17, 4, 5],\n",
       " [17, 5, 5],\n",
       " [18, 1, 6],\n",
       " [18, 2, 6],\n",
       " [18, 3, 6],\n",
       " [18, 4, 5],\n",
       " [18, 5, 5],\n",
       " [19, 1, 3],\n",
       " [19, 2, 5],\n",
       " [19, 3, 4],\n",
       " [19, 4, 5],\n",
       " [19, 5, 6],\n",
       " [20, 1, 6],\n",
       " [20, 2, 5],\n",
       " [20, 3, 5],\n",
       " [20, 4, 6],\n",
       " [20, 5, 5],\n",
       " [21, 1, 6],\n",
       " [21, 2, 6],\n",
       " [21, 3, 6],\n",
       " [21, 4, 6],\n",
       " [21, 5, 6],\n",
       " [22, 1, 2],\n",
       " [22, 2, 3],\n",
       " [22, 3, 1],\n",
       " [22, 4, 2],\n",
       " [22, 5, 2],\n",
       " [23, 1, 3],\n",
       " [23, 2, 4],\n",
       " [23, 3, 4],\n",
       " [23, 4, 2],\n",
       " [24, 1, 4],\n",
       " [24, 2, 3],\n",
       " [24, 3, 4],\n",
       " [24, 4, 4],\n",
       " [25, 1, 4],\n",
       " [25, 2, 4],\n",
       " [25, 3, 4],\n",
       " [25, 4, 4],\n",
       " [26, 1, 4],\n",
       " [26, 2, 4],\n",
       " [26, 3, 4],\n",
       " [26, 4, 4],\n",
       " [27, 1, 4],\n",
       " [27, 2, 4],\n",
       " [27, 3, 4],\n",
       " [27, 4, 3],\n",
       " [28, 1, 4],\n",
       " [28, 2, 4],\n",
       " [28, 3, 4],\n",
       " [28, 4, 4],\n",
       " [29, 1, 4],\n",
       " [29, 2, 4],\n",
       " [29, 3, 4],\n",
       " [29, 4, 4],\n",
       " [30, 1, 4],\n",
       " [30, 2, 4],\n",
       " [30, 3, 4],\n",
       " [30, 4, 4],\n",
       " [31, 1, 2],\n",
       " [31, 2, 3],\n",
       " [31, 3, 2],\n",
       " [31, 4, 3],\n",
       " [32, 1, 4],\n",
       " [32, 2, 4],\n",
       " [32, 3, 4],\n",
       " [32, 4, 4],\n",
       " [33, 1, 3],\n",
       " [33, 2, 3],\n",
       " [33, 3, 4],\n",
       " [33, 4, 4],\n",
       " [34, 1, 4],\n",
       " [34, 2, 3],\n",
       " [34, 3, 4],\n",
       " [34, 4, 4],\n",
       " [35, 1, 4],\n",
       " [35, 2, 4],\n",
       " [35, 3, 4],\n",
       " [35, 4, 4],\n",
       " [36, 1, 4],\n",
       " [36, 2, 4],\n",
       " [36, 3, 4],\n",
       " [36, 4, 4],\n",
       " [37, 1, 4],\n",
       " [37, 2, 4],\n",
       " [37, 3, 4],\n",
       " [37, 4, 4],\n",
       " [38, 1, 3],\n",
       " [38, 2, 4],\n",
       " [38, 3, 3],\n",
       " [38, 4, 4],\n",
       " [39, 1, 4],\n",
       " [39, 2, 4],\n",
       " [39, 3, 4],\n",
       " [39, 4, 4],\n",
       " [40, 1, 4],\n",
       " [40, 2, 4],\n",
       " [40, 3, 4],\n",
       " [40, 4, 4],\n",
       " [41, 1, 4],\n",
       " [41, 2, 3],\n",
       " [41, 3, 3],\n",
       " [41, 4, 3],\n",
       " [42, 1, 4],\n",
       " [42, 2, 4],\n",
       " [42, 3, 4],\n",
       " [42, 4, 4],\n",
       " [43, 1, 5],\n",
       " [43, 2, 6],\n",
       " [43, 3, 6],\n",
       " [43, 4, 4],\n",
       " [43, 5, 5],\n",
       " [44, 1, 4],\n",
       " [44, 2, 6],\n",
       " [44, 3, 6],\n",
       " [44, 4, 6],\n",
       " [44, 5, 5],\n",
       " [45, 1, 3],\n",
       " [45, 2, 4],\n",
       " [45, 3, 4],\n",
       " [45, 4, 5],\n",
       " [45, 5, 6],\n",
       " [46, 1, 6],\n",
       " [46, 2, 6],\n",
       " [46, 3, 3],\n",
       " [46, 4, 5],\n",
       " [46, 5, 5],\n",
       " [47, 1, 5],\n",
       " [47, 2, 5],\n",
       " [47, 3, 5],\n",
       " [47, 4, 4],\n",
       " [47, 5, 5],\n",
       " [48, 1, 5],\n",
       " [48, 2, 5],\n",
       " [48, 3, 6],\n",
       " [48, 4, 3],\n",
       " [48, 5, 6],\n",
       " [49, 1, 5],\n",
       " [49, 2, 6],\n",
       " [49, 3, 6],\n",
       " [49, 4, 3],\n",
       " [49, 5, 4],\n",
       " [50, 1, 3],\n",
       " [50, 2, 5],\n",
       " [50, 3, 5],\n",
       " [50, 4, 6],\n",
       " [50, 5, 1],\n",
       " [51, 1, 3],\n",
       " [51, 2, 5],\n",
       " [51, 3, 6],\n",
       " [51, 4, 5],\n",
       " [51, 5, 5],\n",
       " [52, 1, 4],\n",
       " [52, 2, 2],\n",
       " [52, 3, 2],\n",
       " [52, 4, 5],\n",
       " [52, 5, 5],\n",
       " [53, 1, 5],\n",
       " [53, 2, 5],\n",
       " [53, 3, 2],\n",
       " [53, 4, 2],\n",
       " [53, 5, 5],\n",
       " [54, 1, 6],\n",
       " [54, 2, 6],\n",
       " [54, 3, 6],\n",
       " [54, 4, 5],\n",
       " [54, 5, 5],\n",
       " [55, 1, 6],\n",
       " [55, 2, 4],\n",
       " [55, 3, 5],\n",
       " [55, 4, 6],\n",
       " [55, 5, 6],\n",
       " [56, 1, 5],\n",
       " [56, 2, 6],\n",
       " [56, 3, 6],\n",
       " [56, 4, 6],\n",
       " [56, 5, 6],\n",
       " [57, 1, 6],\n",
       " [57, 2, 5],\n",
       " [57, 3, 5],\n",
       " [57, 4, 6],\n",
       " [57, 5, 6],\n",
       " [58, 1, 6],\n",
       " [58, 2, 6],\n",
       " [58, 3, 6],\n",
       " [58, 4, 6],\n",
       " [58, 5, 5],\n",
       " [59, 1, 6],\n",
       " [59, 2, 6],\n",
       " [59, 3, 4],\n",
       " [59, 4, 4],\n",
       " [59, 5, 6],\n",
       " [60, 1, 6],\n",
       " [60, 2, 6],\n",
       " [60, 3, 5],\n",
       " [60, 4, 1],\n",
       " [60, 5, 1],\n",
       " [61, 1, 4],\n",
       " [61, 2, 3],\n",
       " [61, 3, 6],\n",
       " [61, 4, 6],\n",
       " [61, 5, 6],\n",
       " [62, 1, 3],\n",
       " [62, 2, 3],\n",
       " [62, 3, 4],\n",
       " [62, 4, 4],\n",
       " [62, 5, 5],\n",
       " [63, 1, 3],\n",
       " [63, 2, 4],\n",
       " [63, 3, 4],\n",
       " [63, 4, 4],\n",
       " [63, 5, 4],\n",
       " [64, 1, 5],\n",
       " [64, 2, 4],\n",
       " [64, 3, 6],\n",
       " [64, 4, 6],\n",
       " [64, 5, 4],\n",
       " [65, 1, 6],\n",
       " [65, 2, 6],\n",
       " [65, 3, 6],\n",
       " [65, 4, 6],\n",
       " [65, 5, 6],\n",
       " [66, 1, 6],\n",
       " [66, 2, 6],\n",
       " [66, 3, 6],\n",
       " [66, 4, 6],\n",
       " [66, 5, 6],\n",
       " [67, 1, 6],\n",
       " [67, 2, 4],\n",
       " [67, 3, 2],\n",
       " [67, 4, 4],\n",
       " [67, 5, 6],\n",
       " [68, 1, 5],\n",
       " [68, 2, 6],\n",
       " [68, 3, 5],\n",
       " [68, 4, 5],\n",
       " [68, 5, 5],\n",
       " [69, 1, 5],\n",
       " [69, 2, 5],\n",
       " [69, 3, 5],\n",
       " [69, 4, 5],\n",
       " [69, 5, 5],\n",
       " [70, 1, 6],\n",
       " [70, 2, 6],\n",
       " [70, 3, 6],\n",
       " [70, 4, 6],\n",
       " [70, 5, 6],\n",
       " [71, 1, 6],\n",
       " [71, 2, 6],\n",
       " [71, 3, 5],\n",
       " [71, 4, 5],\n",
       " [71, 5, 6],\n",
       " [72, 1, 3],\n",
       " [72, 2, 3],\n",
       " [72, 3, 3],\n",
       " [72, 4, 4],\n",
       " [72, 5, 4],\n",
       " [73, 1, 4],\n",
       " [73, 2, 6],\n",
       " [73, 3, 5],\n",
       " [73, 4, 5],\n",
       " [73, 5, 6],\n",
       " [74, 1, 6],\n",
       " [74, 2, 6],\n",
       " [74, 3, 6],\n",
       " [74, 4, 6],\n",
       " [74, 5, 6],\n",
       " [75, 1, 6],\n",
       " [75, 2, 5],\n",
       " [75, 3, 4],\n",
       " [75, 4, 5],\n",
       " [75, 5, 4],\n",
       " [76, 1, 6],\n",
       " [76, 2, 6],\n",
       " [76, 3, 6],\n",
       " [76, 4, 6],\n",
       " [76, 5, 6],\n",
       " [77, 1, 5],\n",
       " [77, 2, 5],\n",
       " [77, 3, 5],\n",
       " [77, 4, 6],\n",
       " [77, 5, 6],\n",
       " [78, 1, 6],\n",
       " [78, 2, 6],\n",
       " [78, 3, 5],\n",
       " [78, 4, 5],\n",
       " [78, 5, 3],\n",
       " [79, 1, 1],\n",
       " [79, 2, 6],\n",
       " [79, 3, 6],\n",
       " [79, 4, 5],\n",
       " [79, 5, 5],\n",
       " [80, 1, 6],\n",
       " [80, 2, 6],\n",
       " [80, 3, 6],\n",
       " [80, 4, 6],\n",
       " [80, 5, 6],\n",
       " [81, 1, 6],\n",
       " [81, 2, 6],\n",
       " [81, 3, 6],\n",
       " [81, 4, 6],\n",
       " [81, 5, 6],\n",
       " [82, 1, 5],\n",
       " [82, 2, 5],\n",
       " [82, 3, 6],\n",
       " [82, 4, 6],\n",
       " [82, 5, 5],\n",
       " [83, 1, 5],\n",
       " [83, 2, 5],\n",
       " [83, 3, 6],\n",
       " [83, 4, 5],\n",
       " [83, 5, 5],\n",
       " [84, 1, 6],\n",
       " [84, 2, 6],\n",
       " [84, 3, 6],\n",
       " [84, 4, 6],\n",
       " [84, 5, 1],\n",
       " [85, 1, 6],\n",
       " [85, 2, 6],\n",
       " [85, 3, 5],\n",
       " [85, 4, 5],\n",
       " [85, 5, 6],\n",
       " [86, 1, 6],\n",
       " [86, 2, 6],\n",
       " [86, 3, 6],\n",
       " [86, 4, 6],\n",
       " [86, 5, 6],\n",
       " [87, 1, 5],\n",
       " [87, 2, 5],\n",
       " [87, 3, 5],\n",
       " [87, 4, 5],\n",
       " [87, 5, 5],\n",
       " [88, 1, 5],\n",
       " [88, 2, 6],\n",
       " [88, 3, 3],\n",
       " [88, 4, 6],\n",
       " [88, 5, 6],\n",
       " [89, 1, 5],\n",
       " [89, 2, 5],\n",
       " [89, 3, 5],\n",
       " [89, 4, 5],\n",
       " [89, 5, 5],\n",
       " [90, 1, 5],\n",
       " [90, 2, 4],\n",
       " [90, 3, 4],\n",
       " [90, 4, 5],\n",
       " [90, 5, 5],\n",
       " [91, 1, 4],\n",
       " [91, 2, 4],\n",
       " [91, 3, 4],\n",
       " [91, 4, 5]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22, 3, 1]\n",
      "correct answer D\n",
      "our answer C\n",
      "[50, 5, 1]\n",
      "correct answer B\n",
      "our answer C\n",
      "[60, 4, 1]\n",
      "correct answer D\n",
      "our answer D\n",
      "[60, 5, 1]\n",
      "correct answer E\n",
      "our answer D\n",
      "[79, 1, 1]\n",
      "correct answer D\n",
      "our answer D\n",
      "[84, 5, 1]\n",
      "correct answer E\n",
      "our answer E\n",
      "[  0.   6.  13.  35. 109. 128. 143.]\n"
     ]
    }
   ],
   "source": [
    "answer_count_stat = np.zeros(7)\n",
    "\n",
    "for i in range(len(answer_count)):\n",
    "  answer_count_stat[answer_count[i][2]] += 1\n",
    "  if ((answer_count[i][2]) == 1):\n",
    "    print(answer_count[i])\n",
    "    print(\"correct answer\", ans_df.iloc[answer_count[i][0] - 1][answer_count[i][1]])\n",
    "    for j in range(len(answer)):\n",
    "      if (answer[j][0] == answer_count[i][0] and answer[j][1] == answer_count[i][1]):\n",
    "        print(\"our answer\", answer[j][2])\n",
    "        break\n",
    "\n",
    "print(answer_count_stat)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. BERT (NSP) using probability and considering both previous and next sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Finish Doc 1 ===\n",
      "=== Finish Doc 2 ===\n",
      "=== Finish Doc 3 ===\n",
      "=== Finish Doc 4 ===\n",
      "=== Finish Doc 5 ===\n",
      "=== Finish Doc 6 ===\n",
      "=== Finish Doc 7 ===\n",
      "=== Finish Doc 8 ===\n",
      "=== Finish Doc 9 ===\n",
      "=== Finish Doc 10 ===\n",
      "=== Finish Doc 11 ===\n",
      "=== Finish Doc 12 ===\n",
      "=== Finish Doc 13 ===\n",
      "=== Finish Doc 14 ===\n",
      "=== Finish Doc 15 ===\n",
      "=== Finish Doc 16 ===\n",
      "=== Finish Doc 17 ===\n",
      "=== Finish Doc 18 ===\n",
      "=== Finish Doc 19 ===\n",
      "=== Finish Doc 20 ===\n",
      "=== Finish Doc 21 ===\n",
      "=== Finish Doc 22 ===\n",
      "=== Finish Doc 23 ===\n",
      "=== Finish Doc 24 ===\n",
      "=== Finish Doc 25 ===\n",
      "=== Finish Doc 26 ===\n",
      "=== Finish Doc 27 ===\n",
      "=== Finish Doc 28 ===\n",
      "=== Finish Doc 29 ===\n",
      "=== Finish Doc 30 ===\n",
      "=== Finish Doc 31 ===\n",
      "=== Finish Doc 32 ===\n",
      "=== Finish Doc 33 ===\n",
      "=== Finish Doc 34 ===\n",
      "=== Finish Doc 35 ===\n",
      "=== Finish Doc 36 ===\n",
      "=== Finish Doc 37 ===\n",
      "=== Finish Doc 38 ===\n",
      "=== Finish Doc 39 ===\n",
      "=== Finish Doc 40 ===\n",
      "=== Finish Doc 41 ===\n",
      "=== Finish Doc 42 ===\n",
      "=== Finish Doc 43 ===\n",
      "=== Finish Doc 44 ===\n",
      "=== Finish Doc 45 ===\n",
      "=== Finish Doc 46 ===\n",
      "=== Finish Doc 47 ===\n",
      "=== Finish Doc 48 ===\n",
      "=== Finish Doc 49 ===\n",
      "=== Finish Doc 50 ===\n",
      "=== Finish Doc 51 ===\n",
      "=== Finish Doc 52 ===\n",
      "=== Finish Doc 53 ===\n",
      "=== Finish Doc 54 ===\n",
      "=== Finish Doc 55 ===\n",
      "=== Finish Doc 56 ===\n",
      "=== Finish Doc 57 ===\n",
      "=== Finish Doc 58 ===\n",
      "=== Finish Doc 59 ===\n",
      "=== Finish Doc 60 ===\n",
      "=== Finish Doc 61 ===\n",
      "=== Finish Doc 62 ===\n",
      "=== Finish Doc 63 ===\n",
      "=== Finish Doc 64 ===\n",
      "=== Finish Doc 65 ===\n",
      "=== Finish Doc 66 ===\n",
      "=== Finish Doc 67 ===\n",
      "=== Finish Doc 68 ===\n",
      "=== Finish Doc 69 ===\n",
      "=== Finish Doc 70 ===\n",
      "=== Finish Doc 71 ===\n",
      "=== Finish Doc 72 ===\n",
      "=== Finish Doc 73 ===\n",
      "=== Finish Doc 74 ===\n",
      "=== Finish Doc 75 ===\n",
      "=== Finish Doc 76 ===\n",
      "=== Finish Doc 77 ===\n",
      "=== Finish Doc 78 ===\n",
      "=== Finish Doc 79 ===\n",
      "=== Finish Doc 80 ===\n",
      "=== Finish Doc 81 ===\n",
      "=== Finish Doc 82 ===\n",
      "=== Finish Doc 83 ===\n",
      "=== Finish Doc 84 ===\n",
      "=== Finish Doc 85 ===\n",
      "=== Finish Doc 86 ===\n",
      "=== Finish Doc 87 ===\n",
      "=== Finish Doc 88 ===\n",
      "=== Finish Doc 89 ===\n",
      "=== Finish Doc 90 ===\n",
      "=== Finish Doc 91 ===\n"
     ]
    }
   ],
   "source": [
    "answer_prob = []\n",
    "\n",
    "for i in range(len(question_doc)): # each document\n",
    "  tmp_answer_prob_for_doc = []\n",
    "  question_sentence = re.split('\\(1\\)|\\(2\\)|\\(3\\)|\\(4\\)|\\(5\\)', question_doc[i])\n",
    "  quesion_num = 5\n",
    "  if (ans_df.iloc[i][5] == None):\n",
    "    quesion_num = 4\n",
    "  for j in range(quesion_num): # each question\n",
    "    tmp_answer_prob_for_question = []\n",
    "    for k in range(6): # each option\n",
    "      if (choice_df.iloc[i][choice_cols[k]] != None):\n",
    "        # sentence before\n",
    "        inputs = tokenizer(question_sentence[j], choice_df.iloc[i][choice_cols[k]], return_tensors='pt')\n",
    "        outputs = model(**inputs)[0]\n",
    "        probs = softmax(outputs, dim=1)\n",
    "        # sentence after\n",
    "        if (len(question_sentence) > j):\n",
    "          inputs_2 = tokenizer(choice_df.iloc[i][choice_cols[k]], question_sentence[j+1], return_tensors='pt')\n",
    "          outputs_2 = model(**inputs_2)[0]\n",
    "          probs_2 = softmax(outputs_2, dim=1)\n",
    "          tmp_answer_prob_for_question.append((probs[0][0].item() + probs_2[0][0].item()) / 2)\n",
    "        else:\n",
    "          tmp_answer_prob_for_question.append(probs[0][0].item())\n",
    "    tmp_answer_prob_for_doc.append(tmp_answer_prob_for_question)\n",
    "  answer_prob.append(tmp_answer_prob_for_doc)\n",
    "\n",
    "  print(\"=== Finish Doc\", i+1, \"===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.9999937415122986, 0.9999955296516418, 0.9999942779541016, 0.9999942779541016, 0.9999964237213135], [0.9999821186065674, 0.9999749660491943, 0.9999955296516418, 0.9999958872795105, 0.9999942779541016], [0.9999307990074158, 0.9995757341384888, 0.9999966621398926, 0.9999962449073792, 0.999994158744812], [0.9999839663505554, 0.999997079372406, 0.9999945759773254, 0.9999933838844299, 0.9999958276748657], [0.9999681115150452, 0.999996542930603, 0.9999926090240479, 0.9999942779541016, 0.9999950528144836]], [[0.9999740719795227, 0.9999750852584839, 0.9997751414775848, 0.9999536871910095, 0.999996542930603], [0.999686062335968, 0.9999597072601318, 0.999991774559021, 0.9999958276748657, 0.9999949336051941], [0.9999715089797974, 0.9999947547912598, 0.9999942779541016, 0.9999932050704956, 0.9999934434890747], [0.999986469745636, 0.9999943375587463, 0.9999912977218628, 0.9999883770942688, 0.9999826550483704], [0.5006035520345904, 0.9999906420707703, 0.9986215531826019, 0.9998765885829926, 0.5000033976930354]], [[0.9999966025352478, 0.9998761713504791, 0.999994158744812, 0.9999895095825195, 0.999987781047821, 0.9998748600482941], [0.9999961853027344, 0.999993085861206, 0.999987006187439, 0.9999457597732544, 0.99996417760849, 0.6978424489498138], [0.9999959468841553, 0.9999756217002869, 0.9999873042106628, 0.5001084079776774, 0.999986469745636, 0.9994182586669922], [0.9999962449073792, 0.9999764561653137, 0.9999791979789734, 0.4996807349380106, 0.999971866607666, 0.9996229112148285], [0.9999932646751404, 0.9996342957019806, 0.9999930262565613, 0.5937489718198776, 0.9961874783039093, 0.9950517117977142]], [[0.9999879002571106, 0.9999942183494568, 0.9983986616134644, 0.10469405976982671, 0.5028273405041546], [0.9997313320636749, 0.9998609721660614, 0.4993325648101745, 0.5000019792510102, 0.5273493267595768], [0.9999939799308777, 0.5361045002937317, 0.9867351055145264, 0.9999918341636658, 0.9999956488609314], [0.9999948740005493, 0.5006503033800982, 0.9992985427379608, 0.9999907612800598, 0.9959571063518524], [0.999968409538269, 0.9991792738437653, 0.9971024096012115, 0.9999842047691345, 0.9998502433300018]], [[0.4987322815286461, 0.9999945759773254, 0.9999951720237732, 0.9998687505722046, 0.9999951124191284], [0.4986896908376366, 0.9999956488609314, 0.999994158744812, 0.9999500513076782, 0.9999968409538269], [0.0014031111422809772, 0.999995231628418, 0.9999728202819824, 0.99964240193367, 0.9999971985816956], [0.999887079000473, 0.9999952912330627, 0.9999852776527405, 0.9999968409538269, 0.9999971389770508], [0.9999790191650391, 0.9999953508377075, 0.9999882578849792, 0.9999952912330627, 0.9999967217445374]], [[0.9999842047691345, 0.5014738845638931, 0.9999881386756897, 0.9999927282333374, 0.9990999698638916], [0.999923586845398, 0.999987006187439, 0.9999522566795349, 0.9999744296073914, 0.9999860525131226], [0.9999732375144958, 0.5000970157998381, 0.9999944567680359, 0.9999493360519409, 0.5065580834634602], [0.999994695186615, 0.5010877834865823, 0.9999940395355225, 0.999991774559021, 0.9998765289783478], [0.9999929070472717, 0.9999853372573853, 0.9987163543701172, 0.9999924302101135, 0.9999611377716064]], [[0.9999884366989136, 0.9999964833259583, 0.9999926686286926, 0.9992763102054596, 0.9999417066574097], [0.999984622001648, 0.9999966621398926, 0.9999958276748657, 0.9999963045120239, 0.9999527335166931], [0.999993085861206, 0.9999970197677612, 0.9999959468841553, 0.9999935626983643, 0.9999794363975525], [0.9999907612800598, 0.9999942779541016, 0.9999909996986389, 0.999991238117218, 0.9998790323734283], [0.999994158744812, 0.9999918341636658, 0.9999804496765137, 0.9999862313270569, 0.9975292384624481]], [[0.999996542930603, 0.9999902844429016, 0.9999969601631165, 0.9998931586742401, 0.9999923706054688], [0.9999960660934448, 0.9999417066574097, 0.9999966025352478, 0.9999345541000366, 0.9999967217445374], [0.9999961256980896, 0.9985432922840118, 0.9999967217445374, 0.9999887347221375, 0.9999940395355225], [0.9999938011169434, 0.9972800016403198, 0.9999966621398926, 0.5008041510591283, 0.9992645978927612], [0.9999943971633911, 0.999994695186615, 0.9999963641166687, 0.499964212969644, 0.9971118569374084]], [[0.9999945163726807, 0.9999966025352478, 0.9999838471412659, 0.9999806880950928, 0.9999907612800598], [0.9999945163726807, 0.9999959468841553, 0.9999739527702332, 0.9999793171882629, 0.9999812841415405], [0.5107635501772165, 0.9999546408653259, 0.9998027086257935, 0.9999939203262329, 0.9999374747276306], [0.9997603893280029, 0.9997812211513519, 0.9937248229980469, 0.9999926090240479, 0.9998503029346466], [0.999995231628418, 0.999996542930603, 0.5004990763263777, 0.9998616874217987, 0.9986215233802795]], [[0.500023355407393, 0.9999831914901733, 0.5001771255629137, 0.5000039206938709, 0.9999932050704956], [0.9999974370002747, 0.9999919533729553, 0.5134856505319476, 0.9999967813491821, 0.9999970197677612], [0.9999973177909851, 0.9999927878379822, 0.6665040254592896, 0.9999971985816956, 0.9999967813491821], [0.9999793171882629, 0.9999927282333374, 0.9999186396598816, 0.9999877214431763, 0.9999971389770508], [0.9970791637897491, 0.9999926090240479, 0.999991774559021, 0.9999062418937683, 0.999110609292984]], [[0.9999942779541016, 0.9999966025352478, 0.999994158744812, 0.9999898076057434, 0.5004145179409534, 0.9999968409538269], [0.9999926686286926, 0.9999971389770508, 0.9999961256980896, 0.9999967813491821, 0.9999712109565735, 0.9999969601631165], [0.9999974370002747, 0.9999969601631165, 0.9999968409538269, 0.9999971985816956, 0.9999876618385315, 0.9999967813491821], [0.999996542930603, 0.9999969601631165, 0.9999974966049194, 0.9999973773956299, 0.9999963045120239, 0.9999969005584717], [0.9999966621398926, 0.9999968409538269, 0.9999973177909851, 0.9999972581863403, 0.9999448657035828, 0.9999967813491821]], [[0.9999960660934448, 0.9999969601631165, 0.999995768070221, 0.9999934434890747, 0.9999962449073792, 0.9999958872795105], [0.9999970197677612, 0.9999971985816956, 0.9999967813491821, 0.9999914169311523, 0.9999966025352478, 0.9999966621398926], [0.9999966025352478, 0.9999969005584717, 0.9999948143959045, 0.9999967813491821, 0.9999966025352478, 0.9999967217445374], [0.9999961853027344, 0.9999962449073792, 0.999995231628418, 0.9999951720237732, 0.9999966025352478, 0.9999967217445374], [0.9999961853027344, 0.9999964237213135, 0.9999960660934448, 0.9999929666519165, 0.9999966025352478, 0.9999966025352478]], [[0.9999964237213135, 0.9999857544898987, 0.24147753231227398, 0.9999971389770508, 0.9999972581863403, 0.9999926686286926], [0.5000143267061503, 0.49999390208904515, 0.5002271221019328, 0.9999967813491821, 0.9999823570251465, 0.9999924302101135], [0.5000413533853134, 0.9999831914901733, 0.9999681115150452, 0.9999961256980896, 0.9999933838844299, 0.9999964833259583], [0.9999085366725922, 0.5000692088578944, 0.9999887943267822, 0.9999955892562866, 0.9999899864196777, 0.999996542930603], [0.5000062569606598, 0.4999585433088214, 0.999967634677887, 0.9999879598617554, 0.9999963045120239, 0.5000523387461726]], [[0.999996542930603, 0.9999966025352478, 0.0002973886876134202, 0.999997079372406, 0.9999960064888, 0.999844878911972], [0.9999938607215881, 0.9999951124191284, 0.0002179360672016628, 0.999994695186615, 0.999994695186615, 0.9870476126670837], [0.9999948143959045, 0.9999943971633911, 0.023266677701030858, 0.9999924302101135, 0.999993622303009, 0.9999657273292542], [0.999996542930603, 0.9999961256980896, 0.9998423457145691, 0.9999926686286926, 0.999996542930603, 0.9999940395355225], [0.999997615814209, 0.9999975562095642, 0.5011734712170437, 0.9999971985816956, 0.9999976754188538, 0.9994754493236542]], [[0.9999932646751404, 0.9999924898147583, 0.9987730979919434, 0.9999308586120605, 0.9999939203262329, 0.9998432099819183], [0.9999905228614807, 0.9999944567680359, 0.9991044998168945, 0.9999919533729553, 0.9999933838844299, 0.9999842643737793], [0.9999954700469971, 0.9999960064888, 0.49975363523481064, 0.9998362064361572, 0.9999756217002869, 0.9997924864292145], [0.9999945759773254, 0.9999948740005493, 0.9845722913742065, 0.9999907612800598, 0.99997478723526, 0.999991238117218], [0.9999966621398926, 0.9999971389770508, 0.9999905228614807, 0.9999973177909851, 0.9999945163726807, 0.9999934434890747]], [[0.9999970197677612, 0.9999885559082031, 0.9999969601631165, 0.9999958872795105, 0.999995768070221, 0.999996542930603], [0.9999962449073792, 0.9998935163021088, 0.9999943375587463, 0.9999113082885742, 0.9999963641166687, 0.999972403049469], [0.9999972581863403, 0.9999884366989136, 0.9999970197677612, 0.9999896883964539, 0.9999945759773254, 0.9999962449073792], [0.999996542930603, 0.999994695186615, 0.9999955296516418, 0.9999957084655762, 0.9995154142379761, 0.9988201558589935], [0.9999933838844299, 0.9999873042106628, 0.9999719858169556, 0.9989766478538513, 0.9999146461486816, 0.999871701002121]], [[0.9999876022338867, 0.9999923706054688, 0.9999956488609314, 0.9996922016143799, 0.9999919533729553, 0.9940701723098755], [0.999997079372406, 0.9999967217445374, 0.9999954700469971, 0.9999963641166687, 0.9999969601631165, 0.9999967813491821], [0.9999971985816956, 0.9999930262565613, 0.9999865293502808, 0.9999967813491821, 0.9999971985816956, 0.9999949932098389], [0.999981701374054, 0.9996664226055145, 0.9999856352806091, 0.99996417760849, 0.9999926686286926, 0.5483244583010674], [0.9999701976776123, 0.996913731098175, 0.9999845623970032, 0.9995329082012177, 0.9999920129776001, 0.5005518707912415]], [[0.9999915957450867, 0.9999144077301025, 0.9999929070472717, 0.9999960064888, 0.9999946355819702, 0.9999968409538269], [0.9999918341636658, 0.999902993440628, 0.999994158744812, 0.9999954700469971, 0.9999953508377075, 0.9999960660934448], [0.9998656213283539, 0.9999809265136719, 0.9999951124191284, 0.9999949336051941, 0.9999924898147583, 0.9999967813491821], [0.9999895095825195, 0.9999894499778748, 0.998972624540329, 0.5000351552807842, 0.999995231628418, 0.9999893307685852], [0.9999935030937195, 0.99998539686203, 0.9999868273735046, 0.5008915794896893, 0.9999940991401672, 0.9999914169311523]], [[0.9999974966049194, 0.49225277328514494, 0.4577744681000695, 0.99992835521698, 0.4954026193590835, 0.9999976754188538], [0.9999974966049194, 0.999018669128418, 0.500242371665081, 0.9999865889549255, 0.9999849796295166, 0.999997615814209], [0.9999974966049194, 0.5007197659579106, 0.5008294939179905, 0.9999926090240479, 0.9999960660934448, 0.999997615814209], [0.9999974966049194, 0.49999020018731244, 0.9999319314956665, 0.9999730587005615, 0.9999847412109375, 0.9999975562095642], [0.9999899864196777, 0.999803900718689, 0.99997478723526, 0.9999854564666748, 0.999945878982544, 0.999847412109375]], [[0.9999970197677612, 0.9999970197677612, 0.9958319664001465, 0.9999970197677612, 0.9999971389770508, 0.9999858140945435], [0.9999971389770508, 0.9999973177909851, 0.49710622534621507, 0.9999970197677612, 0.9999972581863403, 0.9999905228614807], [0.9999972581863403, 0.9999972581863403, 0.500633213261608, 0.9999970197677612, 0.9999973177909851, 0.9999960064888], [0.9999971985816956, 0.9999973773956299, 0.9999731779098511, 0.9999971985816956, 0.9999971985816956, 0.9999953508377075], [0.9999971985816956, 0.9999972581863403, 0.5016224390128627, 0.999997079372406, 0.999997079372406, 0.9999954104423523]], [[0.9999862909317017, 0.9999970197677612, 0.9999970197677612, 0.9999951720237732, 0.9999960660934448, 0.999995768070221], [0.9999912977218628, 0.9999966025352478, 0.9999964237213135, 0.9999955296516418, 0.9999955892562866, 0.9999961853027344], [0.9999970197677612, 0.9999961853027344, 0.9999946355819702, 0.9999967217445374, 0.9999954104423523, 0.9999970197677612], [0.9999940991401672, 0.9999966025352478, 0.9999960660934448, 0.9999954700469971, 0.9999967217445374, 0.9999969005584717], [0.9999929666519165, 0.9999969601631165, 0.9999966621398926, 0.9999952912330627, 0.9999971389770508, 0.9999969005584717]], [[0.5001358447916573, 5.625675157716614e-06, 0.9999328255653381, 0.5000108262756839, 0.9999832510948181, 0.4977737044246169], [0.9999866485595703, 3.6184957934892736e-05, 0.9999935626983643, 0.9999869465827942, 0.4999414327139675, 0.5000244856710196], [0.5013435027794912, 0.4999842242687009, 0.9997287690639496, 0.506203742697835, 0.00018038854159385664, 0.5001465695095249], [0.014246596721932292, 0.9999649524688721, 0.5004952214076184, 0.4994737399101723, 1.5782645732542733e-05, 0.8024240732192993], [0.505560337100178, 0.5007505901739933, 0.5860774293541908, 0.9876111149787903, 0.49998413493108274, 0.9999688267707825]], [[0.9998190999031067, 0.5001193887583213, 0.9999969601631165, 0.9999901652336121], [0.9999966025352478, 0.9999961256980896, 0.999997079372406, 0.9999958276748657], [0.9999968409538269, 0.9999966621398926, 0.9999971985816956, 0.9999967813491821], [0.5001515145122539, 0.5015796539373696, 0.9999954700469971, 0.9999939799308777]], [[0.9999975562095642, 0.999997615814209, 0.9991448819637299, 0.999997615814209], [0.9999939203262329, 0.999988317489624, 0.5000535005128768, 0.999997079372406], [0.9999966025352478, 0.9999943971633911, 0.9999921917915344, 0.9999969005584717], [0.999995231628418, 0.999992847442627, 0.9999971389770508, 0.9999961256980896]], [[0.9999969005584717, 0.9999682307243347, 0.9998083710670471, 0.9999971389770508], [0.9999970197677612, 0.9999914765357971, 0.9999895691871643, 0.9999971985816956], [0.9999971389770508, 0.999996542930603, 0.9999963045120239, 0.9999971985816956], [0.9999974370002747, 0.9999969005584717, 0.9999966621398926, 0.9999973773956299]], [[0.9999901056289673, 0.9999953508377075, 0.999993085861206, 0.999993622303009], [0.9999862909317017, 0.9999951124191284, 0.9999930262565613, 0.9999946355819702], [0.9999844431877136, 0.9999951124191284, 0.9999946355819702, 0.9999943375587463], [0.9999558925628662, 0.9999927878379822, 0.9999955296516418, 0.9999926090240479]], [[0.9999949336051941, 0.9999911785125732, 0.9999903440475464, 0.9999682307243347], [0.9999951124191284, 0.9999900460243225, 0.9999771118164062, 0.9999741315841675], [0.9999955892562866, 0.9999954700469971, 0.9992175102233887, 0.9999881386756897], [0.9999935030937195, 0.9999945759773254, 0.5009649810381234, 0.9998681843280792]], [[0.9999786019325256, 0.9999925494194031, 0.9999945163726807, 0.9999427795410156], [0.9999809861183167, 0.9999802112579346, 0.9999955892562866, 0.9999779462814331], [0.9999969005584717, 0.999989926815033, 0.9999971389770508, 0.9999756813049316], [0.9999963641166687, 0.9999828338623047, 0.9999874830245972, 0.9999927282333374]], [[0.9999964237213135, 0.9999969601631165, 0.9998297095298767, 0.9999972581863403], [0.9999958276748657, 0.9999969601631165, 0.9996083378791809, 0.9999971389770508], [0.9999962449073792, 0.9999966621398926, 0.9999971985816956, 0.999996542930603], [0.9999966025352478, 0.9999967217445374, 0.9999964833259583, 0.9999967813491821]], [[0.999935507774353, 0.9999927282333374, 0.9999616146087646, 0.9999889731407166], [0.9999880194664001, 0.9999719858169556, 0.9999441504478455, 0.9999954700469971], [0.9999812841415405, 0.9998792707920074, 0.9999651312828064, 0.9999906420707703], [0.9996176958084106, 0.9999896287918091, 0.9999961256980896, 0.9999939799308777]], [[0.9999960660934448, 0.5000302418557112, 0.5024071456864476, 0.9989505410194397], [0.5002499506517779, 0.9999972581863403, 0.9999943375587463, 0.9999713897705078], [9.45792198763229e-05, 0.9999973773956299, 0.5033276795875281, 0.999991774559021], [4.54525688837748e-05, 0.9999973773956299, 0.9999668598175049, 0.9999951124191284]], [[0.9999839067459106, 0.999997079372406, 0.9999963641166687, 0.9998275637626648], [0.9999891519546509, 0.9999967813491821, 0.9999948143959045, 0.999909520149231], [0.9999955296516418, 0.999993085861206, 0.9999929666519165, 0.9999902248382568], [0.9999945163726807, 0.9999920725822449, 0.9999909996986389, 0.9999953508377075]], [[0.0029859164842491737, 0.9991014003753662, 0.9998989999294281, 0.9998409152030945], [0.00027535779372556135, 0.9999911785125732, 0.9999857544898987, 0.9999729990959167], [0.9729179739952087, 0.9999930262565613, 0.9999948740005493, 0.999991238117218], [0.9722935557365417, 0.9993121325969696, 0.9999801516532898, 0.9999936819076538]], [[0.999501645565033, 0.9999837279319763, 0.9978245794773102, 0.9999966025352478], [0.5003847926855087, 0.9996359944343567, 0.9999650120735168, 0.9999969005584717], [0.9999743700027466, 0.9999140501022339, 0.9999959468841553, 0.9999896287918091], [0.9999926686286926, 0.9999623894691467, 0.9996175169944763, 0.9999904036521912]], [[0.9999969601631165, 0.9999971389770508, 0.9999969005584717, 0.9999910593032837], [0.9999971389770508, 0.9999973177909851, 0.9999973177909851, 0.9999934434890747], [0.9999964237213135, 0.9999958872795105, 0.9999957084655762, 0.999984085559845], [0.9999961853027344, 0.9999961853027344, 0.9999963641166687, 0.9999895095825195]], [[0.9999924898147583, 0.9999966621398926, 0.9999943375587463, 0.9999963045120239], [0.9999819993972778, 0.9999972581863403, 0.9999940395355225, 0.9999963045120239], [0.9999789595603943, 0.9999975562095642, 0.9999961853027344, 0.999995768070221], [0.9999904632568359, 0.9999973177909851, 0.9999969005584717, 0.9999958276748657]], [[0.9999929070472717, 0.9999932646751404, 0.9999938011169434, 0.9999935030937195], [0.999992847442627, 0.9999961853027344, 0.9999905824661255, 0.9999970197677612], [0.9999873042106628, 0.9999967217445374, 0.9999942779541016, 0.9999971985816956], [0.9999931454658508, 0.9999960660934448, 0.9999952912330627, 0.999993085861206]], [[0.9999969601631165, 0.5001225100277225, 0.9999883770942688, 0.9999958872795105], [0.9999966621398926, 0.9999838471412659, 0.9999738335609436, 0.9999963045120239], [0.9999973177909851, 0.5000785536685726, 0.9956795573234558, 0.9999973177909851], [0.9999972581863403, 0.9999489188194275, 0.9999067187309265, 0.9999964237213135]], [[0.9997746646404266, 0.9998103976249695, 0.9926601350307465, 0.9999878406524658], [0.9999964237213135, 0.9999915361404419, 0.999989926815033, 0.9999911785125732], [0.9999802708625793, 0.9999920725822449, 0.9993830025196075, 0.9999933242797852], [0.9999565482139587, 0.9999890923500061, 0.9999967217445374, 0.999997615814209]], [[0.9999842047691345, 0.9999752640724182, 0.9999962449073792, 0.9999956488609314], [0.9999192953109741, 0.9999752640724182, 0.9999960660934448, 0.9999954104423523], [0.9999110102653503, 0.9999955296516418, 0.9999909996986389, 0.9999931454658508], [0.999987781047821, 0.9999931454658508, 0.9999836683273315, 0.9999961853027344]], [[0.9999971985816956, 0.9999828338623047, 0.999960720539093, 0.9999971389770508], [0.9999972581863403, 0.5016541769728065, 0.9999938607215881, 0.9999971985816956], [0.9999969601631165, 0.5000400537974201, 0.9999918341636658, 0.9999972581863403], [0.9999970197677612, 0.5028904459904879, 0.999993622303009, 0.9999972581863403]], [[0.9999906420707703, 0.9999932646751404, 0.9999962449073792, 0.9999845623970032], [0.9999821186065674, 0.999996542930603, 0.999992847442627, 0.9999894499778748], [0.999765008687973, 0.9999958872795105, 0.9995347857475281, 0.9999943971633911], [0.9998341500759125, 0.9999966621398926, 0.9990889132022858, 0.9999867677688599]], [[0.9999962449073792, 0.4998756807181053, 0.9999967217445374, 0.9935150742530823, 0.999997079372406, 0.9946009814739227], [0.9999967217445374, 0.9992861151695251, 0.999996542930603, 0.9914930760860443, 0.9999958276748657, 0.9999847412109375], [0.9999963641166687, 0.9987282454967499, 0.9999969005584717, 0.9994785189628601, 0.9999954104423523, 0.999802976846695], [0.9999961853027344, 0.5002902910928242, 0.9999969005584717, 0.9999771118164062, 0.9999953508377075, 0.5019746287725866], [0.9999946355819702, 0.9999943971633911, 0.9999960660934448, 0.5001919005881064, 0.9999956488609314, 0.9956324696540833]], [[0.9989032447338104, 0.500032884083339, 0.5000532499543624, 0.9999931454658508, 0.9999973773956299, 0.999997079372406], [0.9999959468841553, 0.9999962449073792, 0.999997079372406, 0.9999948740005493, 0.9999974370002747, 0.9999971985816956], [0.9999932646751404, 0.9999960064888, 0.9999949336051941, 0.9999944567680359, 0.9999975562095642, 0.999997079372406], [0.9999762177467346, 0.9999969601631165, 0.9999963641166687, 0.9999959468841553, 0.9999974966049194, 0.9999973177909851], [0.6463766396045685, 0.9999952912330627, 0.9999968409538269, 0.9999915957450867, 0.9999974966049194, 0.999997079372406]], [[0.9993425607681274, 0.00022837030701339245, 0.9999971985816956, 0.5000584307126701, 0.5027740737423301, 0.9999465346336365], [0.9999948740005493, 5.947686076979153e-05, 0.5000064707155616, 0.9999968409538269, 0.9999864101409912, 0.999994158744812], [0.9999948740005493, 9.969535312848166e-05, 0.500621800776571, 0.9999967217445374, 0.9999932646751404, 0.9999913573265076], [0.9999949336051941, 0.00018286326667293906, 0.9988985359668732, 0.9999970197677612, 0.999996542930603, 0.9999963641166687], [0.9999964833259583, 0.999317467212677, 0.9999378323554993, 0.9999961853027344, 0.999995768070221, 0.9999960660934448]], [[0.9999893307685852, 0.9999971985816956, 0.9998942315578461, 0.9999855756759644, 0.9999929666519165, 0.9999840259552002], [0.9998814165592194, 0.999997079372406, 0.9999806880950928, 0.9999905824661255, 0.9999918341636658, 0.9999899864196777], [0.9998832046985626, 0.500396835966967, 0.5000908154906938, 0.9999703764915466, 0.5038376457523555, 0.9999943375587463], [0.9999661445617676, 0.9999794960021973, 0.5006944651249796, 0.9999762177467346, 0.9998750984668732, 0.9999499320983887], [0.9999906420707703, 0.9999971985816956, 0.999958872795105, 0.9999913573265076, 0.5000678257347317, 0.9999853372573853]], [[0.9999940991401672, 0.001324685577856144, 0.9999910593032837, 0.9999569654464722, 0.9999938607215881, 0.9999609589576721], [0.9999834299087524, 0.5036885750014335, 0.9999939799308777, 0.9999955892562866, 0.9999961853027344, 0.999995768070221], [0.53982849791646, 0.9999004900455475, 0.9997681379318237, 0.9999954700469971, 0.9999074637889862, 0.9999968409538269], [0.5087703634053469, 0.5000423703968409, 0.9966490864753723, 0.9999837875366211, 0.760119765996933, 0.9999940395355225], [0.9999947547912598, 0.009602953970897943, 0.9999934434890747, 0.9999967813491821, 0.999995231628418, 0.999996542930603]], [[0.9999964237213135, 0.9999963045120239, 0.9999963641166687, 0.9999909400939941, 0.5016137791099027, 0.9999921321868896], [0.9999966025352478, 0.9999966025352478, 0.9999970197677612, 0.9999913573265076, 0.5007327506318688, 0.9999855756759644], [0.9999964833259583, 0.9999973177909851, 0.9999968409538269, 0.9999938607215881, 0.9999256730079651, 0.9999627470970154], [0.6758390218019485, 0.9999942779541016, 0.5000696704228176, 0.9999819993972778, 0.999944269657135, 0.5001594561763341], [0.9999882578849792, 0.9999935030937195, 0.9997903406620026, 0.9999883770942688, 0.9954092502593994, 0.9999359250068665]], [[0.9999967813491821, 0.9999942779541016, 0.5003462347667664, 0.9999914765357971, 0.9999943375587463, 0.9993410408496857], [0.9999966621398926, 0.999994158744812, 0.9999710321426392, 0.9999855160713196, 0.9999936819076538, 0.9994365274906158], [0.9999951124191284, 0.9999927878379822, 0.9999905228614807, 0.9998641014099121, 0.9999938011169434, 0.9999907612800598], [0.9999951124191284, 0.9999787211418152, 0.506252289749682, 0.5579132735729218, 0.9999951720237732, 0.5210535358637571], [0.9999961256980896, 0.9999950528144836, 0.5000158261500474, 0.5003885073238052, 0.9999957084655762, 0.9999967813491821]], [[0.9999933242797852, 0.5001148849187302, 0.9999932050704956, 0.9999949932098389, 0.5001392105041305, 0.500119162054034], [0.9999838471412659, 0.5002262759080622, 0.9999958276748657, 0.999987781047821, 0.9999963045120239, 0.999990701675415], [0.999993085861206, 0.5000480071175843, 0.9999962449073792, 0.9999746084213257, 0.9999971985816956, 0.9999960660934448], [0.9999953508377075, 0.9997952282428741, 0.9999948143959045, 0.9999962449073792, 0.9999947547912598, 0.999933123588562], [0.5000039023007048, 0.5028573134914041, 0.9995134472846985, 0.5000665278203087, 0.5003560956392903, 0.5006406080210581]], [[0.1147027537226677, 0.9999972581863403, 0.9999658465385437, 0.4999789796793266, 0.9999972581863403, 0.5000437880698883], [0.5000121318953461, 0.9999973773956299, 0.9999861717224121, 0.9999916553497314, 0.9999973773956299, 0.9999025166034698], [0.9999876022338867, 0.9999974966049194, 0.9999921321868896, 0.9999711513519287, 0.999997615814209, 0.9999935030937195], [0.9996155202388763, 0.9999973773956299, 0.9999766945838928, 0.5016572044696659, 0.9999974966049194, 0.9999886155128479], [0.999466747045517, 0.9999971985816956, 0.9999829530715942, 0.005660475539116305, 0.9999974966049194, 0.9999850988388062]], [[0.9999927878379822, 0.006423786864615977, 0.9999624490737915, 0.9979018270969391, 0.49997533205896616, 0.9999768137931824], [0.9999809861183167, 0.0019140380863973405, 0.999984622001648, 7.190313772298396e-05, 0.5000022421854737, 0.5000270837772405], [0.999988853931427, 0.0004849365504924208, 0.9999871253967285, 0.4944609195954399, 0.5006370162591338, 0.5000399835880671], [0.999969482421875, 0.9864607453346252, 0.9999923706054688, 5.2985486945544835e-05, 0.9999960064888, 0.9999951720237732], [0.9999575614929199, 0.99998939037323, 0.9999825954437256, 0.4987941185827367, 0.9999934434890747, 0.9999938607215881]], [[0.9999955296516418, 0.9999955892562866, 0.999991774559021, 0.9989321827888489, 0.5000632935698377, 0.9999926686286926], [0.9999939799308777, 0.999960720539093, 0.9999957084655762, 0.9999913573265076, 0.49231422540469794, 0.999994158744812], [0.5000366283602489, 0.4999010770552559, 0.999995231628418, 0.5008829340804368, 4.019056586912484e-05, 0.9997383952140808], [0.5001131778408308, 0.5009929840452969, 0.501327722100541, 0.9998548328876495, 0.499822914050128, 0.9999890923500061], [0.9998339414596558, 0.999946117401123, 0.521154249086976, 0.9987724721431732, 0.9983009397983551, 0.99983149766922]], [[0.9999960064888, 0.999992847442627, 0.9999961853027344, 0.9999970197677612, 0.9999802708625793, 0.9999873638153076], [0.9999963641166687, 0.9999858736991882, 0.9999961256980896, 0.9999963641166687, 0.9999805092811584, 0.9999344944953918], [0.9999969601631165, 0.9999880194664001, 0.9999970197677612, 0.999997079372406, 0.9999933242797852, 0.996006429195404], [0.9999971985816956, 0.9999876022338867, 0.9999966025352478, 0.9999966025352478, 0.9999915361404419, 0.011345054881530814], [0.999996542930603, 0.9999765753746033, 0.9999962449073792, 0.9999966025352478, 0.9999891519546509, 0.0006554077626788057]], [[0.994183361530304, 0.9998712241649628, 0.999950647354126, 0.9999970197677612, 0.9997820556163788, 0.9999644160270691], [0.5008959207334556, 0.9999907612800598, 0.5739763379096985, 0.9999940395355225, 0.9998759329319, 0.9999682903289795], [0.9998513162136078, 0.9999971985816956, 0.5026386119425297, 0.9999950528144836, 0.9999948143959045, 0.9999944567680359], [0.9999918341636658, 0.9999973773956299, 0.999989926815033, 0.9999920725822449, 0.9999958872795105, 0.9999949932098389], [0.999992311000824, 0.9999973177909851, 0.9999803900718689, 0.999989926815033, 0.9999949336051941, 0.999993085861206]], [[0.9999958872795105, 0.9999635219573975, 0.9999970197677612, 0.5000185187964235, 0.999996542930603, 0.9999960064888], [0.999995231628418, 0.9999944567680359, 0.9999964237213135, 0.999874085187912, 0.9999942183494568, 0.9999942779541016], [0.9999823570251465, 0.9999958872795105, 0.9999940395355225, 0.9995049834251404, 0.9999778270721436, 0.9999008476734161], [0.9999948740005493, 0.9999964237213135, 0.9999967813491821, 0.9999953508377075, 0.9997317492961884, 0.9999949932098389], [0.9999971985816956, 0.9999938607215881, 0.9999971985816956, 0.9997948408126831, 0.9999966025352478, 0.9999971985816956]], [[0.9999939203262329, 0.9999948143959045, 0.9999953508377075, 0.9999931454658508, 0.9999858140945435, 0.9999889731407166], [0.9999816417694092, 0.9999943375587463, 0.9999560713768005, 0.513239860534668, 0.9987147450447083, 0.9999736547470093], [0.999988853931427, 0.9999924898147583, 0.9999871253967285, 0.5404680892825127, 0.999894767999649, 0.9999825954437256], [0.9999963045120239, 0.9999953508377075, 0.9999967813491821, 0.9999824166297913, 0.9999940991401672, 0.9999949336051941], [0.9999948143959045, 0.9999913573265076, 0.9999961256980896, 0.9999899864196777, 0.9999935626983643, 0.9999951720237732]], [[0.9999971985816956, 0.9999933838844299, 0.9999973773956299, 0.9999967217445374, 0.9993599951267242, 0.9999951124191284], [0.9999971985816956, 0.9999887347221375, 0.9999971985816956, 0.9999962449073792, 0.9999918341636658, 0.9999940395355225], [0.9999969005584717, 0.9999704360961914, 0.9999969601631165, 0.999996542930603, 0.9999932646751404, 0.9999942183494568], [0.9999968409538269, 0.9999712109565735, 0.9999969005584717, 0.999996542930603, 0.9999856352806091, 0.9999961256980896], [0.9999969601631165, 0.9999565482139587, 0.9999973773956299, 0.9999969005584717, 0.49964793186336465, 0.9999935030937195]], [[0.9992013275623322, 0.9999889135360718, 0.9999954700469971, 0.9996130466461182, 0.9999569058418274, 0.9999669790267944], [0.9999810457229614, 0.9996858835220337, 0.9999938011169434, 0.9993906915187836, 0.9999290704727173, 0.9999889135360718], [0.9999915957450867, 0.9904262125492096, 0.5093853417783976, 0.49916190768999513, 0.9999898076057434, 0.9999952912330627], [0.9999725818634033, 0.5004931839648634, 0.9988182485103607, 0.523036414757371, 0.9999915957450867, 0.9999879002571106], [0.9999829530715942, 0.9943529367446899, 0.9999369978904724, 0.9996563494205475, 0.9999651312828064, 0.9999637007713318]], [[0.9999926090240479, 0.9999960064888, 0.9999973773956299, 0.9999969005584717, 0.9999974966049194, 0.9999942779541016], [0.9977591037750244, 0.9999946355819702, 0.9999963045120239, 0.9999956488609314, 0.9999970197677612, 0.9999969005584717], [0.5002590194926597, 0.9999958872795105, 0.999993622303009, 0.9999954700469971, 0.9999956488609314, 0.9999933242797852], [0.49939728457343335, 0.5000033595474633, 0.5000004189191714, 0.9999716281890869, 0.5011385863181204, 0.5044654472731054], [0.0007658123249711934, 0.021847872994840145, 0.49998910040812916, 0.9998632371425629, 0.5053492947481573, 0.502930682618171]], [[0.9999969601631165, 0.9999953508377075, 0.9999951720237732, 0.4999403343681479, 0.5339807271957397, 0.9999974966049194], [0.9999956488609314, 0.5200614277273417, 0.9999933242797852, 0.0017809609416872263, 0.999995231628418, 0.5001216935343109], [0.9999951720237732, 0.9998445808887482, 0.9999933838844299, 0.9996504783630371, 0.9999868273735046, 0.9999919533729553], [0.9999953508377075, 0.9999681115150452, 0.9999968409538269, 0.9999774098396301, 0.9999853372573853, 0.9999959468841553], [0.9993369877338409, 0.9997497498989105, 0.9999514818191528, 0.9997326731681824, 0.9940555393695831, 0.9999493360519409]], [[0.49992435842432315, 0.9999570250511169, 0.5020722483750433, 0.0010788432919071056, 0.9995359182357788, 0.9999642372131348], [0.5000009903624232, 0.9986054301261902, 0.4997680549895449, 0.5001708959753159, 0.9999858140945435, 0.9999927878379822], [0.9999851584434509, 0.500279772648355, 0.0018670629360713065, 0.999991774559021, 0.9999942183494568, 0.9998892247676849], [0.9999849200248718, 0.5001054791646311, 0.49994497289299034, 0.9999175667762756, 0.9999916553497314, 0.9999812841415405], [0.9979158043861389, 0.9999942779541016, 0.977414458990097, 0.499903609714238, 0.9999646544456482, 0.8922503292560577]], [[0.019822152665256, 0.999972403049469, 0.00044125895146862604, 0.9999942779541016, 0.49992274237956735, 0.999994695186615], [0.5002649335656315, 0.9999886751174927, 0.9541857540607452, 0.9999924302101135, 0.539762120693922, 0.9999957084655762], [0.9988352358341217, 0.5000280059321085, 0.5000335160220857, 0.9999926090240479, 0.999971866607666, 0.8080216646194458], [0.9997087717056274, 0.0002833929393091239, 0.4998322349747468, 0.9999868869781494, 0.9999937415122986, 0.999830424785614], [0.9999947547912598, 0.5200186334550381, 0.5055618355982006, 0.9999470114707947, 0.9999966621398926, 0.9999974966049194]], [[0.9999966621398926, 0.9998990595340729, 0.999981164932251, 0.9995022714138031, 0.9999914169311523, 0.5001477938785683], [0.9999948740005493, 0.9956882297992706, 0.9999290704727173, 0.9999735951423645, 0.7230393290519714, 0.5000464254553663], [0.9999967217445374, 0.999980092048645, 0.9999830722808838, 0.9999953508377075, 0.9999066889286041, 0.9999743103981018], [0.9997311532497406, 0.9956722855567932, 0.9998390674591064, 0.9995138049125671, 0.9066217839717865, 0.9999973177909851], [0.9999818801879883, 0.9999552369117737, 0.9999814033508301, 0.500035592533095, 0.5024708923883736, 0.9975829124450684]], [[0.9999947547912598, 0.9999967217445374, 0.9999973773956299, 0.999997079372406, 0.9999973773956299, 0.9999974370002747], [0.9999900460243225, 0.9999952912330627, 0.9999971389770508, 0.9999973177909851, 0.9999974966049194, 0.9999973773956299], [0.9999951124191284, 0.9999949336051941, 0.9999968409538269, 0.9999969601631165, 0.9999974370002747, 0.9999973177909851], [0.9998898208141327, 0.9999958872795105, 0.9999961853027344, 0.9999960064888, 0.9999964833259583, 0.9999966025352478], [0.9997125566005707, 0.9999939799308777, 0.9999955296516418, 0.9999957084655762, 0.9999963641166687, 0.9999967217445374]], [[0.9999954700469971, 0.9999748468399048, 0.9999975562095642, 0.9999971985816956, 0.9999960660934448, 0.9999764561653137], [0.9999909400939941, 0.9999855756759644, 0.9999961853027344, 0.9999963045120239, 0.9999964237213135, 0.9999956488609314], [0.9999954700469971, 0.999991238117218, 0.9999966621398926, 0.9999963045120239, 0.9999966025352478, 0.9999934434890747], [0.9999955296516418, 0.9999962449073792, 0.9999963045120239, 0.9999966025352478, 0.9999968409538269, 0.9999933838844299], [0.999973714351654, 0.9999920725822449, 0.9999961256980896, 0.9999963045120239, 0.9999963045120239, 0.9999948740005493]], [[0.999996542930603, 0.9999948143959045, 0.9999969005584717, 0.9999918937683105, 0.9999925494194031, 0.9999380707740784], [0.9999964833259583, 0.9999958872795105, 0.9999966621398926, 0.5010821078903973, 0.5018919338472188, 0.9998622238636017], [0.5054499465040863, 0.9999352097511292, 0.5000116065129987, 0.49944597618377884, 0.017601946834474802, 0.9999929070472717], [0.9992479085922241, 0.9999850988388062, 0.9768393039703369, 0.5093502681702375, 0.5007172276382335, 0.9999945759773254], [0.9999970197677612, 0.9999968409538269, 0.9999969601631165, 0.999994158744812, 0.9999664425849915, 0.9999939799308777]], [[0.9999919533729553, 0.9999967813491821, 0.9999765753746033, 0.9999964237213135, 0.5001433161523892, 0.9999812245368958], [0.9999780058860779, 0.999997079372406, 0.9997528791427612, 0.9999961853027344, 0.9996421039104462, 0.9999922513961792], [0.0038525076815858483, 0.9999974370002747, 0.9999973773956299, 0.9999974966049194, 0.9999492168426514, 0.999997615814209], [0.0051536166245114146, 0.9999970197677612, 0.9999971985816956, 0.9999973177909851, 0.9999863505363464, 0.9999973773956299], [0.4998784586282454, 0.9999973773956299, 0.9999970197677612, 0.9999973773956299, 0.9999605417251587, 0.999997615814209]], [[0.5088940113782883, 0.999997079372406, 0.9999964237213135, 0.9999938607215881, 0.999981164932251, 0.999997079372406], [0.49998662825964857, 0.9999966621398926, 0.9999961853027344, 0.9999929666519165, 0.9999894499778748, 0.9999972581863403], [0.487885128473863, 0.9999967217445374, 0.9999955892562866, 0.9999963641166687, 0.9999224543571472, 0.9999971389770508], [0.0006869548524264246, 0.9999924302101135, 0.9999889135360718, 0.9999786615371704, 0.9998070895671844, 0.99997878074646], [0.5000404496822739, 0.9999947547912598, 0.9998272061347961, 0.9872318506240845, 0.9998475611209869, 0.9999910593032837]], [[0.9999956488609314, 0.9998814165592194, 0.9999961256980896, 0.9999954104423523, 0.9999944567680359, 0.9999954700469971], [0.9999954700469971, 0.9999825954437256, 0.9999955892562866, 0.9999936819076538, 0.9999958276748657, 0.9999959468841553], [0.9999940991401672, 0.9999930262565613, 0.9999951720237732, 0.9999937415122986, 0.9999949336051941, 0.9999948143959045], [0.9999952912330627, 0.9999862909317017, 0.9999951720237732, 0.999995231628418, 0.9999942779541016, 0.9999957084655762], [0.9999954700469971, 0.9999901652336121, 0.9999938011169434, 0.9999949336051941, 0.9999902844429016, 0.9999963045120239]], [[0.9999974966049194, 0.9999959468841553, 0.9999971985816956, 0.9999974370002747, 0.9990793764591217, 0.9999976754188538], [0.9999844431877136, 0.9999842643737793, 0.9999645948410034, 0.9999964237213135, 0.9999932050704956, 0.9999837279319763], [0.9999449253082275, 0.9999903440475464, 0.9999716281890869, 0.5000537004198122, 0.9999939799308777, 0.9999942183494568], [0.9999971985816956, 0.9999949932098389, 0.9999963045120239, 0.5000182266448974, 0.9999952912330627, 0.999997079372406], [0.9999961853027344, 0.999991774559021, 0.9999966025352478, 0.9999973177909851, 0.9999906420707703, 0.9999973773956299]], [[0.9999971985816956, 0.49997352653736016, 0.4999310077437258, 0.9999252557754517, 0.9999960064888], [0.9999975562095642, 0.4988166656839894, 0.0005032939516240731, 0.9995731711387634, 0.9999972581863403], [0.9999974966049194, 0.9994286298751831, 0.5107973292469978, 0.5010083254892379, 0.9999964237213135], [0.9999974966049194, 0.9999940395355225, 0.9999952912330627, 0.4999071482816362, 0.9999932050704956], [0.9999973177909851, 0.9999945163726807, 0.9999952912330627, 0.49993967950831575, 0.9999836683273315]], [[0.7409245520830154, 0.9999957084655762, 0.5057234512642026, 0.9999971985816956, 0.99961918592453, 0.9999591708183289], [0.9999959468841553, 0.9999973177909851, 0.9999966025352478, 0.9999973773956299, 0.9999969005584717, 0.9999883770942688], [0.9999971985816956, 0.9999955892562866, 0.9999969005584717, 0.9999951124191284, 0.9999969601631165, 0.5003402638249099], [0.9999960660934448, 0.9999954104423523, 0.999996542930603, 0.9999935030937195, 0.9999966621398926, 0.4999933517556201], [0.99972203373909, 0.9999936819076538, 0.9999924898147583, 0.9999951720237732, 0.9999951720237732, 0.9999731183052063]], [[0.9999963045120239, 0.9999816417694092, 0.999981701374054, 0.999971330165863, 0.9999945163726807, 0.9999972581863403], [0.9999942779541016, 0.9999865889549255, 0.999977707862854, 0.9998353123664856, 0.9999933838844299, 0.9999899864196777], [0.9999954700469971, 0.9999837279319763, 0.9999381303787231, 0.9999946355819702, 0.9999732971191406, 0.9999949932098389], [0.9999935626983643, 0.9999950528144836, 0.9999338388442993, 0.9999667406082153, 0.9998105764389038, 0.9999953508377075], [0.9999961256980896, 0.9999971985816956, 0.999988317489624, 0.9999799728393555, 0.9999697208404541, 0.9999961853027344]], [[0.9999967813491821, 0.9999316334724426, 0.9999958872795105, 0.9999969005584717, 0.9999806880950928, 0.999967098236084], [0.9999944567680359, 0.999987006187439, 0.9999942183494568, 0.9999960660934448, 0.9999952912330627, 0.013390075153438374], [0.9999961853027344, 0.4994640489239828, 0.999995768070221, 0.9999958276748657, 0.9999898672103882, 0.5002279623004142], [0.9999970197677612, 0.004257772299752105, 0.9999964237213135, 0.9999970197677612, 0.9999894499778748, 0.9999796152114868], [0.9999955892562866, 4.4352027543936856e-05, 0.9999902844429016, 0.9999966025352478, 0.999980628490448, 0.5007425802759826]], [[0.9999950528144836, 0.9999963641166687, 0.9999969005584717, 0.9999967217445374, 0.9999961853027344, 0.9999949932098389], [0.9999942183494568, 0.999996542930603, 0.9999969601631165, 0.9999967217445374, 0.9999966025352478, 0.9999958872795105], [0.9999929070472717, 0.9999966621398926, 0.9999968409538269, 0.9999961853027344, 0.9999949932098389, 0.9999949932098389], [0.9999933242797852, 0.9999961256980896, 0.9999956488609314, 0.999995231628418, 0.9999907612800598, 0.9999939203262329], [0.9999947547912598, 0.9999961853027344, 0.9999961256980896, 0.9999964833259583, 0.9999912977218628, 0.9999954700469971]], [[0.9999952912330627, 0.9999971389770508, 0.9999969005584717, 0.9999930262565613, 0.499959401072374, 0.999996542930603], [0.9999765753746033, 0.9999803304672241, 0.9999960660934448, 0.9999930262565613, 0.4999712924745836, 0.9999966025352478], [0.9999640583992004, 0.9999929070472717, 0.9999961853027344, 0.999994158744812, 0.5000118447969726, 0.999997079372406], [0.9999836087226868, 0.9999968409538269, 0.9999469518661499, 0.9999417066574097, 0.9999950528144836, 0.9999301433563232], [0.9999942779541016, 0.9999949932098389, 0.9997150599956512, 0.9999665021896362, 0.9999845027923584, 0.999622106552124]], [[0.9999973177909851, 0.9999905228614807, 0.9999973773956299, 0.999997615814209, 0.9999955296516418, 0.9999960660934448], [0.9999944567680359, 0.999994695186615, 0.999995768070221, 0.9999962449073792, 0.9999947547912598, 0.9999764561653137], [0.9999895095825195, 0.999996542930603, 0.9999933838844299, 0.9999874830245972, 0.9999909400939941, 0.015789806668180972], [0.9999967217445374, 0.9999964833259583, 0.999996542930603, 0.9999960660934448, 0.9999949932098389, 0.5000545770453755], [0.5006279931985773, 0.500777191366069, 0.9993591010570526, 0.5452241338789463, 0.9992676377296448, 0.9969845712184906]], [[0.5000495087224408, 0.5499992445111275, 0.49974256675341167, 0.9999940395355225, 0.500134635323775, 0.5012825896264985], [0.9999973773956299, 0.9999890923500061, 0.9999727606773376, 0.9999970197677612, 0.9999938011169434, 0.9999593496322632], [0.9999977946281433, 0.9999968409538269, 0.9999961853027344, 0.9999974370002747, 0.9999973773956299, 0.9999886155128479], [0.9999975562095642, 0.9999966025352478, 0.9999936819076538, 0.9999968409538269, 0.9999972581863403, 0.5034394469112158], [0.9999973773956299, 0.9993419349193573, 0.999977171421051, 0.9999948143959045, 0.9999968409538269, 0.0009779756073839962]], [[0.9999666810035706, 0.9999774098396301, 0.9999942183494568, 0.9999948740005493, 0.9999957084655762, 0.9974746406078339], [0.9999180436134338, 0.9999946355819702, 0.9999791383743286, 0.9999930262565613, 0.9999969005584717, 0.9999948143959045], [0.996262937784195, 0.999970555305481, 0.9979203939437866, 0.9999815821647644, 0.9999971389770508, 0.9999943971633911], [0.9996530413627625, 0.9999899864196777, 0.9999911189079285, 0.9999741911888123, 0.9999969601631165, 0.9999912977218628], [0.9999417066574097, 0.9999373555183411, 0.9999916553497314, 0.9992032647132874, 0.9999924302101135, 0.9999046623706818]], [[0.9999946355819702, 0.9999783635139465, 0.9999952912330627, 0.9999954104423523, 0.9999598264694214, 0.999995768070221], [0.9999936819076538, 0.9985810816287994, 0.9999949932098389, 0.9999961853027344, 0.996148943901062, 0.9999961853027344], [0.9999946355819702, 0.9999892115592957, 0.9999946355819702, 0.9999946355819702, 0.9998788237571716, 0.999995231628418], [0.9999933242797852, 0.9999943971633911, 0.9999945759773254, 0.9999963641166687, 0.998807817697525, 0.9999937415122986], [0.999992311000824, 0.9999920129776001, 0.999995231628418, 0.9999970197677612, 0.9939687550067902, 0.9999948740005493]], [[0.999624103307724, 0.9995806515216827, 0.4993093896191567, 0.9999934434890747, 0.9999911189079285, 0.999715119600296], [0.9999670386314392, 0.999697744846344, 0.5000458089634776, 0.9999931454658508, 0.9999839663505554, 0.9998407959938049], [0.9999936819076538, 0.9999977946281433, 0.9999923706054688, 0.9993443787097931, 0.9998945891857147, 0.9999977946281433], [0.9999956488609314, 0.9999977946281433, 0.999994695186615, 0.9979042708873749, 0.9995526373386383, 0.9999977946281433], [0.9999958872795105, 0.9999963641166687, 0.9999946355819702, 0.5001071405204129, 0.9984654784202576, 0.9999939203262329]], [[0.9999723434448242, 0.9999961256980896, 0.9999919533729553, 0.9998153448104858, 0.49982765732875123, 0.9999911189079285], [0.9999861121177673, 0.9999958872795105, 0.9999740123748779, 0.9994395971298218, 0.5015406968304887, 0.9999821186065674], [0.9999927282333374, 0.9999964237213135, 0.9999933242797852, 0.9998759329319, 0.9997183382511139, 0.9999914169311523], [0.9999934434890747, 0.9999967217445374, 0.9999918937683105, 0.9999859929084778, 0.5118780620396137, 0.9999959468841553], [0.9999919533729553, 0.9997080564498901, 0.9999842047691345, 0.9996761977672577, 0.4580830533232074, 0.9999806880950928]], [[0.999994695186615, 0.9999949932098389, 0.9999962449073792, 0.9999896287918091, 0.9999911189079285, 0.9999841451644897], [0.9999962449073792, 0.9999939203262329, 0.9999939203262329, 0.9999898076057434, 0.9999769926071167, 0.9999818801879883], [0.9999968409538269, 0.9999896287918091, 0.9999915361404419, 0.9999942183494568, 0.9995627105236053, 0.9999804496765137], [0.9999956488609314, 0.9999922513961792, 0.9999939799308777, 0.9999933838844299, 0.9999961256980896, 0.9999892115592957], [0.5008848289144225, 0.5000061056293816, 0.5000204053339985, 0.5000048198971854, 0.999957799911499, 0.5000005276081083]], [[0.9999936819076538, 0.999990701675415, 0.9999918937683105, 0.9999964833259583, 0.9997911751270294, 0.9999960660934448], [0.9999974966049194, 0.9999970197677612, 0.9999927282333374, 0.999995231628418, 0.9999579787254333, 0.9999964237213135], [0.9999962449073792, 0.9999960660934448, 0.9999796152114868, 0.9999873638153076, 0.5001845036895247, 0.9999929666519165], [0.9999955296516418, 0.9999930262565613, 0.9999896287918091, 0.9999819397926331, 0.5021380435209721, 0.9999944567680359], [0.999990701675415, 0.999988853931427, 0.9999925494194031, 0.9999931454658508, 0.999992311000824, 0.9999961256980896]], [[0.9999877214431763, 0.9999013841152191, 0.9999898076057434, 0.9994014501571655, 0.9999905228614807, 0.9999908804893494], [0.9999228715896606, 0.9998022019863129, 0.9999977350234985, 0.9993756115436554, 0.9999933242797852, 0.9999973773956299], [0.9999694228172302, 0.9999952912330627, 0.9999944567680359, 0.9999805688858032, 0.9999924302101135, 0.9998619854450226], [0.9782393574714661, 0.9999953508377075, 0.9999593496322632, 0.999997079372406, 0.9999956488609314, 0.9980505108833313], [0.9990724325180054, 0.9999969005584717, 0.9999831318855286, 0.9999971985816956, 0.9999956488609314, 0.9999237060546875]], [[0.999995231628418, 0.999988317489624, 0.9999959468841553, 0.9999961853027344, 0.9999964833259583], [0.9999967813491821, 0.9999444484710693, 0.9999943971633911, 0.9999949932098389, 0.9999966025352478], [0.999997079372406, 0.9999634027481079, 0.9999948740005493, 0.9999951124191284, 0.9999963045120239], [0.9999961853027344, 0.862634152173996, 0.9999956488609314, 0.9999960064888, 0.9999939799308777], [0.9999953508377075, 0.9999738335609436, 0.9999963045120239, 0.9999966621398926, 0.9999939799308777]], [[0.9999963641166687, 0.9999887347221375, 0.9999971985816956, 0.5199243575334549, 0.9999955296516418, 0.9953330457210541], [0.9999966621398926, 0.9998085498809814, 0.9999952912330627, 0.9999171495437622, 0.9999865293502808, 0.9999895095825195], [0.9999801516532898, 0.9999946355819702, 0.5006220398936421, 0.999984622001648, 0.5021081941667944, 0.706066906452179], [0.9999930262565613, 0.9999968409538269, 0.9998696744441986, 0.9994194507598877, 0.9996676743030548, 0.9997035562992096], [0.9999386072158813, 0.9983977377414703, 0.9995822310447693, 0.9995719790458679, 0.9989468455314636, 0.999282717704773]], [[0.9999969601631165, 0.9999966025352478, 0.9999969601631165, 0.9999933242797852, 0.9999969601631165], [0.9999973177909851, 0.9999966025352478, 0.9999971985816956, 0.999993085861206, 0.9999974966049194], [0.999996542930603, 0.9999933242797852, 0.9999971985816956, 0.999912440776825, 0.9999901652336121], [0.999997079372406, 0.9999964833259583, 0.9999973177909851, 0.9999916553497314, 0.9999966025352478], [0.9999967217445374, 0.9999940395355225, 0.9999961256980896, 0.9999678730964661, 0.9999924898147583]], [[0.9999619722366333, 0.980932354927063, 0.9999843239784241, 0.9999903440475464, 0.9999850988388062], [0.5000303176966554, 0.9970981180667877, 0.9997746050357819, 0.9999960064888, 0.9998189210891724], [0.8548663854598999, 0.5890756323933601, 0.9999858736991882, 0.9999964833259583, 0.9999962449073792], [0.9999886155128479, 0.9999844431877136, 0.9999932050704956, 0.9999972581863403, 0.9999950528144836], [0.9999528527259827, 0.9991967976093292, 0.9997972548007965, 0.9999673366546631, 0.9991007447242737]], [[0.9999960660934448, 0.9999815225601196, 0.5030637620948255, 0.9999974966049194, 0.9999913573265076], [0.9999957084655762, 0.9998577535152435, 0.0003592376087908633, 0.9999750256538391, 0.9999856948852539], [0.9999291896820068, 0.9999863505363464, 0.4976572934538126, 0.9999866485595703, 0.9999949336051941], [0.9999389052391052, 0.9999931454658508, 0.9991808533668518, 0.9999955296516418, 0.9999954104423523], [0.500160679948749, 0.5357441231608391, 0.999994695186615, 0.5017861715750769, 0.503615299705416]]]\n"
     ]
    }
   ],
   "source": [
    "print(answer_prob)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-1 Choose from highest probability\n",
    "Start from choosing the highest probability among all questions & options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_answer_1 = []\n",
    "\n",
    "for i in range(len(answer_prob)):\n",
    "  num_q = len(answer_prob[i])\n",
    "  num_o = len(answer_prob[i][0])\n",
    "  chosen = np.zeros((num_q, num_o)) # chosen[j][k] = question j, option k\n",
    "  tmp_answer = np.zeros(num_q)\n",
    "  for x in range(num_q): # we need to find answers for all questions\n",
    "    # find the highest probability for this round\n",
    "    pos_q = 0 # record the highest probability position\n",
    "    pos_o = 0\n",
    "    highest_prob = 0\n",
    "    for j in range(num_q):\n",
    "      for k in range(num_o):\n",
    "        if (answer_prob[i][j][k] > highest_prob and chosen[j][k] == 0):\n",
    "          highest_prob = answer_prob[i][j][k]\n",
    "          pos_q = j\n",
    "          pos_o = k\n",
    "    # record the answer\n",
    "    tmp_answer[pos_q] = pos_o\n",
    "    for j in range(num_q):\n",
    "      chosen[j][pos_o] = 1\n",
    "    for k in range(num_o):\n",
    "      chosen[pos_q][k] = 1\n",
    "  our_answer_1.append(tmp_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([4., 3., 2., 1., 0.]), array([4., 3., 1., 2., 0.]), array([0., 1., 4., 5., 2.]), array([1., 2., 4., 0., 3.]), array([2., 1., 4., 3., 0.]), array([3., 1., 2., 0., 4.]), array([2., 3., 1., 4., 0.]), array([2., 4., 0., 3., 1.]), array([1., 4., 3., 2., 0.]), array([2., 0., 3., 4., 1.]), array([5., 1., 0., 2., 3.]), array([0., 1., 3., 5., 4.]), array([4., 3., 1., 5., 2.]), array([3., 1., 5., 0., 4.]), array([4., 5., 1., 0., 3.]), array([2., 4., 0., 3., 1.]), array([2., 4., 0., 3., 1.]), array([5., 3., 2., 4., 0.]), array([5., 0., 4., 2., 3.]), array([3., 5., 4., 1., 0.]), array([1., 2., 0., 5., 4.]), array([4., 2., 3., 1., 5.]), array([1., 0., 2., 3.]), array([1., 3., 0., 2.]), array([2., 3., 1., 0.]), array([1., 3., 0., 2.]), array([2., 3., 0., 1.]), array([1., 3., 2., 0.]), array([3., 1., 2., 0.]), array([1., 3., 0., 2.]), array([0., 2., 1., 3.]), array([1., 2., 0., 3.]), array([0., 1., 2., 3.]), array([1., 3., 2., 0.]), array([0., 1., 3., 2.]), array([3., 0., 1., 2.]), array([0., 1., 3., 2.]), array([2., 1., 0., 3.]), array([2., 0., 1., 3.]), array([2., 0., 1., 3.]), array([1., 0., 3., 2.]), array([2., 0., 3., 1.]), array([4., 0., 2., 3., 1.]), array([3., 2., 4., 5., 1.]), array([2., 5., 4., 3., 0.]), array([1., 4., 5., 0., 3.]), array([0., 4., 5., 2., 3.]), array([0., 2., 1., 4., 3.]), array([0., 1., 2., 4., 5.]), array([0., 2., 4., 3., 1.]), array([3., 1., 4., 5., 2.]), array([0., 1., 2., 4., 5.]), array([1., 2., 3., 5., 0.]), array([1., 4., 3., 0., 2.]), array([3., 2., 5., 1., 4.]), array([2., 5., 4., 1., 0.]), array([1., 4., 0., 2., 5.]), array([2., 0., 4., 5., 3.]), array([2., 1., 5., 4., 0.]), array([4., 5., 1., 3., 2.]), array([5., 0., 4., 2., 1.]), array([2., 5., 4., 0., 1.]), array([3., 1., 0., 4., 5.]), array([4., 3., 0., 5., 2.]), array([5., 4., 3., 2., 1.]), array([2., 3., 0., 4., 5.]), array([2., 1., 3., 5., 0.]), array([0., 2., 5., 3., 1.]), array([1., 5., 3., 2., 4.]), array([2., 4., 3., 0., 5.]), array([5., 1., 4., 0., 3.]), array([3., 0., 4., 2., 1.]), array([1., 3., 0., 4., 2.]), array([5., 4., 0., 3., 1.]), array([3., 4., 2., 0., 5.]), array([3., 2., 1., 0., 5.]), array([1., 2., 5., 4., 0.]), array([3., 2., 1., 0., 4.]), array([1., 3., 0., 4., 2.]), array([3., 5., 4., 1., 2.]), array([2., 5., 0., 1., 3.]), array([3., 4., 1., 5., 0.]), array([5., 3., 2., 1., 0.]), array([2., 1., 0., 4., 3.]), array([3., 0., 1., 2., 5.]), array([5., 2., 1., 4., 3.]), array([2., 4., 0., 1., 3.]), array([2., 0., 3., 1., 5.]), array([0., 4., 3., 2., 1.]), array([2., 1., 4., 3., 0.]), array([3., 0., 1., 4., 2.])]\n"
     ]
    }
   ],
   "source": [
    "print(our_answer_1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare our answer with the correct answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc 1 : 0.6 ['E', 'D', 'C', 'B', 'A'] ['E', 'D', 'C', 'A', 'B']\n",
      "Doc 2 : 0.4 ['E', 'D', 'B', 'C', 'A'] ['E', 'D', 'C', 'A', 'B']\n",
      "Doc 3 : 0.6 ['A', 'B', 'E', 'F', 'C'] ['D', 'B', 'E', 'A', 'C']\n",
      "Doc 4 : 0.0 ['B', 'C', 'E', 'A', 'D'] ['C', 'E', 'A', 'D', 'B']\n",
      "Doc 5 : 0.6 ['C', 'B', 'E', 'D', 'A'] ['C', 'B', 'E', 'A', 'D']\n",
      "Doc 6 : 0.0 ['D', 'B', 'C', 'A', 'E'] ['C', 'E', 'A', 'D', 'B']\n",
      "Doc 7 : 0.4 ['C', 'D', 'B', 'E', 'A'] ['B', 'D', 'A', 'E', 'C']\n",
      "Doc 8 : 0.4 ['C', 'E', 'A', 'D', 'B'] ['A', 'E', 'D', 'C', 'B']\n",
      "Doc 9 : 0.2 ['B', 'E', 'D', 'C', 'A'] ['E', 'C', 'D', 'A', 'B']\n",
      "Doc 10 : 0.0 ['C', 'A', 'D', 'E', 'B'] ['E', 'D', 'A', 'B', 'C']\n",
      "Doc 11 : 0.4 ['F', 'B', 'A', 'C', 'D'] ['F', 'D', 'A', 'E', 'C']\n",
      "Doc 12 : 0.2 ['A', 'B', 'D', 'F', 'E'] ['B', 'A', 'D', 'E', 'F']\n",
      "Doc 13 : 0.2 ['E', 'D', 'B', 'F', 'C'] ['B', 'D', 'F', 'A', 'E']\n",
      "Doc 14 : 0.2 ['D', 'B', 'F', 'A', 'E'] ['E', 'A', 'F', 'C', 'D']\n",
      "Doc 15 : 0.4 ['E', 'F', 'B', 'A', 'D'] ['E', 'A', 'B', 'F', 'C']\n",
      "Doc 16 : 0.2 ['C', 'E', 'A', 'D', 'B'] ['F', 'E', 'C', 'B', 'D']\n",
      "Doc 17 : 0.4 ['C', 'E', 'A', 'D', 'B'] ['C', 'F', 'A', 'E', 'D']\n",
      "Doc 18 : 0.8 ['F', 'D', 'C', 'E', 'A'] ['F', 'D', 'C', 'E', 'B']\n",
      "Doc 19 : 0.2 ['F', 'A', 'E', 'C', 'D'] ['F', 'B', 'D', 'E', 'C']\n",
      "Doc 20 : 0.0 ['D', 'F', 'E', 'B', 'A'] ['E', 'A', 'D', 'C', 'F']\n",
      "Doc 21 : 0.6 ['B', 'C', 'A', 'F', 'E'] ['C', 'B', 'A', 'F', 'E']\n",
      "Doc 22 : 0.8 ['E', 'C', 'D', 'B', 'F'] ['E', 'A', 'D', 'B', 'F']\n",
      "Doc 23 : 0.5 ['B', 'A', 'C', 'D'] ['C', 'A', 'B', 'D']\n",
      "Doc 24 : 1.0 ['B', 'D', 'A', 'C'] ['B', 'D', 'A', 'C']\n",
      "Doc 25 : 0.0 ['C', 'D', 'B', 'A'] ['D', 'A', 'C', 'B']\n",
      "Doc 26 : 0.25 ['B', 'D', 'A', 'C'] ['A', 'B', 'D', 'C']\n",
      "Doc 27 : 1.0 ['C', 'D', 'A', 'B'] ['C', 'D', 'A', 'B']\n",
      "Doc 28 : 0.25 ['B', 'D', 'C', 'A'] ['B', 'C', 'A', 'D']\n",
      "Doc 29 : 0.25 ['D', 'B', 'C', 'A'] ['A', 'D', 'C', 'B']\n",
      "Doc 30 : 0.5 ['B', 'D', 'A', 'C'] ['B', 'A', 'D', 'C']\n",
      "Doc 31 : 0.5 ['A', 'C', 'B', 'D'] ['A', 'C', 'D', 'B']\n",
      "Doc 32 : 0.5 ['B', 'C', 'A', 'D'] ['C', 'B', 'A', 'D']\n",
      "Doc 33 : 0.5 ['A', 'B', 'C', 'D'] ['D', 'B', 'C', 'A']\n",
      "Doc 34 : 1.0 ['B', 'D', 'C', 'A'] ['B', 'D', 'C', 'A']\n",
      "Doc 35 : 0.0 ['A', 'B', 'D', 'C'] ['D', 'C', 'A', 'B']\n",
      "Doc 36 : 0.5 ['D', 'A', 'B', 'C'] ['A', 'D', 'B', 'C']\n",
      "Doc 37 : 0.0 ['A', 'B', 'D', 'C'] ['C', 'D', 'B', 'A']\n",
      "Doc 38 : 0.5 ['C', 'B', 'A', 'D'] ['C', 'B', 'D', 'A']\n",
      "Doc 39 : 0.5 ['C', 'A', 'B', 'D'] ['D', 'A', 'B', 'C']\n",
      "Doc 40 : 0.5 ['C', 'A', 'B', 'D'] ['A', 'C', 'B', 'D']\n",
      "Doc 41 : 0.5 ['B', 'A', 'D', 'C'] ['B', 'A', 'C', 'D']\n",
      "Doc 42 : 1.0 ['C', 'A', 'D', 'B'] ['C', 'A', 'D', 'B']\n",
      "Doc 43 : 0.8 ['E', 'A', 'C', 'D', 'B'] ['E', 'F', 'C', 'D', 'B']\n",
      "Doc 44 : 0.6 ['D', 'C', 'E', 'F', 'B'] ['D', 'C', 'F', 'E', 'B']\n",
      "Doc 45 : 0.4 ['C', 'F', 'E', 'D', 'A'] ['C', 'F', 'D', 'A', 'B']\n",
      "Doc 46 : 0.2 ['B', 'E', 'F', 'A', 'D'] ['E', 'C', 'F', 'D', 'B']\n",
      "Doc 47 : 0.2 ['A', 'E', 'F', 'C', 'D'] ['E', 'D', 'F', 'A', 'C']\n",
      "Doc 48 : 0.6 ['A', 'C', 'B', 'E', 'D'] ['F', 'C', 'B', 'E', 'A']\n",
      "Doc 49 : 0.6 ['A', 'B', 'C', 'E', 'F'] ['D', 'A', 'C', 'E', 'F']\n",
      "Doc 50 : 0.2 ['A', 'C', 'E', 'D', 'B'] ['D', 'E', 'F', 'A', 'B']\n",
      "Doc 51 : 0.2 ['D', 'B', 'E', 'F', 'C'] ['B', 'D', 'C', 'F', 'E']\n",
      "Doc 52 : 0.2 ['A', 'B', 'C', 'E', 'F'] ['D', 'C', 'F', 'E', 'B']\n",
      "Doc 53 : 0.2 ['B', 'C', 'D', 'F', 'A'] ['E', 'D', 'C', 'B', 'A']\n",
      "Doc 54 : 0.4 ['B', 'E', 'D', 'A', 'C'] ['F', 'E', 'C', 'A', 'D']\n",
      "Doc 55 : 0.2 ['D', 'C', 'F', 'B', 'E'] ['D', 'F', 'B', 'A', 'C']\n",
      "Doc 56 : 0.0 ['C', 'F', 'E', 'B', 'A'] ['E', 'C', 'B', 'D', 'F']\n",
      "Doc 57 : 0.0 ['B', 'E', 'A', 'C', 'F'] ['D', 'B', 'C', 'A', 'E']\n",
      "Doc 58 : 0.4 ['C', 'A', 'E', 'F', 'D'] ['B', 'E', 'C', 'F', 'D']\n",
      "Doc 59 : 0.4 ['C', 'B', 'F', 'E', 'A'] ['C', 'D', 'A', 'E', 'F']\n",
      "Doc 60 : 0.6 ['E', 'F', 'B', 'D', 'C'] ['A', 'F', 'B', 'D', 'E']\n",
      "Doc 61 : 0.2 ['F', 'A', 'E', 'C', 'B'] ['F', 'E', 'D', 'B', 'A']\n",
      "Doc 62 : 0.6 ['C', 'F', 'E', 'A', 'B'] ['C', 'E', 'D', 'A', 'B']\n",
      "Doc 63 : 0.0 ['D', 'B', 'A', 'E', 'F'] ['B', 'F', 'E', 'A', 'C']\n",
      "Doc 64 : 0.4 ['E', 'D', 'A', 'F', 'C'] ['E', 'B', 'D', 'F', 'A']\n",
      "Doc 65 : 0.0 ['F', 'E', 'D', 'C', 'B'] ['C', 'D', 'A', 'B', 'F']\n",
      "Doc 66 : 0.2 ['C', 'D', 'A', 'E', 'F'] ['C', 'F', 'D', 'B', 'E']\n",
      "Doc 67 : 0.2 ['C', 'B', 'D', 'F', 'A'] ['C', 'F', 'B', 'A', 'D']\n",
      "Doc 68 : 0.2 ['A', 'C', 'F', 'D', 'B'] ['A', 'D', 'C', 'E', 'F']\n",
      "Doc 69 : 0.0 ['B', 'F', 'D', 'C', 'E'] ['A', 'E', 'F', 'D', 'B']\n",
      "Doc 70 : 0.2 ['C', 'E', 'D', 'A', 'F'] ['C', 'F', 'B', 'E', 'D']\n",
      "Doc 71 : 0.2 ['F', 'B', 'E', 'A', 'D'] ['F', 'D', 'A', 'E', 'C']\n",
      "Doc 72 : 0.4 ['D', 'A', 'E', 'C', 'B'] ['D', 'F', 'E', 'B', 'C']\n",
      "Doc 73 : 0.0 ['B', 'D', 'A', 'E', 'C'] ['D', 'B', 'E', 'A', 'F']\n",
      "Doc 74 : 0.2 ['F', 'E', 'A', 'D', 'B'] ['C', 'E', 'D', 'F', 'A']\n",
      "Doc 75 : 0.4 ['D', 'E', 'C', 'A', 'F'] ['F', 'B', 'C', 'A', 'D']\n",
      "Doc 76 : 0.4 ['D', 'C', 'B', 'A', 'F'] ['B', 'E', 'C', 'A', 'F']\n",
      "Doc 77 : 0.2 ['B', 'C', 'F', 'E', 'A'] ['C', 'A', 'F', 'B', 'D']\n",
      "Doc 78 : 0.6 ['D', 'C', 'B', 'A', 'E'] ['F', 'D', 'B', 'A', 'E']\n",
      "Doc 79 : 0.2 ['B', 'D', 'A', 'E', 'C'] ['D', 'F', 'C', 'E', 'A']\n",
      "Doc 80 : 0.6 ['D', 'F', 'E', 'B', 'C'] ['D', 'F', 'E', 'C', 'A']\n",
      "Doc 81 : 1.0 ['C', 'F', 'A', 'B', 'D'] ['C', 'F', 'A', 'B', 'D']\n",
      "Doc 82 : 0.6 ['D', 'E', 'B', 'F', 'A'] ['D', 'E', 'F', 'C', 'A']\n",
      "Doc 83 : 0.2 ['F', 'D', 'C', 'B', 'A'] ['D', 'C', 'E', 'F', 'A']\n",
      "Doc 84 : 0.2 ['C', 'B', 'A', 'E', 'D'] ['B', 'C', 'A', 'D', 'E']\n",
      "Doc 85 : 0.4 ['D', 'A', 'B', 'C', 'F'] ['D', 'A', 'F', 'B', 'C']\n",
      "Doc 86 : 0.6 ['F', 'C', 'B', 'E', 'D'] ['F', 'C', 'A', 'E', 'B']\n",
      "Doc 87 : 0.6 ['C', 'E', 'A', 'B', 'D'] ['C', 'E', 'B', 'A', 'D']\n",
      "Doc 88 : 0.6 ['C', 'A', 'D', 'B', 'F'] ['C', 'F', 'D', 'B', 'A']\n",
      "Doc 89 : 0.2 ['A', 'E', 'D', 'C', 'B'] ['B', 'E', 'C', 'D', 'A']\n",
      "Doc 90 : 0.4 ['C', 'B', 'E', 'D', 'A'] ['C', 'D', 'E', 'A', 'B']\n",
      "Doc 91 : 0.6 ['D', 'A', 'B', 'E', 'C'] ['D', 'A', 'E', 'B', 'C']\n"
     ]
    }
   ],
   "source": [
    "correct_rate = []\n",
    "\n",
    "for i in range(len(our_answer_1)):\n",
    "  count = 0\n",
    "  ours = []\n",
    "  correct = []\n",
    "  for j in range(len(our_answer_1[i])):\n",
    "    correct.append(ans_df.iloc[i][j+1])\n",
    "    if (our_answer_1[i][j] == 0):\n",
    "      ours.append('A')\n",
    "    elif (our_answer_1[i][j] == 1):\n",
    "      ours.append('B')\n",
    "    elif (our_answer_1[i][j] == 2):\n",
    "      ours.append('C')\n",
    "    elif (our_answer_1[i][j] == 3):\n",
    "      ours.append('D')\n",
    "    elif (our_answer_1[i][j] == 4):\n",
    "      ours.append('E')\n",
    "    elif (our_answer_1[i][j] == 5):\n",
    "      ours.append('F')\n",
    "    if (ans_df.iloc[i][j+1] == ours[j]):\n",
    "      count += 1\n",
    "  print(\"Doc\", i+1, \":\", count/len(our_answer_1[i]), ours, correct)\n",
    "  correct_rate.append(count/len(our_answer_1[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6, 0.4, 0.6, 0.0, 0.6, 0.0, 0.4, 0.4, 0.2, 0.0, 0.4, 0.2, 0.2, 0.2, 0.4, 0.2, 0.4, 0.8, 0.2, 0.0, 0.6, 0.8, 0.5, 1.0, 0.0, 0.25, 1.0, 0.25, 0.25, 0.5, 0.5, 0.5, 0.5, 1.0, 0.0, 0.5, 0.0, 0.5, 0.5, 0.5, 0.5, 1.0, 0.8, 0.6, 0.4, 0.2, 0.2, 0.6, 0.6, 0.2, 0.2, 0.2, 0.2, 0.4, 0.2, 0.0, 0.0, 0.4, 0.4, 0.6, 0.2, 0.6, 0.0, 0.4, 0.0, 0.2, 0.2, 0.2, 0.0, 0.2, 0.2, 0.4, 0.0, 0.2, 0.4, 0.4, 0.2, 0.6, 0.2, 0.6, 1.0, 0.6, 0.2, 0.2, 0.4, 0.6, 0.6, 0.6, 0.2, 0.4, 0.6]\n"
     ]
    }
   ],
   "source": [
    "print(correct_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37527472527472533"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(correct_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0.6: 16, 0.4: 16, 0.0: 13, 0.2: 25, 0.8: 3, 0.5: 10, 1.0: 5, 0.25: 3})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "collections.Counter(correct_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.  0.34545454545454546 Counter({0.4: 6, 0.2: 6, 0.6: 4, 0.0: 4, 0.8: 2})\n",
      "2.  0.4875 Counter({0.5: 10, 1.0: 4, 0.0: 3, 0.25: 3})\n",
      "3.  0.35 Counter({0.2: 8, 0.6: 5, 0.4: 4, 0.0: 2, 0.8: 1})\n",
      "4.  0.3379310344827586 Counter({0.2: 11, 0.6: 7, 0.4: 6, 0.0: 4, 1.0: 1})\n"
     ]
    }
   ],
   "source": [
    "print(\"1. \", np.mean(correct_rate[0:22]), collections.Counter(correct_rate[0:22]))\n",
    "print(\"2. \", np.mean(correct_rate[22:42]), collections.Counter(correct_rate[22:42]))\n",
    "print(\"3. \", np.mean(correct_rate[42:62]), collections.Counter(correct_rate[42:62]))\n",
    "print(\"4. \", np.mean(correct_rate[62:91]), collections.Counter(correct_rate[62:91]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-2 Use linear sum assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0 3 2 4 1]\n",
      "1 [4 3 2 0 1]\n",
      "2 [3 1 4 0 2]\n",
      "3 [0 1 4 2 3]\n",
      "4 [2 1 4 3 0]\n",
      "5 [3 4 2 0 1]\n",
      "6 [1 3 4 2 0]\n",
      "7 [0 4 3 2 1]\n",
      "8 [2 4 1 3 0]\n",
      "9 [4 0 3 1 2]\n",
      "10 [5 1 0 2 3]\n",
      "11 [1 0 3 5 4]\n",
      "12 [0 3 5 2 4]\n",
      "13 [3 1 0 5 4]\n",
      "14 [4 1 0 5 3]\n",
      "15 [5 4 2 3 0]\n",
      "16 [1 5 0 2 4]\n",
      "17 [5 3 2 4 0]\n",
      "18 [5 3 4 0 2]\n",
      "19 [4 1 5 3 0]\n",
      "20 [2 1 0 5 4]\n",
      "21 [4 3 2 1 5]\n",
      "22 [2 0 1 3]\n",
      "23 [1 3 0 2]\n",
      "24 [3 0 1 2]\n",
      "25 [0 3 1 2]\n",
      "26 [2 0 3 1]\n",
      "27 [1 2 0 3]\n",
      "28 [3 1 2 0]\n",
      "29 [1 0 3 2]\n",
      "30 [0 2 1 3]\n",
      "31 [2 1 0 3]\n",
      "32 [2 1 0 3]\n",
      "33 [1 3 2 0]\n",
      "34 [1 3 0 2]\n",
      "35 [0 3 1 2]\n",
      "36 [0 3 1 2]\n",
      "37 [2 1 3 0]\n",
      "38 [3 0 1 2]\n",
      "39 [3 2 1 0]\n",
      "40 [1 2 3 0]\n",
      "41 [0 2 3 1]\n",
      "42 [4 5 0 2 1]\n",
      "43 [5 0 4 1 2]\n",
      "44 [2 3 0 4 5]\n",
      "45 [4 1 5 3 0]\n",
      "46 [0 4 3 5 2]\n",
      "47 [5 2 0 1 3]\n",
      "48 [1 0 2 4 5]\n",
      "49 [3 4 5 0 2]\n",
      "50 [1 3 2 5 4]\n",
      "51 [5 2 0 4 1]\n",
      "52 [0 3 2 5 1]\n",
      "53 [1 2 4 0 3]\n",
      "54 [3 1 5 4 0]\n",
      "55 [4 0 1 2 5]\n",
      "56 [3 1 0 2 5]\n",
      "57 [2 0 4 5 3]\n",
      "58 [1 2 5 4 0]\n",
      "59 [2 5 1 3 4]\n",
      "60 [1 4 0 5 2]\n",
      "61 [5 4 3 0 1]\n",
      "62 [5 1 3 4 0]\n",
      "63 [4 0 3 5 2]\n",
      "64 [2 3 4 1 5]\n",
      "65 [2 5 4 1 3]\n",
      "66 [2 0 5 1 3]\n",
      "67 [0 1 3 2 5]\n",
      "68 [5 4 3 2 1]\n",
      "69 [0 4 2 3 5]\n",
      "70 [2 3 4 0 5]\n",
      "71 [3 4 0 2 1]\n",
      "72 [3 1 0 2 4]\n",
      "73 [0 4 3 5 1]\n",
      "74 [0 1 4 2 3]\n",
      "75 [3 4 2 1 5]\n",
      "76 [1 2 5 4 0]\n",
      "77 [3 4 1 0 2]\n",
      "78 [3 0 2 1 4]\n",
      "79 [3 1 5 4 2]\n",
      "80 [2 5 0 1 3]\n",
      "81 [4 3 1 5 0]\n",
      "82 [5 1 2 3 0]\n",
      "83 [2 1 0 3 4]\n",
      "84 [3 0 1 5 2]\n",
      "85 [5 2 1 4 3]\n",
      "86 [1 4 0 3 2]\n",
      "87 [4 2 3 1 0]\n",
      "88 [3 4 2 1 0]\n",
      "89 [2 3 4 1 0]\n",
      "90 [3 0 4 1 2]\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import linear_sum_assignment\n",
    "our_answer_2 = []\n",
    "tmp_prob_for_LSA = answer_prob\n",
    "\n",
    "for i in range(len(answer_prob)):\n",
    "  for j in range(len(answer_prob[i])):\n",
    "    for k in range(len(answer_prob[i][j])):\n",
    "      tmp_prob_for_LSA[i][j][k] = -tmp_prob_for_LSA[i][j][k]\n",
    "  row_ind, col_ind = linear_sum_assignment(tmp_prob_for_LSA[i])\n",
    "  our_answer_2.append(col_ind)\n",
    "  print(i, col_ind)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare our answer with the correct answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc 1 : 0.6 ['A', 'D', 'C', 'E', 'B'] ['E', 'D', 'C', 'A', 'B']\n",
      "Doc 2 : 1.0 ['E', 'D', 'C', 'A', 'B'] ['E', 'D', 'C', 'A', 'B']\n",
      "Doc 3 : 1.0 ['D', 'B', 'E', 'A', 'C'] ['D', 'B', 'E', 'A', 'C']\n",
      "Doc 4 : 0.0 ['A', 'B', 'E', 'C', 'D'] ['C', 'E', 'A', 'D', 'B']\n",
      "Doc 5 : 0.6 ['C', 'B', 'E', 'D', 'A'] ['C', 'B', 'E', 'A', 'D']\n",
      "Doc 6 : 0.4 ['D', 'E', 'C', 'A', 'B'] ['C', 'E', 'A', 'D', 'B']\n",
      "Doc 7 : 0.4 ['B', 'D', 'E', 'C', 'A'] ['B', 'D', 'A', 'E', 'C']\n",
      "Doc 8 : 1.0 ['A', 'E', 'D', 'C', 'B'] ['A', 'E', 'D', 'C', 'B']\n",
      "Doc 9 : 0.0 ['C', 'E', 'B', 'D', 'A'] ['E', 'C', 'D', 'A', 'B']\n",
      "Doc 10 : 0.6 ['E', 'A', 'D', 'B', 'C'] ['E', 'D', 'A', 'B', 'C']\n",
      "Doc 11 : 0.4 ['F', 'B', 'A', 'C', 'D'] ['F', 'D', 'A', 'E', 'C']\n",
      "Doc 12 : 0.6 ['B', 'A', 'D', 'F', 'E'] ['B', 'A', 'D', 'E', 'F']\n",
      "Doc 13 : 0.6 ['A', 'D', 'F', 'C', 'E'] ['B', 'D', 'F', 'A', 'E']\n",
      "Doc 14 : 0.0 ['D', 'B', 'A', 'F', 'E'] ['E', 'A', 'F', 'C', 'D']\n",
      "Doc 15 : 0.4 ['E', 'B', 'A', 'F', 'D'] ['E', 'A', 'B', 'F', 'C']\n",
      "Doc 16 : 0.6 ['F', 'E', 'C', 'D', 'A'] ['F', 'E', 'C', 'B', 'D']\n",
      "Doc 17 : 0.4 ['B', 'F', 'A', 'C', 'E'] ['C', 'F', 'A', 'E', 'D']\n",
      "Doc 18 : 0.8 ['F', 'D', 'C', 'E', 'A'] ['F', 'D', 'C', 'E', 'B']\n",
      "Doc 19 : 0.4 ['F', 'D', 'E', 'A', 'C'] ['F', 'B', 'D', 'E', 'C']\n",
      "Doc 20 : 0.2 ['E', 'B', 'F', 'D', 'A'] ['E', 'A', 'D', 'C', 'F']\n",
      "Doc 21 : 1.0 ['C', 'B', 'A', 'F', 'E'] ['C', 'B', 'A', 'F', 'E']\n",
      "Doc 22 : 0.6 ['E', 'D', 'C', 'B', 'F'] ['E', 'A', 'D', 'B', 'F']\n",
      "Doc 23 : 1.0 ['C', 'A', 'B', 'D'] ['C', 'A', 'B', 'D']\n",
      "Doc 24 : 1.0 ['B', 'D', 'A', 'C'] ['B', 'D', 'A', 'C']\n",
      "Doc 25 : 0.5 ['D', 'A', 'B', 'C'] ['D', 'A', 'C', 'B']\n",
      "Doc 26 : 0.5 ['A', 'D', 'B', 'C'] ['A', 'B', 'D', 'C']\n",
      "Doc 27 : 0.5 ['C', 'A', 'D', 'B'] ['C', 'D', 'A', 'B']\n",
      "Doc 28 : 1.0 ['B', 'C', 'A', 'D'] ['B', 'C', 'A', 'D']\n",
      "Doc 29 : 0.25 ['D', 'B', 'C', 'A'] ['A', 'D', 'C', 'B']\n",
      "Doc 30 : 1.0 ['B', 'A', 'D', 'C'] ['B', 'A', 'D', 'C']\n",
      "Doc 31 : 0.5 ['A', 'C', 'B', 'D'] ['A', 'C', 'D', 'B']\n",
      "Doc 32 : 1.0 ['C', 'B', 'A', 'D'] ['C', 'B', 'A', 'D']\n",
      "Doc 33 : 0.25 ['C', 'B', 'A', 'D'] ['D', 'B', 'C', 'A']\n",
      "Doc 34 : 1.0 ['B', 'D', 'C', 'A'] ['B', 'D', 'C', 'A']\n",
      "Doc 35 : 0.25 ['B', 'D', 'A', 'C'] ['D', 'C', 'A', 'B']\n",
      "Doc 36 : 1.0 ['A', 'D', 'B', 'C'] ['A', 'D', 'B', 'C']\n",
      "Doc 37 : 0.5 ['A', 'D', 'B', 'C'] ['C', 'D', 'B', 'A']\n",
      "Doc 38 : 1.0 ['C', 'B', 'D', 'A'] ['C', 'B', 'D', 'A']\n",
      "Doc 39 : 1.0 ['D', 'A', 'B', 'C'] ['D', 'A', 'B', 'C']\n",
      "Doc 40 : 0.5 ['D', 'C', 'B', 'A'] ['A', 'C', 'B', 'D']\n",
      "Doc 41 : 0.25 ['B', 'C', 'D', 'A'] ['B', 'A', 'C', 'D']\n",
      "Doc 42 : 0.5 ['A', 'C', 'D', 'B'] ['C', 'A', 'D', 'B']\n",
      "Doc 43 : 0.6 ['E', 'F', 'A', 'C', 'B'] ['E', 'F', 'C', 'D', 'B']\n",
      "Doc 44 : 0.0 ['F', 'A', 'E', 'B', 'C'] ['D', 'C', 'F', 'E', 'B']\n",
      "Doc 45 : 0.2 ['C', 'D', 'A', 'E', 'F'] ['C', 'F', 'D', 'A', 'B']\n",
      "Doc 46 : 0.6 ['E', 'B', 'F', 'D', 'A'] ['E', 'C', 'F', 'D', 'B']\n",
      "Doc 47 : 0.2 ['A', 'E', 'D', 'F', 'C'] ['E', 'D', 'F', 'A', 'C']\n",
      "Doc 48 : 0.4 ['F', 'C', 'A', 'B', 'D'] ['F', 'C', 'B', 'E', 'A']\n",
      "Doc 49 : 0.8 ['B', 'A', 'C', 'E', 'F'] ['D', 'A', 'C', 'E', 'F']\n",
      "Doc 50 : 0.8 ['D', 'E', 'F', 'A', 'C'] ['D', 'E', 'F', 'A', 'B']\n",
      "Doc 51 : 1.0 ['B', 'D', 'C', 'F', 'E'] ['B', 'D', 'C', 'F', 'E']\n",
      "Doc 52 : 0.6 ['F', 'C', 'A', 'E', 'B'] ['D', 'C', 'F', 'E', 'B']\n",
      "Doc 53 : 0.4 ['A', 'D', 'C', 'F', 'B'] ['E', 'D', 'C', 'B', 'A']\n",
      "Doc 54 : 0.4 ['B', 'C', 'E', 'A', 'D'] ['F', 'E', 'C', 'A', 'D']\n",
      "Doc 55 : 0.2 ['D', 'B', 'F', 'E', 'A'] ['D', 'F', 'B', 'A', 'C']\n",
      "Doc 56 : 0.6 ['E', 'A', 'B', 'C', 'F'] ['E', 'C', 'B', 'D', 'F']\n",
      "Doc 57 : 0.4 ['D', 'B', 'A', 'C', 'F'] ['D', 'B', 'C', 'A', 'E']\n",
      "Doc 58 : 0.4 ['C', 'A', 'E', 'F', 'D'] ['B', 'E', 'C', 'F', 'D']\n",
      "Doc 59 : 0.2 ['B', 'C', 'F', 'E', 'A'] ['C', 'D', 'A', 'E', 'F']\n",
      "Doc 60 : 0.8 ['C', 'F', 'B', 'D', 'E'] ['A', 'F', 'B', 'D', 'E']\n",
      "Doc 61 : 0.2 ['B', 'E', 'A', 'F', 'C'] ['F', 'E', 'D', 'B', 'A']\n",
      "Doc 62 : 0.8 ['F', 'E', 'D', 'A', 'B'] ['C', 'E', 'D', 'A', 'B']\n",
      "Doc 63 : 0.0 ['F', 'B', 'D', 'E', 'A'] ['B', 'F', 'E', 'A', 'C']\n",
      "Doc 64 : 0.6 ['E', 'A', 'D', 'F', 'C'] ['E', 'B', 'D', 'F', 'A']\n",
      "Doc 65 : 0.8 ['C', 'D', 'E', 'B', 'F'] ['C', 'D', 'A', 'B', 'F']\n",
      "Doc 66 : 0.6 ['C', 'F', 'E', 'B', 'D'] ['C', 'F', 'D', 'B', 'E']\n",
      "Doc 67 : 0.4 ['C', 'A', 'F', 'B', 'D'] ['C', 'F', 'B', 'A', 'D']\n",
      "Doc 68 : 0.4 ['A', 'B', 'D', 'C', 'F'] ['A', 'D', 'C', 'E', 'F']\n",
      "Doc 69 : 0.4 ['F', 'E', 'D', 'C', 'B'] ['A', 'E', 'F', 'D', 'B']\n",
      "Doc 70 : 0.0 ['A', 'E', 'C', 'D', 'F'] ['C', 'F', 'B', 'E', 'D']\n",
      "Doc 71 : 0.2 ['C', 'D', 'E', 'A', 'F'] ['F', 'D', 'A', 'E', 'C']\n",
      "Doc 72 : 0.2 ['D', 'E', 'A', 'C', 'B'] ['D', 'F', 'E', 'B', 'C']\n",
      "Doc 73 : 0.4 ['D', 'B', 'A', 'C', 'E'] ['D', 'B', 'E', 'A', 'F']\n",
      "Doc 74 : 0.6 ['A', 'E', 'D', 'F', 'B'] ['C', 'E', 'D', 'F', 'A']\n",
      "Doc 75 : 0.4 ['A', 'B', 'E', 'C', 'D'] ['F', 'B', 'C', 'A', 'D']\n",
      "Doc 76 : 0.6 ['D', 'E', 'C', 'B', 'F'] ['B', 'E', 'C', 'A', 'F']\n",
      "Doc 77 : 0.2 ['B', 'C', 'F', 'E', 'A'] ['C', 'A', 'F', 'B', 'D']\n",
      "Doc 78 : 0.4 ['D', 'E', 'B', 'A', 'C'] ['F', 'D', 'B', 'A', 'E']\n",
      "Doc 79 : 0.4 ['D', 'A', 'C', 'B', 'E'] ['D', 'F', 'C', 'E', 'A']\n",
      "Doc 80 : 0.2 ['D', 'B', 'F', 'E', 'C'] ['D', 'F', 'E', 'C', 'A']\n",
      "Doc 81 : 1.0 ['C', 'F', 'A', 'B', 'D'] ['C', 'F', 'A', 'B', 'D']\n",
      "Doc 82 : 0.2 ['E', 'D', 'B', 'F', 'A'] ['D', 'E', 'F', 'C', 'A']\n",
      "Doc 83 : 0.2 ['F', 'B', 'C', 'D', 'A'] ['D', 'C', 'E', 'F', 'A']\n",
      "Doc 84 : 0.6 ['C', 'B', 'A', 'D', 'E'] ['B', 'C', 'A', 'D', 'E']\n",
      "Doc 85 : 0.6 ['D', 'A', 'B', 'F', 'C'] ['D', 'A', 'F', 'B', 'C']\n",
      "Doc 86 : 0.6 ['F', 'C', 'B', 'E', 'D'] ['F', 'C', 'A', 'E', 'B']\n",
      "Doc 87 : 0.2 ['B', 'E', 'A', 'D', 'C'] ['C', 'E', 'B', 'A', 'D']\n",
      "Doc 88 : 0.6 ['E', 'C', 'D', 'B', 'A'] ['C', 'F', 'D', 'B', 'A']\n",
      "Doc 89 : 0.6 ['D', 'E', 'C', 'B', 'A'] ['B', 'E', 'C', 'D', 'A']\n",
      "Doc 90 : 0.6 ['C', 'D', 'E', 'B', 'A'] ['C', 'D', 'E', 'A', 'B']\n",
      "Doc 91 : 1.0 ['D', 'A', 'E', 'B', 'C'] ['D', 'A', 'E', 'B', 'C']\n"
     ]
    }
   ],
   "source": [
    "correct_rate = []\n",
    "\n",
    "for i in range(len(our_answer_2)):\n",
    "  count = 0\n",
    "  ours = []\n",
    "  correct = []\n",
    "  for j in range(len(our_answer_2[i])):\n",
    "    correct.append(ans_df.iloc[i][j+1])\n",
    "    if (our_answer_2[i][j] == 0):\n",
    "      ours.append('A')\n",
    "    elif (our_answer_2[i][j] == 1):\n",
    "      ours.append('B')\n",
    "    elif (our_answer_2[i][j] == 2):\n",
    "      ours.append('C')\n",
    "    elif (our_answer_2[i][j] == 3):\n",
    "      ours.append('D')\n",
    "    elif (our_answer_2[i][j] == 4):\n",
    "      ours.append('E')\n",
    "    elif (our_answer_2[i][j] == 5):\n",
    "      ours.append('F')\n",
    "    if (ans_df.iloc[i][j+1] == ours[j]):\n",
    "      count += 1\n",
    "  print(\"Doc\", i+1, \":\", count/len(our_answer_2[i]), ours, correct)\n",
    "  correct_rate.append(count/len(our_answer_2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5241758241758242"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(correct_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0.6: 21, 1.0: 16, 0.0: 6, 0.4: 18, 0.8: 6, 0.2: 13, 0.5: 7, 0.25: 4})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "collections.Counter(correct_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.  0.5272727272727272 Counter({0.6: 7, 0.4: 6, 1.0: 4, 0.0: 3, 0.8: 1, 0.2: 1})\n",
      "2.  0.675 Counter({1.0: 9, 0.5: 7, 0.25: 4})\n",
      "3.  0.4800000000000001 Counter({0.2: 5, 0.4: 5, 0.6: 4, 0.8: 4, 0.0: 1, 1.0: 1})\n",
      "4.  0.44827586206896547 Counter({0.6: 10, 0.4: 7, 0.2: 7, 0.0: 2, 1.0: 2, 0.8: 1})\n"
     ]
    }
   ],
   "source": [
    "print(\"1. \", np.mean(correct_rate[0:22]), collections.Counter(correct_rate[0:22]))\n",
    "print(\"2. \", np.mean(correct_rate[22:42]), collections.Counter(correct_rate[22:42]))\n",
    "print(\"3. \", np.mean(correct_rate[42:62]), collections.Counter(correct_rate[42:62]))\n",
    "print(\"4. \", np.mean(correct_rate[62:91]), collections.Counter(correct_rate[62:91]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
