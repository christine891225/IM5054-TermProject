{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read files including `Answer`, `Choice`, `Question`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Files to List\n",
    "doc_num = 91\n",
    "question_doc = []\n",
    "choice_doc = []\n",
    "ans_doc = []\n",
    "\n",
    "for i in range(1, doc_num + 1):\n",
    "    try:\n",
    "        with open(f'Data/Question/{i}.txt', encoding='utf-8') as f:\n",
    "            raw_q = f.read()\n",
    "    except:\n",
    "        with open(f'Data/Question/{i}.txt', encoding='big5') as f:\n",
    "            raw_q = f.read()\n",
    "    try:\n",
    "        with open(f'Data/Choice/{i}.txt', encoding='utf-8') as f:\n",
    "            raw_ch = f.read()\n",
    "    except:\n",
    "        with open(f'Data/Choice/{i}.txt', encoding='big5') as f:\n",
    "            raw_ch = f.read()\n",
    "    try:\n",
    "        with open(f'Data/Answer/{i}.txt', encoding='utf-8') as f:\n",
    "            raw_a = f.read()\n",
    "    except:\n",
    "        with open(f'Data/Answer/{i}.txt', encoding='big5') as f:\n",
    "            raw_a = f.read()\n",
    "    question_doc.append(raw_q)\n",
    "    choice_doc.append(raw_ch.split('\\n'))\n",
    "    ans_doc.append(list(raw_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nothing is made up.</td>\n",
       "      <td>History is nonfiction, too.</td>\n",
       "      <td>But your trip through space would be fiction.</td>\n",
       "      <td>You could write a story in which you fly to t...</td>\n",
       "      <td>But fiction isn’t always different from the w...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>But when I pulled into the driveway, there wa...</td>\n",
       "      <td>Hours later I called my daughter and asked if...</td>\n",
       "      <td>One time, I even shouted at Derek when he unp...</td>\n",
       "      <td>Derek became part of our life and seemed to f...</td>\n",
       "      <td>Without any experience in raising pets, my hu...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Another genre commonly found in Chinese brush...</td>\n",
       "      <td>However, the subject matters later expanded b...</td>\n",
       "      <td>As a result, they have obtained more natural ...</td>\n",
       "      <td>Its growth has inevitably reflected the chang...</td>\n",
       "      <td>It then gradually developed into two separate...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>She got to look at the fine old houses as wel...</td>\n",
       "      <td>Architects make drawings and careful plans of...</td>\n",
       "      <td>The word for what she does is rehabilitation.</td>\n",
       "      <td>Then she went on to study architecture.</td>\n",
       "      <td>That is precisely what Carrie does.</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>There are definitely two sides to this issue.</td>\n",
       "      <td>Scores decreased as the family size increased...</td>\n",
       "      <td>An intelligence test was administered to over...</td>\n",
       "      <td>On the other side are Rutherford and Sewell, ...</td>\n",
       "      <td>Since then, the theory has been elaborated an...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   A  \\\n",
       "1                                Nothing is made up.   \n",
       "2   But when I pulled into the driveway, there wa...   \n",
       "3   Another genre commonly found in Chinese brush...   \n",
       "4   She got to look at the fine old houses as wel...   \n",
       "5      There are definitely two sides to this issue.   \n",
       "\n",
       "                                                   B  \\\n",
       "1                        History is nonfiction, too.   \n",
       "2   Hours later I called my daughter and asked if...   \n",
       "3   However, the subject matters later expanded b...   \n",
       "4   Architects make drawings and careful plans of...   \n",
       "5   Scores decreased as the family size increased...   \n",
       "\n",
       "                                                   C  \\\n",
       "1      But your trip through space would be fiction.   \n",
       "2   One time, I even shouted at Derek when he unp...   \n",
       "3   As a result, they have obtained more natural ...   \n",
       "4      The word for what she does is rehabilitation.   \n",
       "5   An intelligence test was administered to over...   \n",
       "\n",
       "                                                   D  \\\n",
       "1   You could write a story in which you fly to t...   \n",
       "2   Derek became part of our life and seemed to f...   \n",
       "3   Its growth has inevitably reflected the chang...   \n",
       "4            Then she went on to study architecture.   \n",
       "5   On the other side are Rutherford and Sewell, ...   \n",
       "\n",
       "                                                   E     F  \n",
       "1   But fiction isn’t always different from the w...  None  \n",
       "2   Without any experience in raising pets, my hu...  None  \n",
       "3   It then gradually developed into two separate...        \n",
       "4                That is precisely what Carrie does.  None  \n",
       "5   Since then, the theory has been elaborated an...  None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1  2  3  4  5\n",
       "1  E  D  C  A  B\n",
       "2  E  D  C  A  B\n",
       "3  D  B  E  A  C\n",
       "4  C  E  A  D  B\n",
       "5  C  B  E  A  D"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "choice_cols = ['A', 'B', 'C', 'D', 'E', 'F']\n",
    "choice_df = pd.DataFrame(choice_doc, columns=choice_cols, index=[i + 1 for i in range(len(choice_doc))])\n",
    "for col in choice_cols:\n",
    "    choice_df[col] = choice_df[col].str.replace(r'\\([A-F]\\)', '')\n",
    "\n",
    "ans_cols = [1, 2, 3, 4, 5]\n",
    "ans_df = pd.DataFrame(ans_doc, columns=ans_cols, index=[i + 1 for i in range(len(choice_doc))])\n",
    "\n",
    "display(choice_df.head())\n",
    "display(ans_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. BERT (NSP)\n",
    "code ref: https://towardsdatascience.com/bert-for-next-sentence-prediction-466b67f8226f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForNextSentencePrediction: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# pip3 install transformers\n",
    "# pip3 install torch\n",
    "\n",
    "from transformers import BertTokenizer, BertForNextSentencePrediction\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Finish Doc 1 ===\n",
      "=== Finish Doc 2 ===\n",
      "=== Finish Doc 3 ===\n",
      "=== Finish Doc 4 ===\n",
      "=== Finish Doc 5 ===\n",
      "=== Finish Doc 6 ===\n",
      "=== Finish Doc 7 ===\n",
      "=== Finish Doc 8 ===\n",
      "=== Finish Doc 9 ===\n",
      "=== Finish Doc 10 ===\n",
      "=== Finish Doc 11 ===\n",
      "=== Finish Doc 12 ===\n",
      "=== Finish Doc 13 ===\n",
      "=== Finish Doc 14 ===\n",
      "=== Finish Doc 15 ===\n",
      "=== Finish Doc 16 ===\n",
      "=== Finish Doc 17 ===\n",
      "=== Finish Doc 18 ===\n",
      "=== Finish Doc 19 ===\n",
      "=== Finish Doc 20 ===\n",
      "=== Finish Doc 21 ===\n",
      "=== Finish Doc 22 ===\n",
      "=== Finish Doc 23 ===\n",
      "=== Finish Doc 24 ===\n",
      "=== Finish Doc 25 ===\n",
      "=== Finish Doc 26 ===\n",
      "=== Finish Doc 27 ===\n",
      "=== Finish Doc 28 ===\n",
      "=== Finish Doc 29 ===\n",
      "=== Finish Doc 30 ===\n",
      "=== Finish Doc 31 ===\n",
      "=== Finish Doc 32 ===\n",
      "=== Finish Doc 33 ===\n",
      "=== Finish Doc 34 ===\n",
      "=== Finish Doc 35 ===\n",
      "=== Finish Doc 36 ===\n",
      "=== Finish Doc 37 ===\n",
      "=== Finish Doc 38 ===\n",
      "=== Finish Doc 39 ===\n",
      "=== Finish Doc 40 ===\n",
      "=== Finish Doc 41 ===\n",
      "=== Finish Doc 42 ===\n",
      "=== Finish Doc 43 ===\n",
      "=== Finish Doc 44 ===\n",
      "=== Finish Doc 45 ===\n",
      "=== Finish Doc 46 ===\n",
      "=== Finish Doc 47 ===\n",
      "=== Finish Doc 48 ===\n",
      "=== Finish Doc 49 ===\n",
      "=== Finish Doc 50 ===\n",
      "=== Finish Doc 51 ===\n",
      "=== Finish Doc 52 ===\n",
      "=== Finish Doc 53 ===\n",
      "=== Finish Doc 54 ===\n",
      "=== Finish Doc 55 ===\n",
      "=== Finish Doc 56 ===\n",
      "=== Finish Doc 57 ===\n",
      "=== Finish Doc 58 ===\n",
      "=== Finish Doc 59 ===\n",
      "=== Finish Doc 60 ===\n",
      "=== Finish Doc 61 ===\n",
      "=== Finish Doc 62 ===\n",
      "=== Finish Doc 63 ===\n",
      "=== Finish Doc 64 ===\n",
      "=== Finish Doc 65 ===\n",
      "=== Finish Doc 66 ===\n",
      "=== Finish Doc 67 ===\n",
      "=== Finish Doc 68 ===\n",
      "=== Finish Doc 69 ===\n",
      "=== Finish Doc 70 ===\n",
      "=== Finish Doc 71 ===\n",
      "=== Finish Doc 72 ===\n",
      "=== Finish Doc 73 ===\n",
      "=== Finish Doc 74 ===\n",
      "=== Finish Doc 75 ===\n",
      "=== Finish Doc 76 ===\n",
      "=== Finish Doc 77 ===\n",
      "=== Finish Doc 78 ===\n",
      "=== Finish Doc 79 ===\n",
      "=== Finish Doc 80 ===\n",
      "=== Finish Doc 81 ===\n",
      "=== Finish Doc 82 ===\n",
      "=== Finish Doc 83 ===\n",
      "=== Finish Doc 84 ===\n",
      "=== Finish Doc 85 ===\n",
      "=== Finish Doc 86 ===\n",
      "=== Finish Doc 87 ===\n",
      "=== Finish Doc 88 ===\n",
      "=== Finish Doc 89 ===\n",
      "=== Finish Doc 90 ===\n",
      "=== Finish Doc 91 ===\n"
     ]
    }
   ],
   "source": [
    "count_NotNextSentence = 0\n",
    "NotNextSentence = []\n",
    "\n",
    "for i in range(len(question_doc)): # each document\n",
    "  question_sentence = re.split('\\(1\\)|\\(2\\)|\\(3\\)|\\(4\\)|\\(5\\)', question_doc[i])\n",
    "  for j in range(5): # each question\n",
    "      for k in range(6): # each option\n",
    "        if (choice_df.iloc[i][choice_cols[k]] != 'None'):\n",
    "          inputs = tokenizer(question_sentence[j], choice_df.iloc[i][choice_cols[k]], return_tensors='pt')\n",
    "          outputs = model(**inputs)\n",
    "          if (torch.argmax(outputs.logits).item() == 1): # NotNextSentence\n",
    "            count_NotNextSentence += 1\n",
    "            NotNextSentence.append([i+1, j+1, choice_cols[k]]) # Doc i+1, Question j+1, Choice choice_cols[k], is not the answer\n",
    "  print(\"=== Finish Doc\", i+1, \"===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195\n"
     ]
    }
   ],
   "source": [
    "# In all situations (91*5*5 = 2375), only `count_NotNextSentence` situations are defined as `NotNextSentence`\n",
    "print(count_NotNextSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 4, 'D'], [4, 1, 'D'], [4, 2, 'C'], [4, 2, 'D'], [4, 2, 'E'], [4, 3, 'B'], [5, 3, 'A'], [6, 1, 'B'], [6, 4, 'B'], [8, 5, 'D'], [10, 1, 'A'], [10, 1, 'C'], [10, 1, 'D'], [10, 3, 'C'], [10, 5, 'A'], [13, 1, 'C'], [13, 2, 'C'], [14, 1, 'C'], [14, 2, 'C'], [14, 3, 'C'], [17, 5, 'F'], [18, 5, 'D'], [19, 1, 'B'], [19, 1, 'C'], [19, 2, 'C'], [19, 3, 'C'], [19, 4, 'B'], [20, 2, 'C'], [20, 3, 'C'], [20, 5, 'C'], [22, 1, 'A'], [22, 1, 'B'], [22, 1, 'D'], [22, 1, 'F'], [22, 2, 'B'], [22, 2, 'F'], [22, 3, 'B'], [22, 3, 'E'], [22, 3, 'F'], [22, 4, 'A'], [22, 4, 'D'], [22, 4, 'E'], [22, 5, 'A'], [22, 5, 'C'], [22, 5, 'E'], [23, 1, 'B'], [23, 5, 'A'], [23, 5, 'B'], [27, 4, 'C'], [31, 1, 'B'], [31, 1, 'C'], [31, 3, 'A'], [31, 4, 'A'], [31, 5, 'A'], [33, 1, 'A'], [33, 2, 'A'], [33, 5, 'A'], [33, 5, 'B'], [34, 2, 'A'], [34, 5, 'C'], [38, 1, 'B'], [38, 3, 'B'], [38, 5, 'B'], [41, 2, 'B'], [41, 4, 'B'], [43, 1, 'B'], [43, 4, 'B'], [43, 4, 'F'], [44, 1, 'B'], [44, 1, 'C'], [44, 5, 'A'], [45, 1, 'B'], [45, 1, 'D'], [45, 1, 'E'], [45, 2, 'B'], [45, 3, 'B'], [45, 3, 'C'], [45, 4, 'B'], [46, 3, 'E'], [46, 4, 'C'], [46, 5, 'E'], [47, 1, 'B'], [47, 2, 'B'], [47, 4, 'A'], [47, 5, 'B'], [48, 2, 'E'], [49, 1, 'C'], [49, 4, 'D'], [49, 4, 'F'], [49, 5, 'C'], [49, 5, 'D'], [50, 1, 'B'], [50, 1, 'E'], [50, 1, 'F'], [50, 3, 'B'], [51, 1, 'A'], [51, 1, 'D'], [51, 1, 'F'], [51, 2, 'A'], [51, 4, 'D'], [51, 5, 'D'], [52, 1, 'B'], [52, 1, 'E'], [52, 2, 'B'], [52, 2, 'D'], [52, 3, 'B'], [52, 3, 'E'], [52, 3, 'F'], [52, 4, 'D'], [52, 5, 'D'], [53, 2, 'E'], [53, 3, 'E'], [53, 4, 'A'], [53, 4, 'B'], [53, 4, 'E'], [53, 5, 'C'], [54, 4, 'F'], [54, 5, 'F'], [55, 2, 'A'], [55, 3, 'C'], [56, 1, 'D'], [57, 3, 'D'], [59, 3, 'D'], [59, 4, 'B'], [59, 4, 'D'], [60, 4, 'A'], [60, 5, 'A'], [60, 5, 'B'], [61, 1, 'D'], [61, 1, 'E'], [61, 2, 'D'], [62, 1, 'D'], [62, 2, 'A'], [62, 2, 'C'], [62, 2, 'D'], [62, 3, 'C'], [62, 4, 'B'], [62, 4, 'C'], [62, 5, 'D'], [63, 1, 'A'], [63, 1, 'C'], [63, 2, 'A'], [63, 2, 'E'], [63, 4, 'B'], [63, 4, 'C'], [63, 5, 'B'], [63, 5, 'C'], [64, 2, 'E'], [64, 2, 'F'], [64, 5, 'D'], [64, 5, 'E'], [67, 3, 'E'], [67, 4, 'D'], [67, 4, 'E'], [68, 3, 'A'], [68, 4, 'A'], [68, 5, 'A'], [69, 2, 'A'], [69, 3, 'A'], [69, 4, 'A'], [69, 5, 'A'], [71, 4, 'D'], [72, 1, 'B'], [72, 1, 'C'], [72, 2, 'C'], [72, 3, 'C'], [72, 4, 'D'], [73, 1, 'A'], [73, 1, 'C'], [73, 4, 'F'], [75, 2, 'F'], [75, 3, 'F'], [75, 4, 'B'], [75, 5, 'B'], [75, 5, 'F'], [77, 3, 'E'], [78, 3, 'F'], [78, 4, 'F'], [79, 1, 'A'], [79, 1, 'B'], [79, 1, 'C'], [79, 1, 'E'], [79, 1, 'F'], [79, 5, 'F'], [82, 1, 'C'], [82, 2, 'C'], [82, 5, 'D'], [83, 1, 'E'], [83, 2, 'E'], [83, 4, 'E'], [83, 5, 'E'], [85, 4, 'E'], [90, 3, 'B'], [91, 2, 'C'], [91, 3, 'C']]\n"
     ]
    }
   ],
   "source": [
    "print(NotNextSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong answer!! [4, 2, 'E']\n",
      "Wrong answer!! [47, 4, 'A']\n",
      "Wrong answer!! [52, 3, 'F']\n",
      "Wrong answer!! [53, 4, 'B']\n",
      "Wrong answer!! [63, 5, 'C']\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(NotNextSentence)):\n",
    "  if (ans_df.iloc[NotNextSentence[i][0]-1][NotNextSentence[i][1]] == NotNextSentence[i][2]):\n",
    "    print(\"Wrong answer!!\", NotNextSentence[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
