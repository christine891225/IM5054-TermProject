{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**By B08705027 資管四 林暐倫**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E7YBLlxwkr01"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Finetuning BERT for our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tYZYOoBIdAgV",
    "outputId": "4ed150d3-987b-4f79-cb7c-db69874c6329"
   },
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YUYIYgRROolZ",
    "outputId": "0d5d835a-4cee-4a3c-dd2e-2cca64cbf7e3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForNextSentencePrediction: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForNextSentencePrediction\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "CiisNSLkP2Eu"
   },
   "outputs": [],
   "source": [
    "# Read Files to List\n",
    "doc_num = 91\n",
    "question_doc = []\n",
    "choice_doc = []\n",
    "ans_doc = []\n",
    "\n",
    "for i in range(1, doc_num + 1):\n",
    "    try:\n",
    "        with open(f'Data/New/{i}.txt', encoding='utf-8') as f:\n",
    "            raw_q = f.read()\n",
    "    except:\n",
    "        with open(f'Data/New/{i}.txt', encoding='big5') as f:\n",
    "            raw_q = f.read()\n",
    "    question_doc.append(raw_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LmE4Tj6Ra3uv",
    "outputId": "c56830ac-0a8e-41e8-ad96-afbf00805859"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fiction is the name we use for stories that are make-believe, such as Harry Potter or Alice in the Wonderland. But fiction isn’t always different from the way things usually are It can be so close to the truth that it seems as real as something that happened to you this morning. Or, fiction can be as fantastic as the most unbelievable fairy tale. Not everything in a fictional story has to be made up. You could write a story in which you fly to the moon. You, of course, are real, and the moon is real, and many of the things that you could describe, such as the stars, the wind, and the pull of gravity, would be real. But your trip through space would be fiction. It would be a trip you took in your imagination. Nonfiction, on the other hand, is all about true things. Nothing is made up. Someone’s biography is nonfiction; so is your autobiography. So are articles in your local newspaper, and school reports on science. History is nonfiction, too. Imagine writing history about the 1989 San Francisco earthquake, or a report about a high school sports team. An old proverb says, “Truth is stranger than fiction.” Do you think that’s true?']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_doc[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ZzHP1_DWeyJ"
   },
   "source": [
    "finetuing BERT w question_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bg53gpv0bE7z",
    "outputId": "b7eab501-d91e-4a26-e6c4-19763d34b410"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IAt41mSGWNgh"
   },
   "outputs": [],
   "source": [
    "\n",
    "from nltk import tokenize\n",
    "text = []\n",
    "for question in question_doc:\n",
    "  temp = tokenize.sent_tokenize(question)\n",
    "  # temp = tokenizer.enocde_plus(question)\n",
    "  temp.append(' ') # append space as sep\n",
    "  for to_merge in temp:\n",
    "    text.append(to_merge)\n",
    "\n",
    "# preprocessing to remove number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W-xwoWdQYL5f",
    "outputId": "37221866-65ca-490d-c8d6-36eaeb082ad0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1792\n"
     ]
    }
   ],
   "source": [
    "bag = text\n",
    "bag_size = len(bag)\n",
    "print(bag_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "j98grU2NbwM0"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "sentence_a = []\n",
    "sentence_b = []\n",
    "label = []\n",
    "\n",
    "for paragraph in text:\n",
    "    sentences = [\n",
    "        sentence for sentence in paragraph.split('.') if sentence != ''\n",
    "    ]\n",
    "    num_sentences = len(sentences)\n",
    "    if num_sentences > 1:\n",
    "        start = random.randint(0, num_sentences-2)\n",
    "        # 50/50 whether is IsNextSentence or NotNextSentence\n",
    "        if random.random() >= 0.5:\n",
    "            # this is IsNextSentence\n",
    "            sentence_a.append(sentences[start])\n",
    "            sentence_b.append(sentences[start+1])\n",
    "            label.append(0)\n",
    "        else:\n",
    "            index = random.randint(0, bag_size-1)\n",
    "            # this is NotNextSentence\n",
    "            sentence_a.append(sentences[start])\n",
    "            sentence_b.append(bag[index])\n",
    "            label.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HVermps2b0k3",
    "outputId": "228b2674-fe43-4fb1-e8ce-f2652c5a6590"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "An old proverb says, “Truth is stranger than fiction\n",
      "---\n",
      "His name is Bond.\n",
      "\n",
      "1\n",
      "I need directions home\n",
      "---\n",
      "The practice then spread to other towns as a common custom.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(label[i])\n",
    "    print(sentence_a[i] + '\\n---')\n",
    "    print(sentence_b[i] + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "pokCnqnIcCDT"
   },
   "outputs": [],
   "source": [
    "inputs = tokenizer(sentence_a, sentence_b, return_tensors='pt', max_length=512, truncation=True, padding='max_length')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "erWpXEC7cFK2",
    "outputId": "db727c89-a952-47ef-9a00-aa9efc59a72e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S4TpAOxBcEFA",
    "outputId": "cfa10186-b55f-483c-bb8f-8387909b407e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.token_type_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9zMX2POvcJ_d",
    "outputId": "3433e2e7-6da4-4122-fe9a-bdf59f53d4d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['labels'] = torch.LongTensor([label]).T\n",
    "inputs.labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uF2G4xEqcOdw"
   },
   "outputs": [],
   "source": [
    "class MeditationsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AIk_ywTKcQAy"
   },
   "outputs": [],
   "source": [
    "dataset = MeditationsDataset(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ry4sMq60cTAO"
   },
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6THpHTRkcVGH"
   },
   "source": [
    "Training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cVHVIQx7cX0J",
    "outputId": "c4d5ce34-abe8-4710-9cf3-84044121615c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForNextSentencePrediction(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyNSPHead(\n",
       "    (seq_relationship): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# and move our model over to the selected device\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K9HQBziacaon"
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "# activate training mode\n",
    "model.train()\n",
    "# initialize optimizer\n",
    "optim = AdamW(model.parameters(), lr=5e-6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tBWxxHh2ejXM"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hQzDoRLSce7V",
    "outputId": "397933f9-117c-475f-cd77-5c7e8926ea0a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 4/4 [03:09<00:00, 47.33s/it, loss=2.24]\n",
      "Epoch 1: 100%|██████████| 4/4 [02:46<00:00, 41.51s/it, loss=0.637]\n",
      "Epoch 2: 100%|██████████| 4/4 [03:19<00:00, 49.77s/it, loss=0.612]\n",
      "Epoch 3: 100%|██████████| 4/4 [03:15<00:00, 48.77s/it, loss=0.794]\n",
      "Epoch 4: 100%|██████████| 4/4 [02:48<00:00, 42.17s/it, loss=0.368]\n",
      "Epoch 5: 100%|██████████| 4/4 [02:46<00:00, 41.58s/it, loss=0.0594]\n",
      "Epoch 6: 100%|██████████| 4/4 [02:50<00:00, 42.59s/it, loss=0.222]\n",
      "Epoch 7: 100%|██████████| 4/4 [02:58<00:00, 44.63s/it, loss=0.0771]\n",
      "Epoch 8: 100%|██████████| 4/4 [02:47<00:00, 41.87s/it, loss=0.52]\n",
      "Epoch 9: 100%|██████████| 4/4 [02:46<00:00, 41.54s/it, loss=0.0348]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm  # for our progress bar\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # setup loop with TQDM and dataloader\n",
    "    loop = tqdm(loader, leave=True)\n",
    "    for batch in loop:\n",
    "        # initialize calculated gradients (from prev step)\n",
    "        optim.zero_grad()\n",
    "        # pull all tensor batches required for training\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        # process\n",
    "        outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                        labels=labels)\n",
    "        # extract loss\n",
    "        loss = outputs.loss\n",
    "        # calculate loss for every parameter that needs grad update\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optim.step()\n",
    "        # print relevant info to progress bar\n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nYWrb0PMRY3k"
   },
   "outputs": [],
   "source": [
    "PATH = \"new_model.pt\"\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3CFkJRDlu-5"
   },
   "source": [
    "# 2. Use finetuned BERT to predict NSP (bool-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 82
    },
    "id": "jYUeP26Oklxo",
    "outputId": "d7b2c14f-9bdc-4281-e412-0dd075737a7a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-bf6eed8e-fab3-49ec-a3f8-6b2cf4991b61\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf6eed8e-fab3-49ec-a3f8-6b2cf4991b61')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-bf6eed8e-fab3-49ec-a3f8-6b2cf4991b61 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-bf6eed8e-fab3-49ec-a3f8-6b2cf4991b61');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [A, B, C, D, E, F]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-9b185d71-c09f-4291-a002-beee9bfdf728\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b185d71-c09f-4291-a002-beee9bfdf728')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-9b185d71-c09f-4291-a002-beee9bfdf728 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-9b185d71-c09f-4291-a002-beee9bfdf728');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [1, 2, 3, 4, 5]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "choice_cols = ['A', 'B', 'C', 'D', 'E', 'F']\n",
    "choice_df = pd.DataFrame(choice_doc, columns=choice_cols, index=[i + 1 for i in range(len(choice_doc))])\n",
    "for col in choice_cols:\n",
    "    choice_df[col] = choice_df[col].str.replace(r'\\([A-F]\\)', '')\n",
    "\n",
    "ans_cols = [1, 2, 3, 4, 5]\n",
    "ans_df = pd.DataFrame(ans_doc, columns=ans_cols, index=[i + 1 for i in range(len(choice_doc))])\n",
    "\n",
    "display(choice_df.head())\n",
    "display(ans_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "iaXTxUfvkqFd",
    "outputId": "317680a3-d9e8-4ce7-e039-afff9ab779f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Finish Doc 1 ===\n",
      "=== Finish Doc 2 ===\n",
      "=== Finish Doc 3 ===\n",
      "=== Finish Doc 4 ===\n",
      "=== Finish Doc 5 ===\n",
      "=== Finish Doc 6 ===\n",
      "=== Finish Doc 7 ===\n",
      "=== Finish Doc 8 ===\n",
      "=== Finish Doc 9 ===\n",
      "=== Finish Doc 10 ===\n",
      "=== Finish Doc 11 ===\n",
      "=== Finish Doc 12 ===\n",
      "=== Finish Doc 13 ===\n",
      "=== Finish Doc 14 ===\n",
      "=== Finish Doc 15 ===\n",
      "=== Finish Doc 16 ===\n",
      "=== Finish Doc 17 ===\n",
      "=== Finish Doc 18 ===\n",
      "=== Finish Doc 19 ===\n",
      "=== Finish Doc 20 ===\n",
      "=== Finish Doc 21 ===\n",
      "=== Finish Doc 22 ===\n",
      "=== Finish Doc 23 ===\n",
      "=== Finish Doc 24 ===\n",
      "=== Finish Doc 25 ===\n",
      "=== Finish Doc 26 ===\n",
      "=== Finish Doc 27 ===\n",
      "=== Finish Doc 28 ===\n",
      "=== Finish Doc 29 ===\n",
      "=== Finish Doc 30 ===\n",
      "=== Finish Doc 31 ===\n",
      "=== Finish Doc 32 ===\n",
      "=== Finish Doc 33 ===\n",
      "=== Finish Doc 34 ===\n",
      "=== Finish Doc 35 ===\n",
      "=== Finish Doc 36 ===\n",
      "=== Finish Doc 37 ===\n",
      "=== Finish Doc 38 ===\n",
      "=== Finish Doc 39 ===\n",
      "=== Finish Doc 40 ===\n",
      "=== Finish Doc 41 ===\n",
      "=== Finish Doc 42 ===\n",
      "=== Finish Doc 43 ===\n",
      "=== Finish Doc 44 ===\n",
      "=== Finish Doc 45 ===\n",
      "=== Finish Doc 46 ===\n",
      "=== Finish Doc 47 ===\n",
      "=== Finish Doc 48 ===\n",
      "=== Finish Doc 49 ===\n",
      "=== Finish Doc 50 ===\n",
      "=== Finish Doc 51 ===\n",
      "=== Finish Doc 52 ===\n",
      "=== Finish Doc 53 ===\n",
      "=== Finish Doc 54 ===\n",
      "=== Finish Doc 55 ===\n",
      "=== Finish Doc 56 ===\n",
      "=== Finish Doc 57 ===\n",
      "=== Finish Doc 58 ===\n",
      "=== Finish Doc 59 ===\n",
      "=== Finish Doc 60 ===\n",
      "=== Finish Doc 61 ===\n",
      "=== Finish Doc 62 ===\n",
      "=== Finish Doc 63 ===\n",
      "=== Finish Doc 64 ===\n",
      "=== Finish Doc 65 ===\n",
      "=== Finish Doc 66 ===\n",
      "=== Finish Doc 67 ===\n",
      "=== Finish Doc 68 ===\n",
      "=== Finish Doc 69 ===\n",
      "=== Finish Doc 70 ===\n",
      "=== Finish Doc 71 ===\n",
      "=== Finish Doc 72 ===\n",
      "=== Finish Doc 73 ===\n",
      "=== Finish Doc 74 ===\n",
      "=== Finish Doc 75 ===\n",
      "=== Finish Doc 76 ===\n",
      "=== Finish Doc 77 ===\n",
      "=== Finish Doc 78 ===\n",
      "=== Finish Doc 79 ===\n",
      "=== Finish Doc 80 ===\n",
      "=== Finish Doc 81 ===\n",
      "=== Finish Doc 82 ===\n",
      "=== Finish Doc 83 ===\n",
      "=== Finish Doc 84 ===\n",
      "=== Finish Doc 85 ===\n",
      "=== Finish Doc 86 ===\n",
      "=== Finish Doc 87 ===\n",
      "=== Finish Doc 88 ===\n",
      "=== Finish Doc 89 ===\n",
      "=== Finish Doc 90 ===\n",
      "=== Finish Doc 91 ===\n"
     ]
    }
   ],
   "source": [
    "count_NotNextSentence = 0\n",
    "NotNextSentence = []\n",
    "\n",
    "for i in range(len(question_doc)): # each document\n",
    "  question_sentence = re.split('\\(1\\)|\\(2\\)|\\(3\\)|\\(4\\)|\\(5\\)', question_doc[i])\n",
    "  for j in range(5): # each question\n",
    "      for k in range(6): # each option\n",
    "        if (choice_df.iloc[i][choice_cols[k]] != 'None'):\n",
    "          inputs = tokenizer(question_sentence[j], choice_df.iloc[i][choice_cols[k]], return_tensors='pt')\n",
    "          outputs = model(**inputs)\n",
    "          if (torch.argmax(outputs.logits).item() == 1): # NotNextSentence\n",
    "            count_NotNextSentence += 1\n",
    "            NotNextSentence.append([i+1, j+1, choice_cols[k]]) # Doc i+1, Question j+1, Choice choice_cols[k], is not the answer\n",
    "  print(\"=== Finish Doc\", i+1, \"===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pfCLr6u6Omvz",
    "outputId": "01806a67-c946-4d3f-8b23-35a7e647801e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333\n"
     ]
    }
   ],
   "source": [
    "# In all situations (91*5*5 = 2375), only `count_NotNextSentence` situations are defined as `NotNextSentence`\n",
    "print(count_NotNextSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yISDcY65OwEb",
    "outputId": "20b9e6b9-4f73-480f-cd1d-fcf665d2b781"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 'F'], [1, 3, 'B'], [1, 3, 'F'], [1, 4, 'F'], [1, 5, 'F'], [2, 1, 'F'], [2, 2, 'F'], [2, 3, 'F'], [2, 4, 'F'], [3, 4, 'D'], [3, 5, 'D'], [3, 5, 'F'], [4, 1, 'D'], [4, 2, 'C'], [4, 2, 'D'], [4, 2, 'E'], [4, 2, 'F'], [4, 3, 'B'], [4, 4, 'F'], [5, 2, 'F'], [5, 3, 'A'], [5, 5, 'F'], [6, 1, 'B'], [6, 1, 'F'], [6, 2, 'F'], [6, 4, 'F'], [6, 5, 'F'], [7, 1, 'D'], [7, 2, 'F'], [7, 3, 'F'], [7, 4, 'F'], [7, 5, 'F'], [8, 1, 'F'], [8, 5, 'D'], [9, 4, 'A'], [9, 4, 'F'], [10, 1, 'A'], [10, 1, 'C'], [10, 1, 'D'], [10, 3, 'F'], [10, 4, 'F'], [13, 2, 'C'], [14, 1, 'C'], [14, 2, 'C'], [14, 3, 'C'], [14, 4, 'C'], [17, 5, 'F'], [18, 5, 'D'], [19, 1, 'B'], [19, 1, 'C'], [19, 1, 'E'], [19, 2, 'C'], [19, 4, 'B'], [20, 2, 'C'], [20, 3, 'C'], [22, 1, 'A'], [22, 1, 'B'], [22, 1, 'D'], [22, 1, 'F'], [22, 2, 'B'], [22, 2, 'F'], [22, 3, 'B'], [22, 3, 'E'], [22, 3, 'F'], [22, 4, 'A'], [22, 4, 'D'], [22, 4, 'E'], [22, 5, 'A'], [22, 5, 'C'], [22, 5, 'E'], [23, 1, 'B'], [23, 1, 'F'], [23, 2, 'E'], [23, 2, 'F'], [23, 3, 'E'], [23, 3, 'F'], [23, 4, 'F'], [23, 5, 'A'], [23, 5, 'B'], [23, 5, 'F'], [24, 1, 'E'], [24, 1, 'F'], [24, 2, 'E'], [24, 4, 'F'], [25, 2, 'E'], [25, 2, 'F'], [26, 1, 'E'], [26, 1, 'F'], [26, 2, 'E'], [26, 2, 'F'], [26, 3, 'E'], [26, 4, 'E'], [26, 4, 'F'], [26, 5, 'E'], [26, 5, 'F'], [27, 1, 'E'], [27, 1, 'F'], [27, 2, 'E'], [27, 2, 'F'], [27, 3, 'E'], [27, 3, 'F'], [27, 4, 'C'], [27, 4, 'D'], [27, 5, 'E'], [27, 5, 'F'], [28, 3, 'E'], [28, 3, 'F'], [28, 4, 'F'], [28, 5, 'E'], [29, 1, 'E'], [29, 1, 'F'], [29, 2, 'C'], [29, 5, 'E'], [30, 2, 'F'], [30, 3, 'E'], [30, 3, 'F'], [30, 5, 'F'], [31, 1, 'B'], [31, 1, 'F'], [31, 2, 'E'], [31, 2, 'F'], [31, 3, 'A'], [31, 4, 'A'], [31, 4, 'F'], [31, 5, 'A'], [31, 5, 'E'], [31, 5, 'F'], [32, 1, 'E'], [32, 1, 'F'], [32, 2, 'E'], [32, 3, 'E'], [32, 3, 'F'], [32, 4, 'E'], [32, 5, 'E'], [33, 1, 'A'], [33, 1, 'B'], [33, 1, 'E'], [33, 1, 'F'], [33, 2, 'A'], [33, 3, 'A'], [33, 3, 'E'], [33, 3, 'F'], [33, 4, 'E'], [33, 4, 'F'], [33, 5, 'A'], [33, 5, 'B'], [34, 2, 'A'], [34, 2, 'F'], [34, 3, 'E'], [34, 5, 'C'], [35, 2, 'E'], [35, 2, 'F'], [35, 5, 'F'], [36, 2, 'E'], [36, 2, 'F'], [36, 4, 'E'], [36, 4, 'F'], [36, 5, 'F'], [37, 1, 'E'], [37, 2, 'E'], [37, 2, 'F'], [37, 3, 'F'], [37, 4, 'E'], [37, 4, 'F'], [37, 5, 'F'], [38, 1, 'B'], [38, 1, 'E'], [38, 2, 'E'], [38, 2, 'F'], [38, 3, 'C'], [38, 3, 'E'], [38, 4, 'E'], [39, 1, 'C'], [39, 2, 'E'], [39, 3, 'E'], [39, 4, 'E'], [39, 5, 'E'], [39, 5, 'F'], [40, 4, 'E'], [40, 4, 'F'], [40, 5, 'E'], [40, 5, 'F'], [41, 1, 'E'], [41, 1, 'F'], [41, 2, 'B'], [41, 2, 'E'], [41, 2, 'F'], [41, 3, 'E'], [41, 3, 'F'], [41, 4, 'B'], [42, 1, 'E'], [42, 1, 'F'], [42, 2, 'E'], [42, 2, 'F'], [42, 4, 'E'], [42, 4, 'F'], [42, 5, 'E'], [42, 5, 'F'], [43, 1, 'B'], [43, 2, 'D'], [43, 4, 'B'], [44, 1, 'B'], [44, 1, 'C'], [44, 5, 'A'], [45, 1, 'B'], [45, 1, 'D'], [45, 1, 'E'], [45, 2, 'B'], [45, 3, 'B'], [45, 3, 'C'], [45, 4, 'B'], [46, 4, 'C'], [46, 5, 'E'], [47, 1, 'B'], [47, 4, 'A'], [47, 5, 'B'], [48, 2, 'E'], [49, 4, 'F'], [49, 5, 'C'], [50, 1, 'E'], [50, 1, 'F'], [50, 3, 'B'], [51, 1, 'D'], [51, 1, 'F'], [51, 2, 'A'], [51, 2, 'F'], [51, 5, 'D'], [52, 1, 'B'], [52, 1, 'E'], [52, 2, 'B'], [52, 2, 'D'], [52, 3, 'B'], [52, 3, 'E'], [52, 3, 'F'], [52, 4, 'B'], [52, 4, 'D'], [52, 5, 'D'], [53, 2, 'E'], [53, 3, 'E'], [53, 4, 'A'], [53, 4, 'B'], [53, 4, 'E'], [54, 4, 'F'], [54, 5, 'F'], [55, 2, 'A'], [56, 1, 'D'], [58, 1, 'E'], [58, 5, 'E'], [59, 3, 'D'], [59, 4, 'B'], [59, 4, 'D'], [60, 5, 'A'], [60, 5, 'B'], [60, 5, 'C'], [60, 5, 'E'], [60, 5, 'F'], [61, 1, 'D'], [61, 2, 'D'], [62, 1, 'D'], [62, 2, 'A'], [62, 2, 'C'], [62, 2, 'D'], [62, 4, 'B'], [62, 4, 'C'], [62, 5, 'D'], [62, 5, 'F'], [63, 1, 'A'], [63, 1, 'C'], [63, 2, 'A'], [63, 2, 'C'], [63, 4, 'B'], [63, 4, 'C'], [64, 2, 'E'], [64, 2, 'F'], [64, 5, 'D'], [64, 5, 'E'], [67, 3, 'E'], [67, 4, 'E'], [68, 4, 'A'], [68, 5, 'A'], [69, 2, 'A'], [69, 3, 'A'], [69, 4, 'A'], [69, 5, 'A'], [69, 5, 'E'], [71, 4, 'D'], [72, 1, 'B'], [72, 1, 'C'], [72, 2, 'C'], [72, 4, 'D'], [72, 4, 'F'], [72, 5, 'F'], [73, 4, 'F'], [75, 2, 'F'], [75, 3, 'F'], [75, 4, 'B'], [75, 5, 'B'], [75, 5, 'F'], [77, 3, 'E'], [78, 4, 'F'], [79, 1, 'A'], [79, 1, 'B'], [79, 1, 'C'], [79, 1, 'E'], [79, 1, 'F'], [79, 5, 'F'], [80, 1, 'F'], [81, 2, 'E'], [82, 1, 'C'], [82, 2, 'C'], [82, 5, 'D'], [83, 1, 'E'], [83, 5, 'E'], [85, 4, 'E'], [87, 1, 'F'], [87, 2, 'F'], [87, 3, 'F'], [87, 4, 'F'], [89, 1, 'F'], [89, 2, 'F'], [89, 3, 'F'], [89, 4, 'F'], [89, 5, 'F'], [90, 2, 'E'], [90, 2, 'F'], [90, 3, 'A'], [90, 3, 'F'], [90, 5, 'F'], [91, 1, 'F'], [91, 2, 'C'], [91, 2, 'F'], [91, 3, 'C'], [91, 4, 'F']]\n"
     ]
    }
   ],
   "source": [
    "print(NotNextSentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6j3-MOocPEqp"
   },
   "source": [
    "# 3. Use finetuned BERT to predict NSP (probability-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0dEbGUP-rcp2"
   },
   "outputs": [],
   "source": [
    "# Read Files to List\n",
    "doc_num = 91\n",
    "question_doc = []\n",
    "choice_doc = []\n",
    "ans_doc = []\n",
    "\n",
    "for i in range(1, doc_num + 1):\n",
    "    try:\n",
    "        with open(f'Data/Question/{i}.txt', encoding='utf-8') as f:\n",
    "            raw_q = f.read()\n",
    "    except:\n",
    "        with open(f'Data/Question/{i}.txt', encoding='big5') as f:\n",
    "            raw_q = f.read()\n",
    "    try:\n",
    "        with open(f'Data/Choice/{i}.txt', encoding='utf-8') as f:\n",
    "            raw_ch = f.read()\n",
    "    except:\n",
    "        with open(f'Data/Choice/{i}.txt', encoding='big5') as f:\n",
    "            raw_ch = f.read()\n",
    "    try:\n",
    "        with open(f'Data/Answer/{i}.txt', encoding='utf-8') as f:\n",
    "            raw_a = f.read()\n",
    "    except:\n",
    "        with open(f'Data/Answer/{i}.txt', encoding='big5') as f:\n",
    "            raw_a = f.read()\n",
    "    question_doc.append(raw_q)\n",
    "    choice_doc.append(raw_ch.split('\\n'))\n",
    "    ans_doc.append(list(raw_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 526
    },
    "id": "SACRUutTruWo",
    "outputId": "6cc8f8b0-1863-446f-9e9b-c7cfb10d726d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-967bf958-ab13-45f0-ac02-35672050775f\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nothing is made up.</td>\n",
       "      <td>History is nonfiction, too.</td>\n",
       "      <td>But your trip through space would be fiction.</td>\n",
       "      <td>You could write a story in which you fly to t...</td>\n",
       "      <td>But fiction isn’t always different from the w...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>But when I pulled into the driveway, there wa...</td>\n",
       "      <td>Hours later I called my daughter and asked if...</td>\n",
       "      <td>One time, I even shouted at Derek when he unp...</td>\n",
       "      <td>Derek became part of our life and seemed to f...</td>\n",
       "      <td>Without any experience in raising pets, my hu...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Another genre commonly found in Chinese brush...</td>\n",
       "      <td>However, the subject matters later expanded b...</td>\n",
       "      <td>As a result, they have obtained more natural ...</td>\n",
       "      <td>Its growth has inevitably reflected the chang...</td>\n",
       "      <td>It then gradually developed into two separate...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>She got to look at the fine old houses as wel...</td>\n",
       "      <td>Architects make drawings and careful plans of...</td>\n",
       "      <td>The word for what she does is rehabilitation.</td>\n",
       "      <td>Then she went on to study architecture.</td>\n",
       "      <td>That is precisely what Carrie does.</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>There are definitely two sides to this issue.</td>\n",
       "      <td>Scores decreased as the family size increased...</td>\n",
       "      <td>An intelligence test was administered to over...</td>\n",
       "      <td>On the other side are Rutherford and Sewell, ...</td>\n",
       "      <td>Since then, the theory has been elaborated an...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-967bf958-ab13-45f0-ac02-35672050775f')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-967bf958-ab13-45f0-ac02-35672050775f button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-967bf958-ab13-45f0-ac02-35672050775f');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                   A  \\\n",
       "1                                Nothing is made up.   \n",
       "2   But when I pulled into the driveway, there wa...   \n",
       "3   Another genre commonly found in Chinese brush...   \n",
       "4   She got to look at the fine old houses as wel...   \n",
       "5      There are definitely two sides to this issue.   \n",
       "\n",
       "                                                   B  \\\n",
       "1                        History is nonfiction, too.   \n",
       "2   Hours later I called my daughter and asked if...   \n",
       "3   However, the subject matters later expanded b...   \n",
       "4   Architects make drawings and careful plans of...   \n",
       "5   Scores decreased as the family size increased...   \n",
       "\n",
       "                                                   C  \\\n",
       "1      But your trip through space would be fiction.   \n",
       "2   One time, I even shouted at Derek when he unp...   \n",
       "3   As a result, they have obtained more natural ...   \n",
       "4      The word for what she does is rehabilitation.   \n",
       "5   An intelligence test was administered to over...   \n",
       "\n",
       "                                                   D  \\\n",
       "1   You could write a story in which you fly to t...   \n",
       "2   Derek became part of our life and seemed to f...   \n",
       "3   Its growth has inevitably reflected the chang...   \n",
       "4            Then she went on to study architecture.   \n",
       "5   On the other side are Rutherford and Sewell, ...   \n",
       "\n",
       "                                                   E     F  \n",
       "1   But fiction isn’t always different from the w...  None  \n",
       "2   Without any experience in raising pets, my hu...  None  \n",
       "3   It then gradually developed into two separate...        \n",
       "4                That is precisely what Carrie does.  None  \n",
       "5   Since then, the theory has been elaborated an...  None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-9ba19c68-f711-4050-93f0-9876d4e1f209\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ba19c68-f711-4050-93f0-9876d4e1f209')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-9ba19c68-f711-4050-93f0-9876d4e1f209 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-9ba19c68-f711-4050-93f0-9876d4e1f209');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   1  2  3  4  5\n",
       "1  E  D  C  A  B\n",
       "2  E  D  C  A  B\n",
       "3  D  B  E  A  C\n",
       "4  C  E  A  D  B\n",
       "5  C  B  E  A  D"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "choice_cols = ['A', 'B', 'C', 'D', 'E', 'F']\n",
    "choice_df = pd.DataFrame(choice_doc, columns=choice_cols, index=[i + 1 for i in range(len(choice_doc))])\n",
    "for col in choice_cols:\n",
    "    choice_df[col] = choice_df[col].str.replace(r'\\([A-F]\\)', '')\n",
    "\n",
    "ans_cols = [1, 2, 3, 4, 5]\n",
    "ans_df = pd.DataFrame(ans_doc, columns=ans_cols, index=[i + 1 for i in range(len(choice_doc))])\n",
    "\n",
    "display(choice_df.head())\n",
    "display(ans_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1OqLtObLPJ7H",
    "outputId": "d0ca1c43-8083-4425-b1c5-8726216719ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Finish Doc 1 ===\n",
      "=== Finish Doc 2 ===\n",
      "=== Finish Doc 3 ===\n",
      "=== Finish Doc 4 ===\n",
      "=== Finish Doc 5 ===\n",
      "=== Finish Doc 6 ===\n",
      "=== Finish Doc 7 ===\n",
      "=== Finish Doc 8 ===\n",
      "=== Finish Doc 9 ===\n",
      "=== Finish Doc 10 ===\n",
      "=== Finish Doc 11 ===\n",
      "=== Finish Doc 12 ===\n",
      "=== Finish Doc 13 ===\n",
      "=== Finish Doc 14 ===\n",
      "=== Finish Doc 15 ===\n",
      "=== Finish Doc 16 ===\n",
      "=== Finish Doc 17 ===\n",
      "=== Finish Doc 18 ===\n",
      "=== Finish Doc 19 ===\n",
      "=== Finish Doc 20 ===\n",
      "=== Finish Doc 21 ===\n",
      "=== Finish Doc 22 ===\n",
      "=== Finish Doc 23 ===\n",
      "=== Finish Doc 24 ===\n",
      "=== Finish Doc 25 ===\n",
      "=== Finish Doc 26 ===\n",
      "=== Finish Doc 27 ===\n",
      "=== Finish Doc 28 ===\n",
      "=== Finish Doc 29 ===\n",
      "=== Finish Doc 30 ===\n",
      "=== Finish Doc 31 ===\n",
      "=== Finish Doc 32 ===\n",
      "=== Finish Doc 33 ===\n",
      "=== Finish Doc 34 ===\n",
      "=== Finish Doc 35 ===\n",
      "=== Finish Doc 36 ===\n",
      "=== Finish Doc 37 ===\n",
      "=== Finish Doc 38 ===\n",
      "=== Finish Doc 39 ===\n",
      "=== Finish Doc 40 ===\n",
      "=== Finish Doc 41 ===\n",
      "=== Finish Doc 42 ===\n",
      "=== Finish Doc 43 ===\n",
      "=== Finish Doc 44 ===\n",
      "=== Finish Doc 45 ===\n",
      "=== Finish Doc 46 ===\n",
      "=== Finish Doc 47 ===\n",
      "=== Finish Doc 48 ===\n",
      "=== Finish Doc 49 ===\n",
      "=== Finish Doc 50 ===\n",
      "=== Finish Doc 51 ===\n",
      "=== Finish Doc 52 ===\n",
      "=== Finish Doc 53 ===\n",
      "=== Finish Doc 54 ===\n",
      "=== Finish Doc 55 ===\n",
      "=== Finish Doc 56 ===\n",
      "=== Finish Doc 57 ===\n",
      "=== Finish Doc 58 ===\n",
      "=== Finish Doc 59 ===\n",
      "=== Finish Doc 60 ===\n",
      "=== Finish Doc 61 ===\n",
      "=== Finish Doc 62 ===\n",
      "=== Finish Doc 63 ===\n",
      "=== Finish Doc 64 ===\n",
      "=== Finish Doc 65 ===\n",
      "=== Finish Doc 66 ===\n",
      "=== Finish Doc 67 ===\n",
      "=== Finish Doc 68 ===\n",
      "=== Finish Doc 69 ===\n",
      "=== Finish Doc 70 ===\n",
      "=== Finish Doc 71 ===\n",
      "=== Finish Doc 72 ===\n",
      "=== Finish Doc 73 ===\n",
      "=== Finish Doc 74 ===\n",
      "=== Finish Doc 75 ===\n",
      "=== Finish Doc 76 ===\n",
      "=== Finish Doc 77 ===\n",
      "=== Finish Doc 78 ===\n",
      "=== Finish Doc 79 ===\n",
      "=== Finish Doc 80 ===\n",
      "=== Finish Doc 81 ===\n",
      "=== Finish Doc 82 ===\n",
      "=== Finish Doc 83 ===\n",
      "=== Finish Doc 84 ===\n",
      "=== Finish Doc 85 ===\n",
      "=== Finish Doc 86 ===\n",
      "=== Finish Doc 87 ===\n",
      "=== Finish Doc 88 ===\n",
      "=== Finish Doc 89 ===\n",
      "=== Finish Doc 90 ===\n",
      "=== Finish Doc 91 ===\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.functional import softmax\n",
    "answer_prob = []\n",
    "\n",
    "for i in range(len(question_doc)): # each document\n",
    "  tmp_answer_prob_for_doc = []\n",
    "  question_sentence = re.split('\\(1\\)|\\(2\\)|\\(3\\)|\\(4\\)|\\(5\\)', question_doc[i])\n",
    "  quesion_num = 5\n",
    "  if (ans_df.iloc[i][5] == None):\n",
    "    quesion_num = 4\n",
    "  for j in range(quesion_num): # each question\n",
    "    tmp_answer_prob_for_question = []\n",
    "    for k in range(6): # each option\n",
    "      if (choice_df.iloc[i][choice_cols[k]] != None):\n",
    "        # sentence before\n",
    "        inputs = tokenizer(question_sentence[j], choice_df.iloc[i][choice_cols[k]], return_tensors='pt')\n",
    "        outputs = model(**inputs)[0]\n",
    "        probs = softmax(outputs, dim=1)\n",
    "        # sentence after\n",
    "        if (len(question_sentence) > j):\n",
    "          inputs_2 = tokenizer(choice_df.iloc[i][choice_cols[k]], question_sentence[j+1], return_tensors='pt')\n",
    "          outputs_2 = model(**inputs_2)[0]\n",
    "          probs_2 = softmax(outputs_2, dim=1)\n",
    "          tmp_answer_prob_for_question.append((probs[0][0].item() + probs_2[0][0].item()) / 2)\n",
    "        else:\n",
    "          tmp_answer_prob_for_question.append(probs[0][0].item())\n",
    "    tmp_answer_prob_for_doc.append(tmp_answer_prob_for_question)\n",
    "  answer_prob.append(tmp_answer_prob_for_doc)\n",
    "\n",
    "  print(\"=== Finish Doc\", i+1, \"===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "55xKacCjmD7f"
   },
   "outputs": [],
   "source": [
    "our_answer_1 = []\n",
    "\n",
    "for i in range(len(answer_prob)):\n",
    "  num_q = len(answer_prob[i])\n",
    "  num_o = len(answer_prob[i][0])\n",
    "  chosen = np.zeros((num_q, num_o)) # chosen[j][k] = question j, option k\n",
    "  tmp_answer = np.zeros(num_q)\n",
    "  for x in range(num_q): # we need to find answers for all questions\n",
    "    # find the highest probability for this round\n",
    "    pos_q = 0 # record the highest probability position\n",
    "    pos_o = 0\n",
    "    highest_prob = 0\n",
    "    for j in range(num_q):\n",
    "      for k in range(num_o):\n",
    "        if (answer_prob[i][j][k] > highest_prob and chosen[j][k] == 0):\n",
    "          highest_prob = answer_prob[i][j][k]\n",
    "          pos_q = j\n",
    "          pos_o = k\n",
    "    # record the answer\n",
    "    tmp_answer[pos_q] = pos_o\n",
    "    for j in range(num_q):\n",
    "      chosen[j][pos_o] = 1\n",
    "    for k in range(num_o):\n",
    "      chosen[pos_q][k] = 1\n",
    "  our_answer_1.append(tmp_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WpsIdoHymHyH",
    "outputId": "49d2dd76-1e95-43d7-8af5-49f58ba5f0bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc 1 : 0.2 ['E', 'C', 'D', 'B', 'A'] ['E', 'D', 'C', 'A', 'B']\n",
      "Doc 2 : 0.6 ['E', 'D', 'C', 'B', 'A'] ['E', 'D', 'C', 'A', 'B']\n",
      "Doc 3 : 0.6 ['A', 'B', 'E', 'F', 'C'] ['D', 'B', 'E', 'A', 'C']\n",
      "Doc 4 : 0.4 ['B', 'C', 'A', 'D', 'E'] ['C', 'E', 'A', 'D', 'B']\n",
      "Doc 5 : 0.4 ['C', 'A', 'E', 'D', 'B'] ['C', 'B', 'E', 'A', 'D']\n",
      "Doc 6 : 0.0 ['D', 'B', 'C', 'A', 'E'] ['C', 'E', 'A', 'D', 'B']\n",
      "Doc 7 : 0.0 ['E', 'C', 'B', 'D', 'A'] ['B', 'D', 'A', 'E', 'C']\n",
      "Doc 8 : 0.6 ['D', 'E', 'A', 'C', 'B'] ['A', 'E', 'D', 'C', 'B']\n",
      "Doc 9 : 0.2 ['A', 'E', 'C', 'D', 'B'] ['E', 'C', 'D', 'A', 'B']\n",
      "Doc 10 : 0.4 ['C', 'D', 'A', 'E', 'B'] ['E', 'D', 'A', 'B', 'C']\n",
      "Doc 11 : 0.4 ['F', 'B', 'A', 'C', 'D'] ['F', 'D', 'A', 'E', 'C']\n",
      "Doc 12 : 0.6 ['B', 'E', 'D', 'A', 'F'] ['B', 'A', 'D', 'E', 'F']\n",
      "Doc 13 : 0.4 ['E', 'D', 'F', 'C', 'A'] ['B', 'D', 'F', 'A', 'E']\n",
      "Doc 14 : 0.2 ['D', 'B', 'F', 'E', 'A'] ['E', 'A', 'F', 'C', 'D']\n",
      "Doc 15 : 0.2 ['C', 'E', 'B', 'A', 'D'] ['E', 'A', 'B', 'F', 'C']\n",
      "Doc 16 : 0.4 ['C', 'E', 'A', 'B', 'F'] ['F', 'E', 'C', 'B', 'D']\n",
      "Doc 17 : 0.4 ['C', 'A', 'E', 'B', 'D'] ['C', 'F', 'A', 'E', 'D']\n",
      "Doc 18 : 0.2 ['D', 'C', 'F', 'E', 'A'] ['F', 'D', 'C', 'E', 'B']\n",
      "Doc 19 : 0.0 ['C', 'F', 'E', 'A', 'D'] ['F', 'B', 'D', 'E', 'C']\n",
      "Doc 20 : 0.0 ['D', 'F', 'A', 'B', 'E'] ['E', 'A', 'D', 'C', 'F']\n",
      "Doc 21 : 0.6 ['C', 'B', 'F', 'D', 'E'] ['C', 'B', 'A', 'F', 'E']\n",
      "Doc 22 : 0.8 ['E', 'C', 'D', 'B', 'F'] ['E', 'A', 'D', 'B', 'F']\n",
      "Doc 23 : 0.25 ['D', 'A', 'C', 'B'] ['C', 'A', 'B', 'D']\n",
      "Doc 24 : 1.0 ['B', 'D', 'A', 'C'] ['B', 'D', 'A', 'C']\n",
      "Doc 25 : 0.25 ['D', 'C', 'B', 'A'] ['D', 'A', 'C', 'B']\n",
      "Doc 26 : 0.25 ['D', 'B', 'C', 'A'] ['A', 'B', 'D', 'C']\n",
      "Doc 27 : 0.0 ['A', 'C', 'B', 'D'] ['C', 'D', 'A', 'B']\n",
      "Doc 28 : 1.0 ['B', 'C', 'A', 'D'] ['B', 'C', 'A', 'D']\n",
      "Doc 29 : 0.25 ['D', 'B', 'C', 'A'] ['A', 'D', 'C', 'B']\n",
      "Doc 30 : 0.5 ['B', 'D', 'A', 'C'] ['B', 'A', 'D', 'C']\n",
      "Doc 31 : 0.5 ['A', 'B', 'D', 'C'] ['A', 'C', 'D', 'B']\n",
      "Doc 32 : 0.5 ['B', 'C', 'A', 'D'] ['C', 'B', 'A', 'D']\n",
      "Doc 33 : 0.5 ['A', 'B', 'C', 'D'] ['D', 'B', 'C', 'A']\n",
      "Doc 34 : 1.0 ['B', 'D', 'C', 'A'] ['B', 'D', 'C', 'A']\n",
      "Doc 35 : 0.0 ['A', 'B', 'C', 'D'] ['D', 'C', 'A', 'B']\n",
      "Doc 36 : 1.0 ['A', 'D', 'B', 'C'] ['A', 'D', 'B', 'C']\n",
      "Doc 37 : 0.5 ['C', 'B', 'D', 'A'] ['C', 'D', 'B', 'A']\n",
      "Doc 38 : 1.0 ['C', 'B', 'D', 'A'] ['C', 'B', 'D', 'A']\n",
      "Doc 39 : 0.5 ['C', 'A', 'B', 'D'] ['D', 'A', 'B', 'C']\n",
      "Doc 40 : 0.5 ['D', 'C', 'B', 'A'] ['A', 'C', 'B', 'D']\n",
      "Doc 41 : 0.0 ['A', 'C', 'D', 'B'] ['B', 'A', 'C', 'D']\n",
      "Doc 42 : 0.5 ['C', 'B', 'D', 'A'] ['C', 'A', 'D', 'B']\n",
      "Doc 43 : 0.6 ['E', 'F', 'A', 'C', 'B'] ['E', 'F', 'C', 'D', 'B']\n",
      "Doc 44 : 0.2 ['D', 'F', 'E', 'B', 'C'] ['D', 'C', 'F', 'E', 'B']\n",
      "Doc 45 : 0.4 ['C', 'F', 'E', 'D', 'A'] ['C', 'F', 'D', 'A', 'B']\n",
      "Doc 46 : 0.6 ['E', 'D', 'F', 'A', 'B'] ['E', 'C', 'F', 'D', 'B']\n",
      "Doc 47 : 0.4 ['C', 'E', 'F', 'A', 'D'] ['E', 'D', 'F', 'A', 'C']\n",
      "Doc 48 : 0.6 ['A', 'C', 'B', 'E', 'D'] ['F', 'C', 'B', 'E', 'A']\n",
      "Doc 49 : 0.2 ['A', 'B', 'E', 'D', 'F'] ['D', 'A', 'C', 'E', 'F']\n",
      "Doc 50 : 0.2 ['A', 'C', 'E', 'D', 'B'] ['D', 'E', 'F', 'A', 'B']\n",
      "Doc 51 : 0.4 ['A', 'C', 'B', 'F', 'E'] ['B', 'D', 'C', 'F', 'E']\n",
      "Doc 52 : 0.2 ['A', 'B', 'C', 'E', 'F'] ['D', 'C', 'F', 'E', 'B']\n",
      "Doc 53 : 0.2 ['A', 'F', 'C', 'D', 'B'] ['E', 'D', 'C', 'B', 'A']\n",
      "Doc 54 : 0.4 ['D', 'B', 'C', 'A', 'E'] ['F', 'E', 'C', 'A', 'D']\n",
      "Doc 55 : 0.2 ['D', 'C', 'E', 'B', 'F'] ['D', 'F', 'B', 'A', 'C']\n",
      "Doc 56 : 0.6 ['E', 'A', 'B', 'C', 'F'] ['E', 'C', 'B', 'D', 'F']\n",
      "Doc 57 : 0.4 ['D', 'B', 'F', 'C', 'A'] ['D', 'B', 'C', 'A', 'E']\n",
      "Doc 58 : 0.4 ['C', 'E', 'D', 'F', 'A'] ['B', 'E', 'C', 'F', 'D']\n",
      "Doc 59 : 0.6 ['C', 'D', 'F', 'E', 'A'] ['C', 'D', 'A', 'E', 'F']\n",
      "Doc 60 : 0.6 ['E', 'F', 'B', 'D', 'C'] ['A', 'F', 'B', 'D', 'E']\n",
      "Doc 61 : 0.2 ['F', 'A', 'E', 'C', 'D'] ['F', 'E', 'D', 'B', 'A']\n",
      "Doc 62 : 0.6 ['C', 'F', 'E', 'A', 'B'] ['C', 'E', 'D', 'A', 'B']\n",
      "Doc 63 : 0.2 ['B', 'D', 'A', 'E', 'F'] ['B', 'F', 'E', 'A', 'C']\n",
      "Doc 64 : 0.6 ['A', 'B', 'D', 'F', 'C'] ['E', 'B', 'D', 'F', 'A']\n",
      "Doc 65 : 0.2 ['F', 'E', 'D', 'B', 'C'] ['C', 'D', 'A', 'B', 'F']\n",
      "Doc 66 : 0.6 ['C', 'D', 'F', 'B', 'E'] ['C', 'F', 'D', 'B', 'E']\n",
      "Doc 67 : 0.2 ['C', 'A', 'E', 'F', 'B'] ['C', 'F', 'B', 'A', 'D']\n",
      "Doc 68 : 0.4 ['A', 'C', 'B', 'D', 'F'] ['A', 'D', 'C', 'E', 'F']\n",
      "Doc 69 : 0.4 ['B', 'C', 'F', 'D', 'E'] ['A', 'E', 'F', 'D', 'B']\n",
      "Doc 70 : 0.2 ['C', 'E', 'A', 'D', 'F'] ['C', 'F', 'B', 'E', 'D']\n",
      "Doc 71 : 0.2 ['F', 'B', 'E', 'A', 'D'] ['F', 'D', 'A', 'E', 'C']\n",
      "Doc 72 : 0.4 ['D', 'A', 'E', 'C', 'B'] ['D', 'F', 'E', 'B', 'C']\n",
      "Doc 73 : 0.0 ['B', 'D', 'A', 'E', 'C'] ['D', 'B', 'E', 'A', 'F']\n",
      "Doc 74 : 0.2 ['F', 'E', 'A', 'D', 'B'] ['C', 'E', 'D', 'F', 'A']\n",
      "Doc 75 : 0.4 ['F', 'E', 'C', 'D', 'A'] ['F', 'B', 'C', 'A', 'D']\n",
      "Doc 76 : 0.2 ['D', 'C', 'F', 'A', 'B'] ['B', 'E', 'C', 'A', 'F']\n",
      "Doc 77 : 0.6 ['C', 'D', 'F', 'B', 'A'] ['C', 'A', 'F', 'B', 'D']\n",
      "Doc 78 : 0.2 ['D', 'C', 'A', 'B', 'E'] ['F', 'D', 'B', 'A', 'E']\n",
      "Doc 79 : 0.0 ['F', 'D', 'B', 'A', 'E'] ['D', 'F', 'C', 'E', 'A']\n",
      "Doc 80 : 0.6 ['D', 'F', 'E', 'B', 'C'] ['D', 'F', 'E', 'C', 'A']\n",
      "Doc 81 : 0.4 ['F', 'B', 'A', 'C', 'D'] ['C', 'F', 'A', 'B', 'D']\n",
      "Doc 82 : 0.6 ['D', 'E', 'B', 'F', 'A'] ['D', 'E', 'F', 'C', 'A']\n",
      "Doc 83 : 0.4 ['D', 'F', 'C', 'B', 'A'] ['D', 'C', 'E', 'F', 'A']\n",
      "Doc 84 : 0.2 ['C', 'B', 'A', 'E', 'D'] ['B', 'C', 'A', 'D', 'E']\n",
      "Doc 85 : 0.4 ['D', 'A', 'B', 'C', 'F'] ['D', 'A', 'F', 'B', 'C']\n",
      "Doc 86 : 0.2 ['A', 'C', 'E', 'B', 'D'] ['F', 'C', 'A', 'E', 'B']\n",
      "Doc 87 : 0.6 ['C', 'E', 'A', 'B', 'D'] ['C', 'E', 'B', 'A', 'D']\n",
      "Doc 88 : 0.6 ['C', 'A', 'D', 'B', 'E'] ['C', 'F', 'D', 'B', 'A']\n",
      "Doc 89 : 0.6 ['B', 'E', 'D', 'C', 'A'] ['B', 'E', 'C', 'D', 'A']\n",
      "Doc 90 : 0.4 ['A', 'C', 'E', 'D', 'B'] ['C', 'D', 'E', 'A', 'B']\n",
      "Doc 91 : 1.0 ['D', 'A', 'E', 'B', 'C'] ['D', 'A', 'E', 'B', 'C']\n"
     ]
    }
   ],
   "source": [
    "correct_rate = []\n",
    "\n",
    "for i in range(len(our_answer_1)):\n",
    "  count = 0\n",
    "  ours = []\n",
    "  correct = []\n",
    "  for j in range(len(our_answer_1[i])):\n",
    "    correct.append(ans_df.iloc[i][j+1])\n",
    "    if (our_answer_1[i][j] == 0):\n",
    "      ours.append('A')\n",
    "    elif (our_answer_1[i][j] == 1):\n",
    "      ours.append('B')\n",
    "    elif (our_answer_1[i][j] == 2):\n",
    "      ours.append('C')\n",
    "    elif (our_answer_1[i][j] == 3):\n",
    "      ours.append('D')\n",
    "    elif (our_answer_1[i][j] == 4):\n",
    "      ours.append('E')\n",
    "    elif (our_answer_1[i][j] == 5):\n",
    "      ours.append('F')\n",
    "    if (ans_df.iloc[i][j+1] == ours[j]):\n",
    "      count += 1\n",
    "  print(\"Doc\", i+1, \":\", count/len(our_answer_1[i]), ours, correct)\n",
    "  correct_rate.append(count/len(our_answer_1[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1RqqQvF5mQ_n",
    "outputId": "50b4bc91-386e-40a1-b152-10b9af25c329"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4021978021978022"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(correct_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RAQkrSfpmSMH",
    "outputId": "d5dbb758-4a22-4bb5-81bc-017eed1ff0a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0.2: 22, 0.6: 20, 0.4: 21, 0.0: 9, 0.8: 1, 0.25: 4, 1.0: 6, 0.5: 8})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "collections.Counter(correct_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ixA3hBLHmb_X",
    "outputId": "dbe16071-f81c-4f05-b877-7bc284d034f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.  0.34545454545454546 Counter({0.4: 7, 0.2: 5, 0.6: 5, 0.0: 4, 0.8: 1})\n",
      "2.  0.5 Counter({0.5: 8, 1.0: 5, 0.25: 4, 0.0: 3})\n",
      "3.  0.39999999999999997 Counter({0.6: 7, 0.2: 7, 0.4: 6})\n",
      "4.  0.3793103448275862 Counter({0.2: 10, 0.6: 8, 0.4: 8, 0.0: 2, 1.0: 1})\n"
     ]
    }
   ],
   "source": [
    "print(\"1. \", np.mean(correct_rate[0:22]), collections.Counter(correct_rate[0:22]))\n",
    "print(\"2. \", np.mean(correct_rate[22:42]), collections.Counter(correct_rate[22:42]))\n",
    "print(\"3. \", np.mean(correct_rate[42:62]), collections.Counter(correct_rate[42:62]))\n",
    "print(\"4. \", np.mean(correct_rate[62:91]), collections.Counter(correct_rate[62:91]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L6XIhQIFmfoq"
   },
   "source": [
    "# 4. Use finetuned BERT for NSP with linear sum assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Hw6Jq5-minr",
    "outputId": "914ef80c-b90e-4d76-e4f0-69a4a0a422b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0 3 2 1 4]\n",
      "1 [4 3 2 0 1]\n",
      "2 [3 1 4 0 2]\n",
      "3 [1 0 4 2 3]\n",
      "4 [2 1 4 3 0]\n",
      "5 [3 4 2 0 1]\n",
      "6 [1 2 4 3 0]\n",
      "7 [0 4 3 2 1]\n",
      "8 [4 2 1 3 0]\n",
      "9 [1 0 3 4 2]\n",
      "10 [5 1 0 2 3]\n",
      "11 [1 0 3 5 4]\n",
      "12 [0 3 5 2 4]\n",
      "13 [3 1 4 5 0]\n",
      "14 [3 4 1 0 5]\n",
      "15 [5 4 2 1 0]\n",
      "16 [2 1 3 0 4]\n",
      "17 [3 2 5 1 4]\n",
      "18 [5 4 3 0 2]\n",
      "19 [3 0 4 1 5]\n",
      "20 [2 1 0 5 4]\n",
      "21 [4 0 2 1 5]\n",
      "22 [2 1 0 3]\n",
      "23 [1 3 0 2]\n",
      "24 [3 0 1 2]\n",
      "25 [3 0 1 2]\n",
      "26 [2 3 0 1]\n",
      "27 [1 2 0 3]\n",
      "28 [1 3 2 0]\n",
      "29 [1 0 3 2]\n",
      "30 [0 2 3 1]\n",
      "31 [2 1 0 3]\n",
      "32 [2 1 0 3]\n",
      "33 [1 3 2 0]\n",
      "34 [1 3 0 2]\n",
      "35 [0 3 1 2]\n",
      "36 [2 1 3 0]\n",
      "37 [2 1 3 0]\n",
      "38 [3 0 1 2]\n",
      "39 [3 2 1 0]\n",
      "40 [1 2 3 0]\n",
      "41 [0 2 3 1]\n",
      "42 [4 0 2 3 1]\n",
      "43 [4 0 5 1 2]\n",
      "44 [2 5 3 4 0]\n",
      "45 [4 1 5 0 3]\n",
      "46 [2 4 3 5 0]\n",
      "47 [5 2 0 1 3]\n",
      "48 [3 1 0 4 5]\n",
      "49 [3 4 5 0 2]\n",
      "50 [1 3 2 5 4]\n",
      "51 [5 0 2 4 1]\n",
      "52 [1 0 2 5 3]\n",
      "53 [1 3 4 0 2]\n",
      "54 [3 1 5 4 0]\n",
      "55 [4 2 1 3 5]\n",
      "56 [2 1 5 0 4]\n",
      "57 [2 4 3 5 0]\n",
      "58 [1 2 5 4 0]\n",
      "59 [2 4 1 3 5]\n",
      "60 [1 4 0 2 5]\n",
      "61 [1 5 3 0 4]\n",
      "62 [1 5 3 4 0]\n",
      "63 [4 0 3 5 2]\n",
      "64 [2 4 3 1 5]\n",
      "65 [3 5 2 1 4]\n",
      "66 [2 0 5 1 3]\n",
      "67 [3 1 2 4 5]\n",
      "68 [5 4 3 2 1]\n",
      "69 [2 4 0 3 5]\n",
      "70 [2 3 4 0 5]\n",
      "71 [0 5 4 2 1]\n",
      "72 [3 1 0 2 4]\n",
      "73 [4 5 3 1 0]\n",
      "74 [3 4 2 5 0]\n",
      "75 [3 4 2 1 5]\n",
      "76 [5 2 3 1 0]\n",
      "77 [3 4 1 0 2]\n",
      "78 [3 0 2 1 4]\n",
      "79 [3 5 4 1 2]\n",
      "80 [2 5 0 1 3]\n",
      "81 [4 3 5 1 0]\n",
      "82 [2 1 5 3 0]\n",
      "83 [2 1 0 5 4]\n",
      "84 [3 2 1 0 5]\n",
      "85 [2 5 4 1 3]\n",
      "86 [1 4 0 2 3]\n",
      "87 [4 2 1 0 3]\n",
      "88 [3 4 2 0 1]\n",
      "89 [4 3 2 1 0]\n",
      "90 [3 0 4 1 2]\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import linear_sum_assignment\n",
    "our_answer_2 = []\n",
    "tmp_prob_for_LSA = answer_prob\n",
    "\n",
    "for i in range(len(answer_prob)):\n",
    "  for j in range(len(answer_prob[i])):\n",
    "    for k in range(len(answer_prob[i][j])):\n",
    "      tmp_prob_for_LSA[i][j][k] = -tmp_prob_for_LSA[i][j][k]\n",
    "  row_ind, col_ind = linear_sum_assignment(tmp_prob_for_LSA[i])\n",
    "  our_answer_2.append(col_ind)\n",
    "  print(i, col_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kIctCv_emnWw",
    "outputId": "67c10b31-bc2f-43e5-f715-090d609bc363"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc 1 : 0.4 ['A', 'D', 'C', 'B', 'E'] ['E', 'D', 'C', 'A', 'B']\n",
      "Doc 2 : 1.0 ['E', 'D', 'C', 'A', 'B'] ['E', 'D', 'C', 'A', 'B']\n",
      "Doc 3 : 1.0 ['D', 'B', 'E', 'A', 'C'] ['D', 'B', 'E', 'A', 'C']\n",
      "Doc 4 : 0.0 ['B', 'A', 'E', 'C', 'D'] ['C', 'E', 'A', 'D', 'B']\n",
      "Doc 5 : 0.6 ['C', 'B', 'E', 'D', 'A'] ['C', 'B', 'E', 'A', 'D']\n",
      "Doc 6 : 0.4 ['D', 'E', 'C', 'A', 'B'] ['C', 'E', 'A', 'D', 'B']\n",
      "Doc 7 : 0.2 ['B', 'C', 'E', 'D', 'A'] ['B', 'D', 'A', 'E', 'C']\n",
      "Doc 8 : 1.0 ['A', 'E', 'D', 'C', 'B'] ['A', 'E', 'D', 'C', 'B']\n",
      "Doc 9 : 0.4 ['E', 'C', 'B', 'D', 'A'] ['E', 'C', 'D', 'A', 'B']\n",
      "Doc 10 : 0.2 ['B', 'A', 'D', 'E', 'C'] ['E', 'D', 'A', 'B', 'C']\n",
      "Doc 11 : 0.4 ['F', 'B', 'A', 'C', 'D'] ['F', 'D', 'A', 'E', 'C']\n",
      "Doc 12 : 0.6 ['B', 'A', 'D', 'F', 'E'] ['B', 'A', 'D', 'E', 'F']\n",
      "Doc 13 : 0.6 ['A', 'D', 'F', 'C', 'E'] ['B', 'D', 'F', 'A', 'E']\n",
      "Doc 14 : 0.0 ['D', 'B', 'E', 'F', 'A'] ['E', 'A', 'F', 'C', 'D']\n",
      "Doc 15 : 0.2 ['D', 'E', 'B', 'A', 'F'] ['E', 'A', 'B', 'F', 'C']\n",
      "Doc 16 : 0.8 ['F', 'E', 'C', 'B', 'A'] ['F', 'E', 'C', 'B', 'D']\n",
      "Doc 17 : 0.2 ['C', 'B', 'D', 'A', 'E'] ['C', 'F', 'A', 'E', 'D']\n",
      "Doc 18 : 0.0 ['D', 'C', 'F', 'B', 'E'] ['F', 'D', 'C', 'E', 'B']\n",
      "Doc 19 : 0.6 ['F', 'E', 'D', 'A', 'C'] ['F', 'B', 'D', 'E', 'C']\n",
      "Doc 20 : 0.4 ['D', 'A', 'E', 'B', 'F'] ['E', 'A', 'D', 'C', 'F']\n",
      "Doc 21 : 1.0 ['C', 'B', 'A', 'F', 'E'] ['C', 'B', 'A', 'F', 'E']\n",
      "Doc 22 : 0.8 ['E', 'A', 'C', 'B', 'F'] ['E', 'A', 'D', 'B', 'F']\n",
      "Doc 23 : 0.5 ['C', 'B', 'A', 'D'] ['C', 'A', 'B', 'D']\n",
      "Doc 24 : 1.0 ['B', 'D', 'A', 'C'] ['B', 'D', 'A', 'C']\n",
      "Doc 25 : 0.5 ['D', 'A', 'B', 'C'] ['D', 'A', 'C', 'B']\n",
      "Doc 26 : 0.25 ['D', 'A', 'B', 'C'] ['A', 'B', 'D', 'C']\n",
      "Doc 27 : 1.0 ['C', 'D', 'A', 'B'] ['C', 'D', 'A', 'B']\n",
      "Doc 28 : 1.0 ['B', 'C', 'A', 'D'] ['B', 'C', 'A', 'D']\n",
      "Doc 29 : 0.5 ['B', 'D', 'C', 'A'] ['A', 'D', 'C', 'B']\n",
      "Doc 30 : 1.0 ['B', 'A', 'D', 'C'] ['B', 'A', 'D', 'C']\n",
      "Doc 31 : 1.0 ['A', 'C', 'D', 'B'] ['A', 'C', 'D', 'B']\n",
      "Doc 32 : 1.0 ['C', 'B', 'A', 'D'] ['C', 'B', 'A', 'D']\n",
      "Doc 33 : 0.25 ['C', 'B', 'A', 'D'] ['D', 'B', 'C', 'A']\n",
      "Doc 34 : 1.0 ['B', 'D', 'C', 'A'] ['B', 'D', 'C', 'A']\n",
      "Doc 35 : 0.25 ['B', 'D', 'A', 'C'] ['D', 'C', 'A', 'B']\n",
      "Doc 36 : 1.0 ['A', 'D', 'B', 'C'] ['A', 'D', 'B', 'C']\n",
      "Doc 37 : 0.5 ['C', 'B', 'D', 'A'] ['C', 'D', 'B', 'A']\n",
      "Doc 38 : 1.0 ['C', 'B', 'D', 'A'] ['C', 'B', 'D', 'A']\n",
      "Doc 39 : 1.0 ['D', 'A', 'B', 'C'] ['D', 'A', 'B', 'C']\n",
      "Doc 40 : 0.5 ['D', 'C', 'B', 'A'] ['A', 'C', 'B', 'D']\n",
      "Doc 41 : 0.25 ['B', 'C', 'D', 'A'] ['B', 'A', 'C', 'D']\n",
      "Doc 42 : 0.5 ['A', 'C', 'D', 'B'] ['C', 'A', 'D', 'B']\n",
      "Doc 43 : 0.8 ['E', 'A', 'C', 'D', 'B'] ['E', 'F', 'C', 'D', 'B']\n",
      "Doc 44 : 0.2 ['E', 'A', 'F', 'B', 'C'] ['D', 'C', 'F', 'E', 'B']\n",
      "Doc 45 : 0.6 ['C', 'F', 'D', 'E', 'A'] ['C', 'F', 'D', 'A', 'B']\n",
      "Doc 46 : 0.4 ['E', 'B', 'F', 'A', 'D'] ['E', 'C', 'F', 'D', 'B']\n",
      "Doc 47 : 0.0 ['C', 'E', 'D', 'F', 'A'] ['E', 'D', 'F', 'A', 'C']\n",
      "Doc 48 : 0.4 ['F', 'C', 'A', 'B', 'D'] ['F', 'C', 'B', 'E', 'A']\n",
      "Doc 49 : 0.6 ['D', 'B', 'A', 'E', 'F'] ['D', 'A', 'C', 'E', 'F']\n",
      "Doc 50 : 0.8 ['D', 'E', 'F', 'A', 'C'] ['D', 'E', 'F', 'A', 'B']\n",
      "Doc 51 : 1.0 ['B', 'D', 'C', 'F', 'E'] ['B', 'D', 'C', 'F', 'E']\n",
      "Doc 52 : 0.4 ['F', 'A', 'C', 'E', 'B'] ['D', 'C', 'F', 'E', 'B']\n",
      "Doc 53 : 0.2 ['B', 'A', 'C', 'F', 'D'] ['E', 'D', 'C', 'B', 'A']\n",
      "Doc 54 : 0.2 ['B', 'D', 'E', 'A', 'C'] ['F', 'E', 'C', 'A', 'D']\n",
      "Doc 55 : 0.2 ['D', 'B', 'F', 'E', 'A'] ['D', 'F', 'B', 'A', 'C']\n",
      "Doc 56 : 1.0 ['E', 'C', 'B', 'D', 'F'] ['E', 'C', 'B', 'D', 'F']\n",
      "Doc 57 : 0.6 ['C', 'B', 'F', 'A', 'E'] ['D', 'B', 'C', 'A', 'E']\n",
      "Doc 58 : 0.4 ['C', 'E', 'D', 'F', 'A'] ['B', 'E', 'C', 'F', 'D']\n",
      "Doc 59 : 0.2 ['B', 'C', 'F', 'E', 'A'] ['C', 'D', 'A', 'E', 'F']\n",
      "Doc 60 : 0.4 ['C', 'E', 'B', 'D', 'F'] ['A', 'F', 'B', 'D', 'E']\n",
      "Doc 61 : 0.2 ['B', 'E', 'A', 'C', 'F'] ['F', 'E', 'D', 'B', 'A']\n",
      "Doc 62 : 0.4 ['B', 'F', 'D', 'A', 'E'] ['C', 'E', 'D', 'A', 'B']\n",
      "Doc 63 : 0.4 ['B', 'F', 'D', 'E', 'A'] ['B', 'F', 'E', 'A', 'C']\n",
      "Doc 64 : 0.6 ['E', 'A', 'D', 'F', 'C'] ['E', 'B', 'D', 'F', 'A']\n",
      "Doc 65 : 0.6 ['C', 'E', 'D', 'B', 'F'] ['C', 'D', 'A', 'B', 'F']\n",
      "Doc 66 : 0.6 ['D', 'F', 'C', 'B', 'E'] ['C', 'F', 'D', 'B', 'E']\n",
      "Doc 67 : 0.4 ['C', 'A', 'F', 'B', 'D'] ['C', 'F', 'B', 'A', 'D']\n",
      "Doc 68 : 0.6 ['D', 'B', 'C', 'E', 'F'] ['A', 'D', 'C', 'E', 'F']\n",
      "Doc 69 : 0.4 ['F', 'E', 'D', 'C', 'B'] ['A', 'E', 'F', 'D', 'B']\n",
      "Doc 70 : 0.2 ['C', 'E', 'A', 'D', 'F'] ['C', 'F', 'B', 'E', 'D']\n",
      "Doc 71 : 0.2 ['C', 'D', 'E', 'A', 'F'] ['F', 'D', 'A', 'E', 'C']\n",
      "Doc 72 : 0.4 ['A', 'F', 'E', 'C', 'B'] ['D', 'F', 'E', 'B', 'C']\n",
      "Doc 73 : 0.4 ['D', 'B', 'A', 'C', 'E'] ['D', 'B', 'E', 'A', 'F']\n",
      "Doc 74 : 0.4 ['E', 'F', 'D', 'B', 'A'] ['C', 'E', 'D', 'F', 'A']\n",
      "Doc 75 : 0.2 ['D', 'E', 'C', 'F', 'A'] ['F', 'B', 'C', 'A', 'D']\n",
      "Doc 76 : 0.6 ['D', 'E', 'C', 'B', 'F'] ['B', 'E', 'C', 'A', 'F']\n",
      "Doc 77 : 0.2 ['F', 'C', 'D', 'B', 'A'] ['C', 'A', 'F', 'B', 'D']\n",
      "Doc 78 : 0.4 ['D', 'E', 'B', 'A', 'C'] ['F', 'D', 'B', 'A', 'E']\n",
      "Doc 79 : 0.4 ['D', 'A', 'C', 'B', 'E'] ['D', 'F', 'C', 'E', 'A']\n",
      "Doc 80 : 0.6 ['D', 'F', 'E', 'B', 'C'] ['D', 'F', 'E', 'C', 'A']\n",
      "Doc 81 : 1.0 ['C', 'F', 'A', 'B', 'D'] ['C', 'F', 'A', 'B', 'D']\n",
      "Doc 82 : 0.4 ['E', 'D', 'F', 'B', 'A'] ['D', 'E', 'F', 'C', 'A']\n",
      "Doc 83 : 0.2 ['C', 'B', 'F', 'D', 'A'] ['D', 'C', 'E', 'F', 'A']\n",
      "Doc 84 : 0.4 ['C', 'B', 'A', 'F', 'E'] ['B', 'C', 'A', 'D', 'E']\n",
      "Doc 85 : 0.2 ['D', 'C', 'B', 'A', 'F'] ['D', 'A', 'F', 'B', 'C']\n",
      "Doc 86 : 0.0 ['C', 'F', 'E', 'B', 'D'] ['F', 'C', 'A', 'E', 'B']\n",
      "Doc 87 : 0.4 ['B', 'E', 'A', 'C', 'D'] ['C', 'E', 'B', 'A', 'D']\n",
      "Doc 88 : 0.0 ['E', 'C', 'B', 'A', 'D'] ['C', 'F', 'D', 'B', 'A']\n",
      "Doc 89 : 0.4 ['D', 'E', 'C', 'A', 'B'] ['B', 'E', 'C', 'D', 'A']\n",
      "Doc 90 : 0.2 ['E', 'D', 'C', 'B', 'A'] ['C', 'D', 'E', 'A', 'B']\n",
      "Doc 91 : 1.0 ['D', 'A', 'E', 'B', 'C'] ['D', 'A', 'E', 'B', 'C']\n"
     ]
    }
   ],
   "source": [
    "## Compare our answer with the correct answer\n",
    "correct_rate = []\n",
    "\n",
    "for i in range(len(our_answer_2)):\n",
    "  count = 0\n",
    "  ours = []\n",
    "  correct = []\n",
    "  for j in range(len(our_answer_2[i])):\n",
    "    correct.append(ans_df.iloc[i][j+1])\n",
    "    if (our_answer_2[i][j] == 0):\n",
    "      ours.append('A')\n",
    "    elif (our_answer_2[i][j] == 1):\n",
    "      ours.append('B')\n",
    "    elif (our_answer_2[i][j] == 2):\n",
    "      ours.append('C')\n",
    "    elif (our_answer_2[i][j] == 3):\n",
    "      ours.append('D')\n",
    "    elif (our_answer_2[i][j] == 4):\n",
    "      ours.append('E')\n",
    "    elif (our_answer_2[i][j] == 5):\n",
    "      ours.append('F')\n",
    "    if (ans_df.iloc[i][j+1] == ours[j]):\n",
    "      count += 1\n",
    "  print(\"Doc\", i+1, \":\", count/len(our_answer_2[i]), ours, correct)\n",
    "  correct_rate.append(count/len(our_answer_2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zSAY5Zm7mzB7",
    "outputId": "3d99d712-4a0e-4449-b9f7-257fd848b750"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5010989010989011"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(correct_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6KiamH9bmzB8",
    "outputId": "e0e3d5c3-3d76-4e65-a669-e67e48d875e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0.4: 23, 1.0: 18, 0.0: 6, 0.6: 13, 0.2: 17, 0.8: 4, 0.5: 6, 0.25: 4})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "collections.Counter(correct_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LrNL_cbEmzB8",
    "outputId": "dc56a0b4-70f6-4953-b870-4246aab8f121"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.  0.49090909090909096 Counter({0.4: 5, 1.0: 4, 0.6: 4, 0.2: 4, 0.0: 3, 0.8: 2})\n",
      "2.  0.7 Counter({1.0: 10, 0.5: 6, 0.25: 4})\n",
      "3.  0.45 Counter({0.2: 6, 0.4: 6, 0.6: 3, 0.8: 2, 1.0: 2, 0.0: 1})\n",
      "4.  0.40689655172413797 Counter({0.4: 12, 0.2: 7, 0.6: 6, 1.0: 2, 0.0: 2})\n"
     ]
    }
   ],
   "source": [
    "print(\"1. \", np.mean(correct_rate[0:22]), collections.Counter(correct_rate[0:22]))\n",
    "print(\"2. \", np.mean(correct_rate[22:42]), collections.Counter(correct_rate[22:42]))\n",
    "print(\"3. \", np.mean(correct_rate[42:62]), collections.Counter(correct_rate[42:62]))\n",
    "print(\"4. \", np.mean(correct_rate[62:91]), collections.Counter(correct_rate[62:91]))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
